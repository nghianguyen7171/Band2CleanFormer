{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Synthetic EEG+EOG Dictionary Keys (SNR Levels): dict_keys([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
      "üîπ Clean EEG Shape: (4514, 1024)\n",
      "üîπ SNR Level -7: Shape = (4514, 1024)\n",
      "üîπ SNR Level -6: Shape = (4514, 1024)\n",
      "üîπ SNR Level -5: Shape = (4514, 1024)\n",
      "üîπ SNR Level -4: Shape = (4514, 1024)\n",
      "üîπ SNR Level -3: Shape = (4514, 1024)\n",
      "üîπ SNR Level -2: Shape = (4514, 1024)\n",
      "üîπ SNR Level -1: Shape = (4514, 1024)\n",
      "üîπ SNR Level 0: Shape = (4514, 1024)\n",
      "üîπ SNR Level 1: Shape = (4514, 1024)\n",
      "üîπ SNR Level 2: Shape = (4514, 1024)\n",
      "üîπ Clean EEG Mean: -0.01437441971536275\n",
      "üîπ Clean EEG Std Dev: 228.54837530823107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dataset files\n",
    "#synthetic_eeg_eog_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/Linear_synthetic_eeg_eog.npy\"\n",
    "#clean_eeg_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/EEG_all_epochs.npy\"\n",
    "synthetic_eeg_eog_path = \"/home/tulgaa/Desktop/emg_dataset/signal/Linear_synthetic_eeg_emg.npy\"\n",
    "clean_eeg_path = \"/home/tulgaa/Desktop/emg_dataset/signal/EEG_all_epochs.npy\"\n",
    "\n",
    "# Load the numpy arrays\n",
    "synthetic_eeg_eog = np.load(synthetic_eeg_eog_path, allow_pickle=True).item()  # Dictionary of SNR levels\n",
    "clean_eeg = np.load(clean_eeg_path)  # Ground truth EEG\n",
    "\n",
    "# Inspect dataset keys and shapes\n",
    "print(\"üîπ Synthetic EEG+EOG Dictionary Keys (SNR Levels):\", synthetic_eeg_eog.keys())\n",
    "print(\"üîπ Clean EEG Shape:\", clean_eeg.shape)\n",
    "\n",
    "# Print shape of each SNR level data\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    print(f\"üîπ SNR Level {snr}: Shape = {synthetic_eeg_eog[snr].shape}\")\n",
    "\n",
    "# Check statistics of clean EEG data\n",
    "print(\"üîπ Clean EEG Mean:\", np.mean(clean_eeg))\n",
    "print(\"üîπ Clean EEG Std Dev:\", np.std(clean_eeg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Set: torch.Size([36112, 1024]) Clean: torch.Size([36112, 1024])\n",
      "‚úÖ Testing Set: torch.Size([9028, 1024]) Clean: torch.Size([9028, 1024])\n",
      "üîÅ SNR Distribution in Test Set: (array([-7, -6, -5, -4, -3, -2, -1,  0,  1,  2]), array([903, 902, 903, 903, 903, 903, 903, 903, 902, 903]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Combine all SNR levels into a single dataset\n",
    "X_all, Y_all, snr_labels_all = [], [], []\n",
    "\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    contaminated = synthetic_eeg_eog[snr]\n",
    "    clean = clean_eeg\n",
    "    X_all.append(contaminated)\n",
    "    Y_all.append(clean)\n",
    "    snr_labels_all.extend([int(snr)] * len(contaminated))\n",
    "\n",
    "# Stack all data\n",
    "X_all = np.vstack(X_all)\n",
    "Y_all = np.vstack(Y_all)\n",
    "snr_labels_all = np.array(snr_labels_all)\n",
    "\n",
    "# Global stratified train/test split\n",
    "X_train, X_test, Y_train, Y_test, snr_labels_train, snr_labels_test = train_test_split(\n",
    "    X_all, Y_all, snr_labels_all, test_size=0.2, stratify=snr_labels_all, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# Final shapes and SNR label info\n",
    "print(\"‚úÖ Training Set:\", X_train_tensor.shape, \"Clean:\", Y_train_tensor.shape)\n",
    "print(\"‚úÖ Testing Set:\", X_test_tensor.shape, \"Clean:\", Y_test_tensor.shape)\n",
    "print(\"üîÅ SNR Distribution in Test Set:\", np.unique(snr_labels_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGDnet(\n",
      "  (embedding): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EEGDnet(nn.Module):\n",
    "    def __init__(self, seq_len=1024, embed_dim=64, num_heads=4, depth=6, mlp_dim=128):\n",
    "        super(EEGDnet, self).__init__()\n",
    "        \n",
    "        # Reshape Layer: Convert 1D EEG (512,) ‚Üí 2D (8, 64)\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h, self.w = 8, 64  # Reshaped dimensions\n",
    "\n",
    "        # Linear Projection to Embed Dim\n",
    "        self.embedding = nn.Linear(self.w, embed_dim)  # Projects 64 ‚Üí 64\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.h, embed_dim))  # Positional Encoding\n",
    "\n",
    "        # Transformer Encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=mlp_dim, batch_first=True),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        # Output Layer: Convert back to 1D EEG (512,)\n",
    "        self.output_layer = nn.Linear(embed_dim, self.w)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape (Batch, 512) ‚Üí (Batch, 8, 64)\n",
    "        x = x.view(-1, self.h, self.w)\n",
    "\n",
    "        # Embedding & Positional Encoding\n",
    "        x = self.embedding(x) + self.pos_embedding\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Convert back to 1D EEG (Batch, 512)\n",
    "        x = self.output_layer(x).view(-1, self.seq_len)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "model = EEGDnet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üî• Using device: {device}\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = EEGDnet().to(device)\n",
    "\n",
    "# Define loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 10  # Stop if validation loss does not improve for 10 epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, X_train_input, y_train_input, X_test_input, y_test_input, epochs=100, batch_size=64):\n",
    "    global best_val_loss, epochs_no_improve\n",
    "    model.train()\n",
    "\n",
    "    # Move tensors to GPU\n",
    "    X_train_input = X_train_input.to(device)\n",
    "    y_train_input = y_train_input.to(device)\n",
    "    X_test_input = X_test_input.to(device)\n",
    "    y_test_input = y_test_input.to(device)\n",
    "\n",
    "    # Create Data Loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_input, y_train_input)\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test_input, y_test_input)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in test_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_output = model(X_val)\n",
    "                val_loss += criterion(val_output, y_val).item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.6f} - Val Loss: {avg_val_loss:.6f} - Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_eegdnet.pth\")\n",
    "            print(\"‚úÖ Model improved! Saving checkpoint.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"‚ö†Ô∏è No improvement for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000] - Train Loss: 52365.578668 - Val Loss: 51702.514323 - Time: 1.53s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2/5000] - Train Loss: 52311.024197 - Val Loss: 51661.286458 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [3/5000] - Train Loss: 52265.272569 - Val Loss: 51613.648872 - Time: 1.39s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [4/5000] - Train Loss: 52190.961046 - Val Loss: 51566.640191 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [5/5000] - Train Loss: 52169.632053 - Val Loss: 51525.747396 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [6/5000] - Train Loss: 52144.502279 - Val Loss: 51491.470486 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [7/5000] - Train Loss: 52136.833116 - Val Loss: 51461.616753 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [8/5000] - Train Loss: 52030.373372 - Val Loss: 51434.334635 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [9/5000] - Train Loss: 52043.534939 - Val Loss: 51408.585938 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [10/5000] - Train Loss: 52059.482313 - Val Loss: 51383.840712 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [11/5000] - Train Loss: 52044.313260 - Val Loss: 51359.807726 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [12/5000] - Train Loss: 51983.201823 - Val Loss: 51336.231771 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [13/5000] - Train Loss: 51987.297960 - Val Loss: 51312.941840 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [14/5000] - Train Loss: 51904.943902 - Val Loss: 51289.870226 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [15/5000] - Train Loss: 51987.579536 - Val Loss: 51266.920139 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [16/5000] - Train Loss: 51954.689128 - Val Loss: 51244.121094 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [17/5000] - Train Loss: 51932.961046 - Val Loss: 51221.352865 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [18/5000] - Train Loss: 51761.432292 - Val Loss: 51198.617622 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [19/5000] - Train Loss: 51850.798286 - Val Loss: 51175.956163 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [20/5000] - Train Loss: 51789.921007 - Val Loss: 51153.258681 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [21/5000] - Train Loss: 51800.345486 - Val Loss: 51130.546875 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [22/5000] - Train Loss: 51760.041233 - Val Loss: 51107.840278 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [23/5000] - Train Loss: 51741.390191 - Val Loss: 51085.062066 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [24/5000] - Train Loss: 51684.720269 - Val Loss: 51062.300781 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [25/5000] - Train Loss: 51657.909288 - Val Loss: 51039.493056 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [26/5000] - Train Loss: 51623.278103 - Val Loss: 51016.628038 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [27/5000] - Train Loss: 51637.024631 - Val Loss: 50993.719184 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [28/5000] - Train Loss: 51599.010091 - Val Loss: 50970.722656 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [29/5000] - Train Loss: 51634.594618 - Val Loss: 50947.705729 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [30/5000] - Train Loss: 51542.634983 - Val Loss: 50924.597656 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [31/5000] - Train Loss: 51529.456055 - Val Loss: 50901.469184 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [32/5000] - Train Loss: 51551.220703 - Val Loss: 50878.248698 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [33/5000] - Train Loss: 51527.193576 - Val Loss: 50855.045573 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [34/5000] - Train Loss: 51486.822157 - Val Loss: 50831.718316 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [35/5000] - Train Loss: 51451.960720 - Val Loss: 50808.369358 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [36/5000] - Train Loss: 51462.695964 - Val Loss: 50784.968316 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [37/5000] - Train Loss: 51490.301107 - Val Loss: 50761.509115 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [38/5000] - Train Loss: 51364.592665 - Val Loss: 50738.029514 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [39/5000] - Train Loss: 51361.867188 - Val Loss: 50714.463542 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [40/5000] - Train Loss: 51348.545356 - Val Loss: 50690.905382 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [41/5000] - Train Loss: 51333.815213 - Val Loss: 50667.284288 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [42/5000] - Train Loss: 51320.749783 - Val Loss: 50643.551215 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [43/5000] - Train Loss: 51248.747830 - Val Loss: 50619.851128 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [44/5000] - Train Loss: 51169.403320 - Val Loss: 50596.057292 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [45/5000] - Train Loss: 51191.837457 - Val Loss: 50572.228299 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [46/5000] - Train Loss: 51229.904622 - Val Loss: 50548.336372 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [47/5000] - Train Loss: 51176.069227 - Val Loss: 50524.345920 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [48/5000] - Train Loss: 51155.466580 - Val Loss: 50500.452257 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [49/5000] - Train Loss: 51147.794488 - Val Loss: 50476.346354 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [50/5000] - Train Loss: 51135.240777 - Val Loss: 50452.263455 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [51/5000] - Train Loss: 51088.643880 - Val Loss: 50428.102431 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [52/5000] - Train Loss: 51046.469076 - Val Loss: 50403.937500 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [53/5000] - Train Loss: 50993.491102 - Val Loss: 50379.714844 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [54/5000] - Train Loss: 51013.570638 - Val Loss: 50355.361111 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [55/5000] - Train Loss: 50992.539714 - Val Loss: 50330.993490 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [56/5000] - Train Loss: 50938.602214 - Val Loss: 50306.685764 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [57/5000] - Train Loss: 50885.332574 - Val Loss: 50282.109375 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [58/5000] - Train Loss: 50890.404948 - Val Loss: 50257.575087 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [59/5000] - Train Loss: 50867.039062 - Val Loss: 50233.010851 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [60/5000] - Train Loss: 50866.194444 - Val Loss: 50208.312066 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [61/5000] - Train Loss: 50838.636936 - Val Loss: 50183.662326 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [62/5000] - Train Loss: 50822.154297 - Val Loss: 50158.876736 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [63/5000] - Train Loss: 50789.007161 - Val Loss: 50134.049045 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [64/5000] - Train Loss: 50768.944770 - Val Loss: 50109.150174 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [65/5000] - Train Loss: 50672.571072 - Val Loss: 50084.266493 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [66/5000] - Train Loss: 50753.182943 - Val Loss: 50059.268229 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [67/5000] - Train Loss: 50623.415256 - Val Loss: 50034.191406 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [68/5000] - Train Loss: 50582.165148 - Val Loss: 50009.062066 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [69/5000] - Train Loss: 50681.458333 - Val Loss: 49983.949219 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [70/5000] - Train Loss: 50574.325195 - Val Loss: 49958.720052 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [71/5000] - Train Loss: 50553.220703 - Val Loss: 49933.464844 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [72/5000] - Train Loss: 50557.144640 - Val Loss: 49908.134549 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [73/5000] - Train Loss: 50496.615885 - Val Loss: 49882.736111 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [74/5000] - Train Loss: 50553.476888 - Val Loss: 49857.396267 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [75/5000] - Train Loss: 50490.809462 - Val Loss: 49831.878038 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [76/5000] - Train Loss: 50441.324978 - Val Loss: 49806.212674 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [77/5000] - Train Loss: 50435.656684 - Val Loss: 49780.626302 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [78/5000] - Train Loss: 50436.046115 - Val Loss: 49754.996962 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [79/5000] - Train Loss: 50401.182183 - Val Loss: 49729.191840 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [80/5000] - Train Loss: 50410.763672 - Val Loss: 49703.438368 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [81/5000] - Train Loss: 50325.343207 - Val Loss: 49677.546875 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [82/5000] - Train Loss: 50259.100043 - Val Loss: 49651.594618 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [83/5000] - Train Loss: 50224.302300 - Val Loss: 49625.700087 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [84/5000] - Train Loss: 50197.483181 - Val Loss: 49599.791233 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [85/5000] - Train Loss: 50222.251953 - Val Loss: 49573.659288 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [86/5000] - Train Loss: 50183.271810 - Val Loss: 49547.513889 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [87/5000] - Train Loss: 50149.192817 - Val Loss: 49521.248698 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [88/5000] - Train Loss: 50125.799154 - Val Loss: 49495.055556 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [89/5000] - Train Loss: 50166.169596 - Val Loss: 49468.710938 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [90/5000] - Train Loss: 50094.986328 - Val Loss: 49442.347656 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [91/5000] - Train Loss: 49993.282661 - Val Loss: 49415.968316 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [92/5000] - Train Loss: 49987.598090 - Val Loss: 49389.518663 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [93/5000] - Train Loss: 49987.689345 - Val Loss: 49363.110677 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [94/5000] - Train Loss: 49934.360569 - Val Loss: 49336.458767 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [95/5000] - Train Loss: 50019.926324 - Val Loss: 49309.733507 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [96/5000] - Train Loss: 49890.792318 - Val Loss: 49283.121528 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [97/5000] - Train Loss: 49935.605794 - Val Loss: 49256.489583 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [98/5000] - Train Loss: 49893.311523 - Val Loss: 49229.693576 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [99/5000] - Train Loss: 49877.262153 - Val Loss: 49202.811198 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [100/5000] - Train Loss: 49828.301541 - Val Loss: 49175.865451 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [101/5000] - Train Loss: 49768.004557 - Val Loss: 49148.911024 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [102/5000] - Train Loss: 49737.628689 - Val Loss: 49121.967882 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [103/5000] - Train Loss: 49734.004557 - Val Loss: 49094.866753 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [104/5000] - Train Loss: 49652.995334 - Val Loss: 49067.664062 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [105/5000] - Train Loss: 49620.895508 - Val Loss: 49040.631944 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [106/5000] - Train Loss: 49608.951280 - Val Loss: 49013.300781 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [107/5000] - Train Loss: 49594.615994 - Val Loss: 48986.127170 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [108/5000] - Train Loss: 49527.549262 - Val Loss: 48958.839410 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [109/5000] - Train Loss: 49571.406033 - Val Loss: 48931.448351 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [110/5000] - Train Loss: 49506.401042 - Val Loss: 48903.983073 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [111/5000] - Train Loss: 49544.599609 - Val Loss: 48876.530382 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [112/5000] - Train Loss: 49500.009006 - Val Loss: 48848.973090 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [113/5000] - Train Loss: 49465.283746 - Val Loss: 48821.419705 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [114/5000] - Train Loss: 49386.408963 - Val Loss: 48793.820312 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [115/5000] - Train Loss: 49413.485569 - Val Loss: 48766.089844 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [116/5000] - Train Loss: 49350.437174 - Val Loss: 48738.424913 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [117/5000] - Train Loss: 49323.087891 - Val Loss: 48710.575521 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [118/5000] - Train Loss: 49355.638672 - Val Loss: 48682.868056 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [119/5000] - Train Loss: 49292.384115 - Val Loss: 48654.869358 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [120/5000] - Train Loss: 49272.976454 - Val Loss: 48626.873698 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [121/5000] - Train Loss: 49154.239583 - Val Loss: 48598.964844 - Time: 1.38s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [122/5000] - Train Loss: 49199.638997 - Val Loss: 48570.905382 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [123/5000] - Train Loss: 49197.581272 - Val Loss: 48542.799045 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [124/5000] - Train Loss: 49183.140625 - Val Loss: 48514.550781 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [125/5000] - Train Loss: 49160.077365 - Val Loss: 48486.370660 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [126/5000] - Train Loss: 49082.381293 - Val Loss: 48458.238281 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [127/5000] - Train Loss: 49009.252604 - Val Loss: 48430.040799 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [128/5000] - Train Loss: 49100.750000 - Val Loss: 48401.650174 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [129/5000] - Train Loss: 49023.475911 - Val Loss: 48373.198351 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [130/5000] - Train Loss: 48977.577257 - Val Loss: 48344.747396 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [131/5000] - Train Loss: 48941.992730 - Val Loss: 48316.290365 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [132/5000] - Train Loss: 48941.196940 - Val Loss: 48287.884983 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [133/5000] - Train Loss: 48862.858398 - Val Loss: 48259.392361 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [134/5000] - Train Loss: 48845.772678 - Val Loss: 48230.528646 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [135/5000] - Train Loss: 48787.599718 - Val Loss: 48201.848090 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [136/5000] - Train Loss: 48734.552734 - Val Loss: 48173.300781 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [137/5000] - Train Loss: 48786.890842 - Val Loss: 48144.362413 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [138/5000] - Train Loss: 48732.135851 - Val Loss: 48115.605035 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [139/5000] - Train Loss: 48699.288845 - Val Loss: 48086.737847 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [140/5000] - Train Loss: 48654.674154 - Val Loss: 48058.034288 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [141/5000] - Train Loss: 48606.138889 - Val Loss: 48029.122396 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [142/5000] - Train Loss: 48662.181424 - Val Loss: 47999.835069 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [143/5000] - Train Loss: 48576.537001 - Val Loss: 47970.925347 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [144/5000] - Train Loss: 48610.685872 - Val Loss: 47941.670139 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [145/5000] - Train Loss: 48527.828451 - Val Loss: 47912.405816 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [146/5000] - Train Loss: 48557.997613 - Val Loss: 47883.344618 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [147/5000] - Train Loss: 48450.947700 - Val Loss: 47854.140625 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [148/5000] - Train Loss: 48427.684245 - Val Loss: 47824.681858 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [149/5000] - Train Loss: 48417.082791 - Val Loss: 47795.355035 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [150/5000] - Train Loss: 48424.046441 - Val Loss: 47766.157118 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [151/5000] - Train Loss: 48394.273546 - Val Loss: 47736.622396 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [152/5000] - Train Loss: 48348.901584 - Val Loss: 47707.178819 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [153/5000] - Train Loss: 48328.113715 - Val Loss: 47677.828559 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [154/5000] - Train Loss: 48261.319444 - Val Loss: 47648.005642 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [155/5000] - Train Loss: 48244.570312 - Val Loss: 47618.536024 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [156/5000] - Train Loss: 48263.620551 - Val Loss: 47588.866753 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [157/5000] - Train Loss: 48194.951931 - Val Loss: 47559.052083 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [158/5000] - Train Loss: 48156.432943 - Val Loss: 47529.553819 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [159/5000] - Train Loss: 48132.967556 - Val Loss: 47499.412760 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [160/5000] - Train Loss: 48080.105686 - Val Loss: 47469.465712 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [161/5000] - Train Loss: 47993.159505 - Val Loss: 47440.057292 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [162/5000] - Train Loss: 48113.120334 - Val Loss: 47410.019965 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [163/5000] - Train Loss: 47987.923611 - Val Loss: 47380.222222 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [164/5000] - Train Loss: 48003.465386 - Val Loss: 47350.037760 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [165/5000] - Train Loss: 47943.719727 - Val Loss: 47320.444444 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [166/5000] - Train Loss: 47942.627496 - Val Loss: 47290.024306 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [167/5000] - Train Loss: 47879.592122 - Val Loss: 47259.866319 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [168/5000] - Train Loss: 47921.150933 - Val Loss: 47229.641493 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [169/5000] - Train Loss: 47869.604492 - Val Loss: 47199.278646 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [170/5000] - Train Loss: 47808.669813 - Val Loss: 47168.979601 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [171/5000] - Train Loss: 47751.639648 - Val Loss: 47138.986111 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [172/5000] - Train Loss: 47756.027995 - Val Loss: 47108.496962 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [173/5000] - Train Loss: 47633.599067 - Val Loss: 47078.229601 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [174/5000] - Train Loss: 47686.560872 - Val Loss: 47047.635851 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [175/5000] - Train Loss: 47601.619683 - Val Loss: 47017.173177 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [176/5000] - Train Loss: 47592.906684 - Val Loss: 46986.894097 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [177/5000] - Train Loss: 47561.477865 - Val Loss: 46956.425781 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [178/5000] - Train Loss: 47545.047960 - Val Loss: 46925.876736 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [179/5000] - Train Loss: 47514.193576 - Val Loss: 46895.265625 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [180/5000] - Train Loss: 47507.032769 - Val Loss: 46864.627604 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [181/5000] - Train Loss: 47491.283095 - Val Loss: 46833.971354 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [182/5000] - Train Loss: 47411.695421 - Val Loss: 46803.416667 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [183/5000] - Train Loss: 47418.190104 - Val Loss: 46772.531250 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [184/5000] - Train Loss: 47365.212023 - Val Loss: 46742.050347 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [185/5000] - Train Loss: 47359.742188 - Val Loss: 46711.071181 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [186/5000] - Train Loss: 47314.107205 - Val Loss: 46679.937500 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [187/5000] - Train Loss: 47304.002713 - Val Loss: 46649.213542 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [188/5000] - Train Loss: 47217.033854 - Val Loss: 46618.339844 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [189/5000] - Train Loss: 47209.298937 - Val Loss: 46586.882378 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [190/5000] - Train Loss: 47207.591797 - Val Loss: 46556.210069 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [191/5000] - Train Loss: 47163.500217 - Val Loss: 46524.942708 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [192/5000] - Train Loss: 47091.893880 - Val Loss: 46493.622396 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [193/5000] - Train Loss: 47161.095920 - Val Loss: 46462.832899 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [194/5000] - Train Loss: 47087.480252 - Val Loss: 46431.300781 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [195/5000] - Train Loss: 47044.091797 - Val Loss: 46400.319444 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [196/5000] - Train Loss: 46979.475369 - Val Loss: 46369.005208 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [197/5000] - Train Loss: 46953.235135 - Val Loss: 46337.824653 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [198/5000] - Train Loss: 46962.870660 - Val Loss: 46306.421875 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [199/5000] - Train Loss: 46905.645725 - Val Loss: 46274.998264 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [200/5000] - Train Loss: 46876.872613 - Val Loss: 46243.306858 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [201/5000] - Train Loss: 46879.937066 - Val Loss: 46211.921007 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [202/5000] - Train Loss: 46792.575412 - Val Loss: 46180.465712 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [203/5000] - Train Loss: 46825.129340 - Val Loss: 46148.779080 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [204/5000] - Train Loss: 46701.612522 - Val Loss: 46117.082031 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [205/5000] - Train Loss: 46744.508898 - Val Loss: 46085.845052 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [206/5000] - Train Loss: 46671.982856 - Val Loss: 46054.068576 - Time: 1.39s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [207/5000] - Train Loss: 46683.955729 - Val Loss: 46022.319878 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [208/5000] - Train Loss: 46610.113390 - Val Loss: 45990.259115 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [209/5000] - Train Loss: 46609.758355 - Val Loss: 45958.689670 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [210/5000] - Train Loss: 46627.237630 - Val Loss: 45927.139757 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [211/5000] - Train Loss: 46502.723090 - Val Loss: 45895.678385 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [212/5000] - Train Loss: 46507.004991 - Val Loss: 45863.724826 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [213/5000] - Train Loss: 46497.569444 - Val Loss: 45831.727865 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [214/5000] - Train Loss: 46492.774957 - Val Loss: 45800.338542 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [215/5000] - Train Loss: 46395.282661 - Val Loss: 45767.930122 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [216/5000] - Train Loss: 46380.799588 - Val Loss: 45735.371528 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [217/5000] - Train Loss: 46386.561957 - Val Loss: 45703.853299 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [218/5000] - Train Loss: 46350.031141 - Val Loss: 45672.068576 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [219/5000] - Train Loss: 46279.210720 - Val Loss: 45639.410156 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [220/5000] - Train Loss: 46315.754883 - Val Loss: 45607.336372 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [221/5000] - Train Loss: 46228.251411 - Val Loss: 45574.973958 - Time: 1.38s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [222/5000] - Train Loss: 46152.782010 - Val Loss: 45542.924479 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [223/5000] - Train Loss: 46075.449219 - Val Loss: 45510.819878 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [224/5000] - Train Loss: 46134.100043 - Val Loss: 45478.833767 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [225/5000] - Train Loss: 46042.620877 - Val Loss: 45446.529948 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [226/5000] - Train Loss: 46037.427951 - Val Loss: 45414.086372 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [227/5000] - Train Loss: 46025.263672 - Val Loss: 45381.989583 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [228/5000] - Train Loss: 46026.375109 - Val Loss: 45349.685330 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [229/5000] - Train Loss: 45975.442708 - Val Loss: 45316.744358 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [230/5000] - Train Loss: 45930.523329 - Val Loss: 45284.654080 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [231/5000] - Train Loss: 45858.624023 - Val Loss: 45252.575521 - Time: 1.39s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [232/5000] - Train Loss: 45838.840169 - Val Loss: 45220.015191 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [233/5000] - Train Loss: 45810.180339 - Val Loss: 45187.564670 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [234/5000] - Train Loss: 45804.783203 - Val Loss: 45154.832899 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [235/5000] - Train Loss: 45783.156359 - Val Loss: 45121.826823 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [236/5000] - Train Loss: 45814.509983 - Val Loss: 45089.748264 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [237/5000] - Train Loss: 45732.964627 - Val Loss: 45056.877170 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [238/5000] - Train Loss: 45698.741753 - Val Loss: 45023.990451 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [239/5000] - Train Loss: 45662.444770 - Val Loss: 44991.600260 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [240/5000] - Train Loss: 45602.288520 - Val Loss: 44959.108941 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [241/5000] - Train Loss: 45596.929470 - Val Loss: 44925.769097 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [242/5000] - Train Loss: 45599.712023 - Val Loss: 44893.164497 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [243/5000] - Train Loss: 45539.543294 - Val Loss: 44860.476997 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [244/5000] - Train Loss: 45479.399740 - Val Loss: 44827.911024 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [245/5000] - Train Loss: 45378.860460 - Val Loss: 44794.932726 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [246/5000] - Train Loss: 45367.535482 - Val Loss: 44761.743490 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [247/5000] - Train Loss: 45333.765516 - Val Loss: 44729.509983 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [248/5000] - Train Loss: 45347.851454 - Val Loss: 44695.962240 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [249/5000] - Train Loss: 45267.711372 - Val Loss: 44663.112413 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [250/5000] - Train Loss: 45250.405273 - Val Loss: 44629.996528 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [251/5000] - Train Loss: 45220.109266 - Val Loss: 44597.034722 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [252/5000] - Train Loss: 45210.367947 - Val Loss: 44563.091146 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [253/5000] - Train Loss: 45214.301215 - Val Loss: 44530.255208 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [254/5000] - Train Loss: 45109.458442 - Val Loss: 44497.037760 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [255/5000] - Train Loss: 45138.058377 - Val Loss: 44464.145399 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [256/5000] - Train Loss: 45102.631185 - Val Loss: 44431.069444 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [257/5000] - Train Loss: 45023.222005 - Val Loss: 44397.895399 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [258/5000] - Train Loss: 44973.724175 - Val Loss: 44365.451823 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [259/5000] - Train Loss: 44958.296549 - Val Loss: 44332.579861 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [260/5000] - Train Loss: 44975.566081 - Val Loss: 44298.564236 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [261/5000] - Train Loss: 44954.307075 - Val Loss: 44264.863281 - Time: 1.39s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [262/5000] - Train Loss: 44948.275933 - Val Loss: 44232.049913 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [263/5000] - Train Loss: 44939.486111 - Val Loss: 44198.741319 - Time: 1.44s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [264/5000] - Train Loss: 44813.399306 - Val Loss: 44164.800347 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [265/5000] - Train Loss: 44814.363498 - Val Loss: 44131.878906 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [266/5000] - Train Loss: 44700.097439 - Val Loss: 44097.970052 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [267/5000] - Train Loss: 44719.195964 - Val Loss: 44064.572049 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [268/5000] - Train Loss: 44673.123806 - Val Loss: 44031.225260 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [269/5000] - Train Loss: 44701.765842 - Val Loss: 43997.511719 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [270/5000] - Train Loss: 44590.229926 - Val Loss: 43964.308160 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [271/5000] - Train Loss: 44538.666450 - Val Loss: 43930.444444 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [272/5000] - Train Loss: 44567.929145 - Val Loss: 43896.669271 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [273/5000] - Train Loss: 44534.512912 - Val Loss: 43863.362413 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [274/5000] - Train Loss: 44459.878689 - Val Loss: 43829.776910 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [275/5000] - Train Loss: 44469.152669 - Val Loss: 43796.419705 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [276/5000] - Train Loss: 44379.748264 - Val Loss: 43762.332031 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [277/5000] - Train Loss: 44381.761068 - Val Loss: 43728.949653 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [278/5000] - Train Loss: 44356.718967 - Val Loss: 43695.306858 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [279/5000] - Train Loss: 44304.241645 - Val Loss: 43662.138021 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [280/5000] - Train Loss: 44245.999132 - Val Loss: 43627.982205 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [281/5000] - Train Loss: 44239.769206 - Val Loss: 43595.145833 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [282/5000] - Train Loss: 44182.887478 - Val Loss: 43560.767361 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [283/5000] - Train Loss: 44153.793620 - Val Loss: 43526.720486 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [284/5000] - Train Loss: 44123.192600 - Val Loss: 43492.807292 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [285/5000] - Train Loss: 44166.764757 - Val Loss: 43458.993056 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [286/5000] - Train Loss: 44110.060655 - Val Loss: 43425.171007 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [287/5000] - Train Loss: 44089.880425 - Val Loss: 43391.839410 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [288/5000] - Train Loss: 44006.203451 - Val Loss: 43357.654948 - Time: 1.41s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [289/5000] - Train Loss: 43974.542643 - Val Loss: 43323.082465 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [290/5000] - Train Loss: 43973.204319 - Val Loss: 43288.997830 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [291/5000] - Train Loss: 43864.420573 - Val Loss: 43255.570312 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [292/5000] - Train Loss: 43845.839410 - Val Loss: 43221.064670 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [293/5000] - Train Loss: 43846.542426 - Val Loss: 43187.486111 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [294/5000] - Train Loss: 43805.116319 - Val Loss: 43153.175347 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [295/5000] - Train Loss: 43759.465386 - Val Loss: 43119.442708 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [296/5000] - Train Loss: 43656.338976 - Val Loss: 43085.157118 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [297/5000] - Train Loss: 43698.895399 - Val Loss: 43051.670573 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [298/5000] - Train Loss: 43735.115777 - Val Loss: 43016.875000 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [299/5000] - Train Loss: 43617.705838 - Val Loss: 42983.532118 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [300/5000] - Train Loss: 43602.548503 - Val Loss: 42948.144965 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [301/5000] - Train Loss: 43583.695638 - Val Loss: 42915.048611 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [302/5000] - Train Loss: 43565.770182 - Val Loss: 42880.840712 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [303/5000] - Train Loss: 43561.406250 - Val Loss: 42846.526910 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [304/5000] - Train Loss: 43489.545681 - Val Loss: 42811.895833 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [305/5000] - Train Loss: 43494.121962 - Val Loss: 42778.631944 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [306/5000] - Train Loss: 43392.133572 - Val Loss: 42743.885851 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [307/5000] - Train Loss: 43383.252387 - Val Loss: 42709.745226 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [308/5000] - Train Loss: 43337.370443 - Val Loss: 42675.445747 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [309/5000] - Train Loss: 43314.744792 - Val Loss: 42640.556858 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [310/5000] - Train Loss: 43252.167643 - Val Loss: 42606.158854 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [311/5000] - Train Loss: 43233.953993 - Val Loss: 42571.661024 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [312/5000] - Train Loss: 43149.383138 - Val Loss: 42537.838542 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [313/5000] - Train Loss: 43169.263672 - Val Loss: 42503.570312 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [314/5000] - Train Loss: 43148.349718 - Val Loss: 42468.187066 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [315/5000] - Train Loss: 43105.558485 - Val Loss: 42434.269097 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [316/5000] - Train Loss: 43050.240777 - Val Loss: 42399.595486 - Time: 1.38s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [317/5000] - Train Loss: 43037.768663 - Val Loss: 42365.052517 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [318/5000] - Train Loss: 42982.682943 - Val Loss: 42330.642361 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [319/5000] - Train Loss: 42935.831055 - Val Loss: 42296.533420 - Time: 1.62s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [320/5000] - Train Loss: 42891.137044 - Val Loss: 42261.398003 - Time: 1.79s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [321/5000] - Train Loss: 42868.144531 - Val Loss: 42227.689236 - Time: 1.84s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [322/5000] - Train Loss: 42884.024089 - Val Loss: 42193.749132 - Time: 1.77s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [323/5000] - Train Loss: 42780.073785 - Val Loss: 42158.629340 - Time: 1.85s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [324/5000] - Train Loss: 42749.563368 - Val Loss: 42124.760851 - Time: 1.87s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [325/5000] - Train Loss: 42752.505859 - Val Loss: 42089.923611 - Time: 1.69s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [326/5000] - Train Loss: 42699.703342 - Val Loss: 42054.638021 - Time: 1.87s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [327/5000] - Train Loss: 42687.911567 - Val Loss: 42020.924479 - Time: 1.78s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [328/5000] - Train Loss: 42656.310221 - Val Loss: 41984.952691 - Time: 1.86s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [329/5000] - Train Loss: 42659.416341 - Val Loss: 41950.871962 - Time: 1.72s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [330/5000] - Train Loss: 42610.871419 - Val Loss: 41916.776042 - Time: 1.69s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [331/5000] - Train Loss: 42538.604275 - Val Loss: 41882.201389 - Time: 1.91s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [332/5000] - Train Loss: 42564.669488 - Val Loss: 41848.028646 - Time: 1.72s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [333/5000] - Train Loss: 42429.591688 - Val Loss: 41812.392795 - Time: 1.81s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [334/5000] - Train Loss: 42498.675890 - Val Loss: 41777.886285 - Time: 1.73s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [335/5000] - Train Loss: 42404.449110 - Val Loss: 41743.708767 - Time: 1.84s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [336/5000] - Train Loss: 42346.563368 - Val Loss: 41707.632378 - Time: 1.83s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [337/5000] - Train Loss: 42329.139431 - Val Loss: 41673.811632 - Time: 1.73s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [338/5000] - Train Loss: 42294.112847 - Val Loss: 41638.521267 - Time: 1.91s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [339/5000] - Train Loss: 42312.061198 - Val Loss: 41604.358073 - Time: 1.72s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [340/5000] - Train Loss: 42238.667860 - Val Loss: 41569.926649 - Time: 1.75s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [341/5000] - Train Loss: 42247.835286 - Val Loss: 41534.705729 - Time: 1.75s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [342/5000] - Train Loss: 42174.559787 - Val Loss: 41500.207465 - Time: 1.76s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [343/5000] - Train Loss: 42122.304253 - Val Loss: 41465.325955 - Time: 1.90s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [344/5000] - Train Loss: 42054.122830 - Val Loss: 41430.617188 - Time: 1.83s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [345/5000] - Train Loss: 42040.629340 - Val Loss: 41394.682726 - Time: 1.73s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [346/5000] - Train Loss: 41948.228624 - Val Loss: 41360.440538 - Time: 1.96s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [347/5000] - Train Loss: 41926.999674 - Val Loss: 41325.621528 - Time: 1.81s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [348/5000] - Train Loss: 42002.262695 - Val Loss: 41290.158420 - Time: 1.98s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [349/5000] - Train Loss: 41930.211372 - Val Loss: 41255.868056 - Time: 1.84s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [350/5000] - Train Loss: 41859.465495 - Val Loss: 41220.794271 - Time: 1.86s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [351/5000] - Train Loss: 41824.965386 - Val Loss: 41185.752170 - Time: 1.91s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [352/5000] - Train Loss: 41808.450195 - Val Loss: 41152.235243 - Time: 1.77s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [353/5000] - Train Loss: 41813.955838 - Val Loss: 41117.598958 - Time: 2.00s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [354/5000] - Train Loss: 41744.741211 - Val Loss: 41081.271267 - Time: 1.89s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [355/5000] - Train Loss: 41662.901259 - Val Loss: 41046.361979 - Time: 1.86s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [356/5000] - Train Loss: 41712.101562 - Val Loss: 41011.728733 - Time: 1.94s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [357/5000] - Train Loss: 41631.621094 - Val Loss: 40977.238715 - Time: 1.54s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [358/5000] - Train Loss: 41610.536784 - Val Loss: 40941.406250 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [359/5000] - Train Loss: 41517.470703 - Val Loss: 40906.733073 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [360/5000] - Train Loss: 41568.465386 - Val Loss: 40872.625868 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [361/5000] - Train Loss: 41517.455838 - Val Loss: 40837.873264 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [362/5000] - Train Loss: 41467.589193 - Val Loss: 40803.496962 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [363/5000] - Train Loss: 41454.712999 - Val Loss: 40768.686632 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [364/5000] - Train Loss: 41399.794379 - Val Loss: 40734.395399 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [365/5000] - Train Loss: 41378.961046 - Val Loss: 40697.482205 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [366/5000] - Train Loss: 41301.363715 - Val Loss: 40663.592882 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [367/5000] - Train Loss: 41294.204427 - Val Loss: 40628.609375 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [368/5000] - Train Loss: 41268.759549 - Val Loss: 40593.194444 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [369/5000] - Train Loss: 41231.685330 - Val Loss: 40558.544705 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [370/5000] - Train Loss: 41214.281793 - Val Loss: 40523.414931 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [371/5000] - Train Loss: 41188.706163 - Val Loss: 40487.051649 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [372/5000] - Train Loss: 41135.815864 - Val Loss: 40452.108073 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [373/5000] - Train Loss: 41113.313585 - Val Loss: 40417.865451 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [374/5000] - Train Loss: 41062.480143 - Val Loss: 40381.802951 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [375/5000] - Train Loss: 41000.481879 - Val Loss: 40348.423611 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [376/5000] - Train Loss: 40970.979601 - Val Loss: 40312.801215 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [377/5000] - Train Loss: 40901.227539 - Val Loss: 40276.483073 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [378/5000] - Train Loss: 40966.178060 - Val Loss: 40240.931858 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [379/5000] - Train Loss: 40885.361220 - Val Loss: 40207.881076 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [380/5000] - Train Loss: 40879.026801 - Val Loss: 40172.428819 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [381/5000] - Train Loss: 40787.907552 - Val Loss: 40136.638021 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [382/5000] - Train Loss: 40765.499457 - Val Loss: 40101.092882 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [383/5000] - Train Loss: 40793.613064 - Val Loss: 40066.540365 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [384/5000] - Train Loss: 40705.178060 - Val Loss: 40029.778646 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [385/5000] - Train Loss: 40615.274523 - Val Loss: 39995.311198 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [386/5000] - Train Loss: 40616.999674 - Val Loss: 39960.546875 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [387/5000] - Train Loss: 40633.241536 - Val Loss: 39926.862413 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [388/5000] - Train Loss: 40574.931424 - Val Loss: 39892.499566 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [389/5000] - Train Loss: 40539.105143 - Val Loss: 39855.303819 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [390/5000] - Train Loss: 40447.018121 - Val Loss: 39821.120226 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [391/5000] - Train Loss: 40432.624674 - Val Loss: 39786.350694 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [392/5000] - Train Loss: 40424.218207 - Val Loss: 39751.958767 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [393/5000] - Train Loss: 40413.867188 - Val Loss: 39715.886285 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [394/5000] - Train Loss: 40351.569227 - Val Loss: 39681.242188 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [395/5000] - Train Loss: 40314.468533 - Val Loss: 39644.962240 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [396/5000] - Train Loss: 40279.962457 - Val Loss: 39609.368924 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [397/5000] - Train Loss: 40236.172092 - Val Loss: 39574.422309 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [398/5000] - Train Loss: 40145.348958 - Val Loss: 39540.153646 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [399/5000] - Train Loss: 40136.889648 - Val Loss: 39504.841146 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [400/5000] - Train Loss: 40165.170356 - Val Loss: 39469.180122 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [401/5000] - Train Loss: 40104.302192 - Val Loss: 39434.467448 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [402/5000] - Train Loss: 40069.579644 - Val Loss: 39399.594618 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [403/5000] - Train Loss: 39992.527886 - Val Loss: 39362.671875 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [404/5000] - Train Loss: 40001.262912 - Val Loss: 39328.746528 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [405/5000] - Train Loss: 39962.995334 - Val Loss: 39293.181858 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [406/5000] - Train Loss: 39943.391927 - Val Loss: 39257.358507 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [407/5000] - Train Loss: 39922.892253 - Val Loss: 39222.683594 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [408/5000] - Train Loss: 39812.993273 - Val Loss: 39189.252604 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [409/5000] - Train Loss: 39814.608507 - Val Loss: 39151.156250 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [410/5000] - Train Loss: 39781.922743 - Val Loss: 39117.410156 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [411/5000] - Train Loss: 39749.768880 - Val Loss: 39082.468750 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [412/5000] - Train Loss: 39760.601997 - Val Loss: 39047.516927 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [413/5000] - Train Loss: 39726.650499 - Val Loss: 39011.476562 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [414/5000] - Train Loss: 39702.875000 - Val Loss: 38976.634549 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [415/5000] - Train Loss: 39607.601237 - Val Loss: 38941.398872 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [416/5000] - Train Loss: 39552.109266 - Val Loss: 38905.555122 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [417/5000] - Train Loss: 39616.072700 - Val Loss: 38870.808594 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [418/5000] - Train Loss: 39459.952908 - Val Loss: 38836.542969 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [419/5000] - Train Loss: 39510.807617 - Val Loss: 38800.561632 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [420/5000] - Train Loss: 39482.869249 - Val Loss: 38765.142361 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [421/5000] - Train Loss: 39425.831163 - Val Loss: 38731.179688 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [422/5000] - Train Loss: 39398.270725 - Val Loss: 38694.757812 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [423/5000] - Train Loss: 39316.896701 - Val Loss: 38660.510851 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [424/5000] - Train Loss: 39255.409722 - Val Loss: 38625.557292 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [425/5000] - Train Loss: 39252.888997 - Val Loss: 38589.984809 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [426/5000] - Train Loss: 39245.333008 - Val Loss: 38553.952257 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [427/5000] - Train Loss: 39173.120660 - Val Loss: 38518.922309 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [428/5000] - Train Loss: 39138.678928 - Val Loss: 38483.718750 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [429/5000] - Train Loss: 39130.275608 - Val Loss: 38449.162326 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [430/5000] - Train Loss: 39097.155599 - Val Loss: 38413.433160 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [431/5000] - Train Loss: 39079.218641 - Val Loss: 38377.835938 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [432/5000] - Train Loss: 38988.949761 - Val Loss: 38342.264757 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [433/5000] - Train Loss: 39000.838216 - Val Loss: 38307.615451 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [434/5000] - Train Loss: 39002.215929 - Val Loss: 38272.759549 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [435/5000] - Train Loss: 38900.478841 - Val Loss: 38238.056424 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [436/5000] - Train Loss: 38878.338433 - Val Loss: 38202.008681 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [437/5000] - Train Loss: 38836.426975 - Val Loss: 38166.909722 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [438/5000] - Train Loss: 38804.070204 - Val Loss: 38131.258247 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [439/5000] - Train Loss: 38717.858290 - Val Loss: 38097.475260 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [440/5000] - Train Loss: 38733.816840 - Val Loss: 38061.428385 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [441/5000] - Train Loss: 38730.352105 - Val Loss: 38026.404948 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [442/5000] - Train Loss: 38691.140408 - Val Loss: 37991.434462 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [443/5000] - Train Loss: 38641.265191 - Val Loss: 37954.971354 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [444/5000] - Train Loss: 38615.367405 - Val Loss: 37920.379340 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [445/5000] - Train Loss: 38501.597222 - Val Loss: 37885.210069 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [446/5000] - Train Loss: 38585.242947 - Val Loss: 37851.144097 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [447/5000] - Train Loss: 38483.439019 - Val Loss: 37816.753038 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [448/5000] - Train Loss: 38478.720812 - Val Loss: 37781.658854 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [449/5000] - Train Loss: 38421.664931 - Val Loss: 37745.914497 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [450/5000] - Train Loss: 38386.246202 - Val Loss: 37711.947483 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [451/5000] - Train Loss: 38336.999240 - Val Loss: 37674.968316 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [452/5000] - Train Loss: 38365.195964 - Val Loss: 37640.541233 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [453/5000] - Train Loss: 38255.215820 - Val Loss: 37604.350694 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [454/5000] - Train Loss: 38258.351780 - Val Loss: 37570.562934 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [455/5000] - Train Loss: 38188.810655 - Val Loss: 37534.326389 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [456/5000] - Train Loss: 38234.795898 - Val Loss: 37500.583333 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [457/5000] - Train Loss: 38085.292101 - Val Loss: 37465.038628 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [458/5000] - Train Loss: 38100.147569 - Val Loss: 37432.779514 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [459/5000] - Train Loss: 38113.986003 - Val Loss: 37395.601562 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [460/5000] - Train Loss: 38007.241211 - Val Loss: 37360.554253 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [461/5000] - Train Loss: 38012.583550 - Val Loss: 37325.087240 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [462/5000] - Train Loss: 38003.701172 - Val Loss: 37289.621962 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [463/5000] - Train Loss: 37906.755751 - Val Loss: 37255.199219 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [464/5000] - Train Loss: 37925.281250 - Val Loss: 37219.039931 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [465/5000] - Train Loss: 37838.008138 - Val Loss: 37183.586806 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [466/5000] - Train Loss: 37778.842014 - Val Loss: 37149.248264 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [467/5000] - Train Loss: 37821.447591 - Val Loss: 37114.854167 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [468/5000] - Train Loss: 37741.086372 - Val Loss: 37079.759983 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [469/5000] - Train Loss: 37802.316406 - Val Loss: 37043.981337 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [470/5000] - Train Loss: 37693.723958 - Val Loss: 37009.501736 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [471/5000] - Train Loss: 37661.582357 - Val Loss: 36974.060330 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [472/5000] - Train Loss: 37663.233724 - Val Loss: 36940.692708 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [473/5000] - Train Loss: 37595.303928 - Val Loss: 36905.215712 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [474/5000] - Train Loss: 37531.530165 - Val Loss: 36872.475694 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [475/5000] - Train Loss: 37537.757053 - Val Loss: 36836.050347 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [476/5000] - Train Loss: 37451.372179 - Val Loss: 36799.811198 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [477/5000] - Train Loss: 37442.670247 - Val Loss: 36765.694444 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [478/5000] - Train Loss: 37429.307834 - Val Loss: 36730.462240 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [479/5000] - Train Loss: 37412.720161 - Val Loss: 36697.480035 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [480/5000] - Train Loss: 37351.464084 - Val Loss: 36660.989149 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [481/5000] - Train Loss: 37248.015082 - Val Loss: 36625.789931 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [482/5000] - Train Loss: 37379.886610 - Val Loss: 36593.421007 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [483/5000] - Train Loss: 37247.108724 - Val Loss: 36556.681424 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [484/5000] - Train Loss: 37223.180773 - Val Loss: 36519.709635 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [485/5000] - Train Loss: 37137.895074 - Val Loss: 36488.066840 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [486/5000] - Train Loss: 37134.314670 - Val Loss: 36451.796875 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [487/5000] - Train Loss: 37136.200304 - Val Loss: 36417.654080 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [488/5000] - Train Loss: 37034.445095 - Val Loss: 36382.674479 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [489/5000] - Train Loss: 37037.988824 - Val Loss: 36347.620226 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [490/5000] - Train Loss: 37005.210720 - Val Loss: 36312.620660 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [491/5000] - Train Loss: 36986.278863 - Val Loss: 36279.301649 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [492/5000] - Train Loss: 36928.894965 - Val Loss: 36244.532552 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [493/5000] - Train Loss: 36876.489800 - Val Loss: 36210.127604 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [494/5000] - Train Loss: 36902.301107 - Val Loss: 36174.771267 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [495/5000] - Train Loss: 36836.738932 - Val Loss: 36139.330729 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [496/5000] - Train Loss: 36799.441949 - Val Loss: 36104.872830 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [497/5000] - Train Loss: 36776.793728 - Val Loss: 36073.755208 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [498/5000] - Train Loss: 36697.945855 - Val Loss: 36036.696181 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [499/5000] - Train Loss: 36734.949110 - Val Loss: 36003.353299 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [500/5000] - Train Loss: 36675.191840 - Val Loss: 35968.699653 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [501/5000] - Train Loss: 36597.069878 - Val Loss: 35932.388455 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [502/5000] - Train Loss: 36592.860569 - Val Loss: 35898.234809 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [503/5000] - Train Loss: 36520.208550 - Val Loss: 35862.963976 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [504/5000] - Train Loss: 36564.288954 - Val Loss: 35830.165799 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [505/5000] - Train Loss: 36472.741536 - Val Loss: 35795.755642 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [506/5000] - Train Loss: 36443.519965 - Val Loss: 35759.339410 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [507/5000] - Train Loss: 36343.775825 - Val Loss: 35724.895833 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [508/5000] - Train Loss: 36397.243598 - Val Loss: 35691.001302 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [509/5000] - Train Loss: 36373.018880 - Val Loss: 35656.750434 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [510/5000] - Train Loss: 36405.610243 - Val Loss: 35622.286024 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [511/5000] - Train Loss: 36254.435547 - Val Loss: 35586.920139 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [512/5000] - Train Loss: 36173.513780 - Val Loss: 35551.467014 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [513/5000] - Train Loss: 36220.957357 - Val Loss: 35517.082899 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [514/5000] - Train Loss: 36191.229709 - Val Loss: 35485.099826 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [515/5000] - Train Loss: 36121.831272 - Val Loss: 35449.071615 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [516/5000] - Train Loss: 36120.637370 - Val Loss: 35413.914062 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [517/5000] - Train Loss: 36097.973199 - Val Loss: 35381.544705 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [518/5000] - Train Loss: 36014.218207 - Val Loss: 35345.224392 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [519/5000] - Train Loss: 35974.394314 - Val Loss: 35311.075955 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [520/5000] - Train Loss: 35938.446181 - Val Loss: 35275.507378 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [521/5000] - Train Loss: 35943.995551 - Val Loss: 35242.779080 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [522/5000] - Train Loss: 35884.888997 - Val Loss: 35207.865017 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [523/5000] - Train Loss: 35867.232639 - Val Loss: 35174.793403 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [524/5000] - Train Loss: 35894.972114 - Val Loss: 35139.023872 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [525/5000] - Train Loss: 35813.384115 - Val Loss: 35103.184896 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [526/5000] - Train Loss: 35732.095052 - Val Loss: 35072.606337 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [527/5000] - Train Loss: 35791.044379 - Val Loss: 35036.901476 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [528/5000] - Train Loss: 35700.593316 - Val Loss: 35003.710069 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [529/5000] - Train Loss: 35683.574436 - Val Loss: 34968.676215 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [530/5000] - Train Loss: 35634.106662 - Val Loss: 34935.524306 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [531/5000] - Train Loss: 35637.520616 - Val Loss: 34899.560764 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [532/5000] - Train Loss: 35560.925022 - Val Loss: 34869.939236 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [533/5000] - Train Loss: 35567.004774 - Val Loss: 34831.909288 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [534/5000] - Train Loss: 35494.748264 - Val Loss: 34799.803385 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [535/5000] - Train Loss: 35480.671658 - Val Loss: 34764.921875 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [536/5000] - Train Loss: 35469.424262 - Val Loss: 34732.067708 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [537/5000] - Train Loss: 35490.070312 - Val Loss: 34698.378906 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [538/5000] - Train Loss: 35377.257053 - Val Loss: 34663.329861 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [539/5000] - Train Loss: 35287.777669 - Val Loss: 34627.031250 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [540/5000] - Train Loss: 35327.212782 - Val Loss: 34594.204210 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [541/5000] - Train Loss: 35305.486979 - Val Loss: 34561.763889 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [542/5000] - Train Loss: 35215.711697 - Val Loss: 34528.032552 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [543/5000] - Train Loss: 35185.326931 - Val Loss: 34494.384549 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [544/5000] - Train Loss: 35167.842556 - Val Loss: 34460.937934 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [545/5000] - Train Loss: 35079.330132 - Val Loss: 34424.484809 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [546/5000] - Train Loss: 35079.757053 - Val Loss: 34389.807509 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [547/5000] - Train Loss: 35099.281467 - Val Loss: 34357.220052 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [548/5000] - Train Loss: 35056.218533 - Val Loss: 34322.018663 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [549/5000] - Train Loss: 35019.662001 - Val Loss: 34287.725694 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [550/5000] - Train Loss: 34936.597114 - Val Loss: 34253.882378 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [551/5000] - Train Loss: 34921.634440 - Val Loss: 34221.604818 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [552/5000] - Train Loss: 34903.556098 - Val Loss: 34187.674045 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [553/5000] - Train Loss: 34843.863444 - Val Loss: 34155.217014 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [554/5000] - Train Loss: 34770.657444 - Val Loss: 34119.076389 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [555/5000] - Train Loss: 34782.937609 - Val Loss: 34086.255642 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [556/5000] - Train Loss: 34757.524197 - Val Loss: 34051.827040 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [557/5000] - Train Loss: 34761.354167 - Val Loss: 34016.657986 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [558/5000] - Train Loss: 34702.388780 - Val Loss: 33984.229601 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [559/5000] - Train Loss: 34658.807292 - Val Loss: 33952.347656 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [560/5000] - Train Loss: 34609.225369 - Val Loss: 33915.744141 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [561/5000] - Train Loss: 34604.696723 - Val Loss: 33885.379340 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [562/5000] - Train Loss: 34617.866753 - Val Loss: 33848.522569 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [563/5000] - Train Loss: 34494.826714 - Val Loss: 33815.382812 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [564/5000] - Train Loss: 34491.002062 - Val Loss: 33781.624132 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [565/5000] - Train Loss: 34431.046387 - Val Loss: 33747.953993 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [566/5000] - Train Loss: 34415.409180 - Val Loss: 33715.168837 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [567/5000] - Train Loss: 34405.758247 - Val Loss: 33680.661892 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [568/5000] - Train Loss: 34357.784505 - Val Loss: 33644.705078 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [569/5000] - Train Loss: 34283.852648 - Val Loss: 33615.542101 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [570/5000] - Train Loss: 34274.347765 - Val Loss: 33581.560764 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [571/5000] - Train Loss: 34240.571940 - Val Loss: 33547.702691 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [572/5000] - Train Loss: 34215.985189 - Val Loss: 33512.803168 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [573/5000] - Train Loss: 34175.838433 - Val Loss: 33479.463325 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [574/5000] - Train Loss: 34196.000434 - Val Loss: 33446.240451 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [575/5000] - Train Loss: 34140.890571 - Val Loss: 33411.750434 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [576/5000] - Train Loss: 34050.905165 - Val Loss: 33380.813151 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [577/5000] - Train Loss: 34068.232476 - Val Loss: 33344.908854 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [578/5000] - Train Loss: 34027.859592 - Val Loss: 33311.597222 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [579/5000] - Train Loss: 33999.519097 - Val Loss: 33280.166233 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [580/5000] - Train Loss: 33952.187934 - Val Loss: 33244.421441 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [581/5000] - Train Loss: 33952.601454 - Val Loss: 33210.815104 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [582/5000] - Train Loss: 33892.222548 - Val Loss: 33178.948134 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [583/5000] - Train Loss: 33881.753255 - Val Loss: 33146.725911 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [584/5000] - Train Loss: 33830.685330 - Val Loss: 33111.714410 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [585/5000] - Train Loss: 33809.250597 - Val Loss: 33078.350694 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [586/5000] - Train Loss: 33775.213487 - Val Loss: 33043.948134 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [587/5000] - Train Loss: 33784.667046 - Val Loss: 33011.239366 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [588/5000] - Train Loss: 33743.753038 - Val Loss: 32980.026259 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [589/5000] - Train Loss: 33663.368652 - Val Loss: 32946.959635 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [590/5000] - Train Loss: 33633.025825 - Val Loss: 32912.366102 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [591/5000] - Train Loss: 33589.310004 - Val Loss: 32879.851780 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [592/5000] - Train Loss: 33564.896105 - Val Loss: 32844.967448 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [593/5000] - Train Loss: 33520.086372 - Val Loss: 32814.046007 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [594/5000] - Train Loss: 33504.648112 - Val Loss: 32780.270833 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [595/5000] - Train Loss: 33479.424696 - Val Loss: 32746.930339 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [596/5000] - Train Loss: 33409.065430 - Val Loss: 32711.235677 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [597/5000] - Train Loss: 33403.124295 - Val Loss: 32680.093533 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [598/5000] - Train Loss: 33380.947700 - Val Loss: 32649.188151 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [599/5000] - Train Loss: 33297.438205 - Val Loss: 32617.237196 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [600/5000] - Train Loss: 33295.703288 - Val Loss: 32584.565755 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [601/5000] - Train Loss: 33268.550836 - Val Loss: 32550.646484 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [602/5000] - Train Loss: 33296.357259 - Val Loss: 32518.341797 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [603/5000] - Train Loss: 33167.542480 - Val Loss: 32484.741753 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [604/5000] - Train Loss: 33174.314616 - Val Loss: 32451.010417 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [605/5000] - Train Loss: 33175.223470 - Val Loss: 32416.594618 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [606/5000] - Train Loss: 33104.122233 - Val Loss: 32383.537760 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [607/5000] - Train Loss: 33068.153863 - Val Loss: 32351.891059 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [608/5000] - Train Loss: 33014.276855 - Val Loss: 32320.610894 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [609/5000] - Train Loss: 33001.498752 - Val Loss: 32288.115451 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [610/5000] - Train Loss: 32969.674750 - Val Loss: 32251.626085 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [611/5000] - Train Loss: 32960.732910 - Val Loss: 32219.791667 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [612/5000] - Train Loss: 32933.583116 - Val Loss: 32190.304470 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [613/5000] - Train Loss: 32933.449382 - Val Loss: 32157.289497 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [614/5000] - Train Loss: 32835.764540 - Val Loss: 32121.634549 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [615/5000] - Train Loss: 32807.709201 - Val Loss: 32091.954861 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [616/5000] - Train Loss: 32786.468913 - Val Loss: 32058.248264 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [617/5000] - Train Loss: 32755.714952 - Val Loss: 32024.462891 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [618/5000] - Train Loss: 32735.350043 - Val Loss: 31991.042318 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [619/5000] - Train Loss: 32648.422038 - Val Loss: 31957.614800 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [620/5000] - Train Loss: 32635.321235 - Val Loss: 31926.347222 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [621/5000] - Train Loss: 32591.699382 - Val Loss: 31895.571832 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [622/5000] - Train Loss: 32595.513021 - Val Loss: 31864.520182 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [623/5000] - Train Loss: 32606.126682 - Val Loss: 31831.760634 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [624/5000] - Train Loss: 32513.903375 - Val Loss: 31799.416233 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [625/5000] - Train Loss: 32471.444987 - Val Loss: 31765.810981 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [626/5000] - Train Loss: 32467.296984 - Val Loss: 31735.715061 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [627/5000] - Train Loss: 32412.655436 - Val Loss: 31700.145833 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [628/5000] - Train Loss: 32397.575358 - Val Loss: 31670.258681 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [629/5000] - Train Loss: 32339.568414 - Val Loss: 31637.116970 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [630/5000] - Train Loss: 32338.953939 - Val Loss: 31605.223090 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [631/5000] - Train Loss: 32287.114258 - Val Loss: 31571.261719 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [632/5000] - Train Loss: 32297.605089 - Val Loss: 31540.192925 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [633/5000] - Train Loss: 32242.854058 - Val Loss: 31508.153429 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [634/5000] - Train Loss: 32191.673448 - Val Loss: 31473.530816 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [635/5000] - Train Loss: 32184.205132 - Val Loss: 31445.023003 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [636/5000] - Train Loss: 32156.348958 - Val Loss: 31408.407552 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [637/5000] - Train Loss: 32158.795030 - Val Loss: 31379.809462 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [638/5000] - Train Loss: 32121.541016 - Val Loss: 31349.000217 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [639/5000] - Train Loss: 32088.365289 - Val Loss: 31312.984592 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [640/5000] - Train Loss: 32021.838162 - Val Loss: 31280.921007 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [641/5000] - Train Loss: 32041.881619 - Val Loss: 31250.062066 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [642/5000] - Train Loss: 31989.169705 - Val Loss: 31218.345920 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [643/5000] - Train Loss: 31933.192980 - Val Loss: 31183.583116 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [644/5000] - Train Loss: 31865.076606 - Val Loss: 31152.083984 - Time: 1.15s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [645/5000] - Train Loss: 31852.221571 - Val Loss: 31121.349175 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [646/5000] - Train Loss: 31850.608832 - Val Loss: 31086.058160 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [647/5000] - Train Loss: 31775.365885 - Val Loss: 31055.208984 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [648/5000] - Train Loss: 31738.086209 - Val Loss: 31024.162543 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [649/5000] - Train Loss: 31733.294217 - Val Loss: 30993.119358 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [650/5000] - Train Loss: 31673.115777 - Val Loss: 30959.423177 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [651/5000] - Train Loss: 31684.810059 - Val Loss: 30927.655165 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [652/5000] - Train Loss: 31668.771484 - Val Loss: 30904.146267 - Time: 1.16s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [653/5000] - Train Loss: 31595.126682 - Val Loss: 30871.818576 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [654/5000] - Train Loss: 31577.792046 - Val Loss: 30839.153646 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [655/5000] - Train Loss: 31588.213704 - Val Loss: 30802.963976 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [656/5000] - Train Loss: 31522.934028 - Val Loss: 30773.483941 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [657/5000] - Train Loss: 31485.358290 - Val Loss: 30741.190972 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [658/5000] - Train Loss: 31427.737359 - Val Loss: 30708.227214 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [659/5000] - Train Loss: 31436.260037 - Val Loss: 30680.280816 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [660/5000] - Train Loss: 31410.409776 - Val Loss: 30644.073568 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [661/5000] - Train Loss: 31463.128581 - Val Loss: 30614.105035 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [662/5000] - Train Loss: 31380.929633 - Val Loss: 30580.964193 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [663/5000] - Train Loss: 31294.513346 - Val Loss: 30549.973958 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [664/5000] - Train Loss: 31270.217014 - Val Loss: 30521.528429 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [665/5000] - Train Loss: 31204.179633 - Val Loss: 30488.035156 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [666/5000] - Train Loss: 31212.853895 - Val Loss: 30458.673177 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [667/5000] - Train Loss: 31171.864963 - Val Loss: 30428.877821 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [668/5000] - Train Loss: 31172.132216 - Val Loss: 30394.646484 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [669/5000] - Train Loss: 31165.579047 - Val Loss: 30360.973307 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [670/5000] - Train Loss: 31126.368544 - Val Loss: 30333.827257 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [671/5000] - Train Loss: 31084.961697 - Val Loss: 30299.729384 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [672/5000] - Train Loss: 31067.183105 - Val Loss: 30269.231771 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [673/5000] - Train Loss: 30991.359646 - Val Loss: 30235.842882 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [674/5000] - Train Loss: 30945.185438 - Val Loss: 30207.172743 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [675/5000] - Train Loss: 30918.612305 - Val Loss: 30174.015625 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [676/5000] - Train Loss: 30917.496365 - Val Loss: 30144.163194 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [677/5000] - Train Loss: 30916.003526 - Val Loss: 30109.796441 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [678/5000] - Train Loss: 30849.935872 - Val Loss: 30080.133898 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [679/5000] - Train Loss: 30849.089627 - Val Loss: 30049.297092 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [680/5000] - Train Loss: 30771.804742 - Val Loss: 30019.681858 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [681/5000] - Train Loss: 30755.427789 - Val Loss: 29987.286024 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [682/5000] - Train Loss: 30734.053277 - Val Loss: 29956.152778 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [683/5000] - Train Loss: 30682.826389 - Val Loss: 29925.851780 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [684/5000] - Train Loss: 30621.976345 - Val Loss: 29892.524957 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [685/5000] - Train Loss: 30660.073513 - Val Loss: 29866.325304 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [686/5000] - Train Loss: 30601.292914 - Val Loss: 29833.444878 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [687/5000] - Train Loss: 30568.010959 - Val Loss: 29799.229167 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [688/5000] - Train Loss: 30539.342339 - Val Loss: 29773.898003 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [689/5000] - Train Loss: 30501.517470 - Val Loss: 29740.138238 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [690/5000] - Train Loss: 30458.718967 - Val Loss: 29711.187283 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [691/5000] - Train Loss: 30449.965386 - Val Loss: 29680.712240 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [692/5000] - Train Loss: 30425.973362 - Val Loss: 29650.682509 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [693/5000] - Train Loss: 30408.427463 - Val Loss: 29617.505425 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [694/5000] - Train Loss: 30354.058811 - Val Loss: 29588.741102 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [695/5000] - Train Loss: 30393.497613 - Val Loss: 29557.952474 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [696/5000] - Train Loss: 30245.231662 - Val Loss: 29529.123047 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [697/5000] - Train Loss: 30291.169651 - Val Loss: 29495.648655 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [698/5000] - Train Loss: 30218.896918 - Val Loss: 29464.664062 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [699/5000] - Train Loss: 30182.489041 - Val Loss: 29434.626953 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [700/5000] - Train Loss: 30189.244954 - Val Loss: 29402.969401 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [701/5000] - Train Loss: 30114.744520 - Val Loss: 29373.147352 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [702/5000] - Train Loss: 30177.563965 - Val Loss: 29342.051649 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [703/5000] - Train Loss: 30070.349175 - Val Loss: 29312.473958 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [704/5000] - Train Loss: 30072.281413 - Val Loss: 29280.877821 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [705/5000] - Train Loss: 30012.218262 - Val Loss: 29251.186849 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [706/5000] - Train Loss: 29956.064236 - Val Loss: 29219.029514 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [707/5000] - Train Loss: 29982.283691 - Val Loss: 29189.519965 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [708/5000] - Train Loss: 29953.056803 - Val Loss: 29162.345269 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [709/5000] - Train Loss: 29903.920790 - Val Loss: 29132.736111 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [710/5000] - Train Loss: 29845.630154 - Val Loss: 29096.630208 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [711/5000] - Train Loss: 29841.182346 - Val Loss: 29066.630642 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [712/5000] - Train Loss: 29802.566895 - Val Loss: 29039.506076 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [713/5000] - Train Loss: 29824.625705 - Val Loss: 29011.352865 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [714/5000] - Train Loss: 29713.252170 - Val Loss: 28980.056858 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [715/5000] - Train Loss: 29728.110352 - Val Loss: 28946.901042 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [716/5000] - Train Loss: 29680.647461 - Val Loss: 28918.149740 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [717/5000] - Train Loss: 29653.722222 - Val Loss: 28883.598741 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [718/5000] - Train Loss: 29614.075033 - Val Loss: 28855.187066 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [719/5000] - Train Loss: 29581.371582 - Val Loss: 28824.857422 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [720/5000] - Train Loss: 29588.301053 - Val Loss: 28797.074002 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [721/5000] - Train Loss: 29555.458605 - Val Loss: 28767.337457 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [722/5000] - Train Loss: 29597.022244 - Val Loss: 28736.932509 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [723/5000] - Train Loss: 29470.248047 - Val Loss: 28709.978299 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [724/5000] - Train Loss: 29422.740072 - Val Loss: 28675.528429 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [725/5000] - Train Loss: 29484.433377 - Val Loss: 28646.576172 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [726/5000] - Train Loss: 29413.499403 - Val Loss: 28615.883681 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [727/5000] - Train Loss: 29368.273220 - Val Loss: 28587.132161 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [728/5000] - Train Loss: 29324.284451 - Val Loss: 28560.244575 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [729/5000] - Train Loss: 29315.506673 - Val Loss: 28528.616970 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [730/5000] - Train Loss: 29268.377821 - Val Loss: 28498.900391 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [731/5000] - Train Loss: 29220.276096 - Val Loss: 28467.401693 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [732/5000] - Train Loss: 29185.402886 - Val Loss: 28435.907552 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [733/5000] - Train Loss: 29199.868869 - Val Loss: 28408.855035 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [734/5000] - Train Loss: 29186.637641 - Val Loss: 28378.519531 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [735/5000] - Train Loss: 29181.390734 - Val Loss: 28351.776042 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [736/5000] - Train Loss: 29070.975532 - Val Loss: 28320.044054 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [737/5000] - Train Loss: 29102.010634 - Val Loss: 28293.042318 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [738/5000] - Train Loss: 29105.559028 - Val Loss: 28261.135851 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [739/5000] - Train Loss: 29044.348416 - Val Loss: 28231.559028 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [740/5000] - Train Loss: 28994.238444 - Val Loss: 28202.720052 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [741/5000] - Train Loss: 28997.062717 - Val Loss: 28173.014540 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [742/5000] - Train Loss: 28901.726454 - Val Loss: 28145.478733 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [743/5000] - Train Loss: 28875.184787 - Val Loss: 28115.470703 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [744/5000] - Train Loss: 28867.556532 - Val Loss: 28088.914280 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [745/5000] - Train Loss: 28862.722982 - Val Loss: 28056.276042 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [746/5000] - Train Loss: 28824.077257 - Val Loss: 28027.921007 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [747/5000] - Train Loss: 28746.970812 - Val Loss: 27998.246311 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [748/5000] - Train Loss: 28777.827420 - Val Loss: 27968.478299 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [749/5000] - Train Loss: 28752.303060 - Val Loss: 27939.261936 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [750/5000] - Train Loss: 28733.357042 - Val Loss: 27909.707465 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [751/5000] - Train Loss: 28722.557400 - Val Loss: 27881.975694 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [752/5000] - Train Loss: 28640.647786 - Val Loss: 27850.328559 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [753/5000] - Train Loss: 28588.880208 - Val Loss: 27818.373915 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [754/5000] - Train Loss: 28583.638238 - Val Loss: 27789.375651 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [755/5000] - Train Loss: 28575.545193 - Val Loss: 27765.275608 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [756/5000] - Train Loss: 28503.219021 - Val Loss: 27735.629123 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [757/5000] - Train Loss: 28486.985623 - Val Loss: 27705.584852 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [758/5000] - Train Loss: 28493.031033 - Val Loss: 27678.708116 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [759/5000] - Train Loss: 28406.060059 - Val Loss: 27647.634766 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [760/5000] - Train Loss: 28423.753364 - Val Loss: 27623.809462 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [761/5000] - Train Loss: 28443.633247 - Val Loss: 27594.218316 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [762/5000] - Train Loss: 28339.245768 - Val Loss: 27562.245226 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [763/5000] - Train Loss: 28365.154243 - Val Loss: 27534.023872 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [764/5000] - Train Loss: 28320.258843 - Val Loss: 27505.066189 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [765/5000] - Train Loss: 28285.914171 - Val Loss: 27477.546441 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [766/5000] - Train Loss: 28296.632704 - Val Loss: 27446.625434 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [767/5000] - Train Loss: 28241.366970 - Val Loss: 27419.994575 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [768/5000] - Train Loss: 28209.385634 - Val Loss: 27388.778429 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [769/5000] - Train Loss: 28188.903103 - Val Loss: 27360.658420 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [770/5000] - Train Loss: 28116.289388 - Val Loss: 27335.086155 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [771/5000] - Train Loss: 28156.806586 - Val Loss: 27307.283203 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [772/5000] - Train Loss: 28118.975586 - Val Loss: 27277.309028 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [773/5000] - Train Loss: 28053.674642 - Val Loss: 27248.233724 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [774/5000] - Train Loss: 28025.668240 - Val Loss: 27218.338108 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [775/5000] - Train Loss: 28060.093099 - Val Loss: 27194.900608 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [776/5000] - Train Loss: 27992.700575 - Val Loss: 27167.697266 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [777/5000] - Train Loss: 27980.360677 - Val Loss: 27135.704210 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [778/5000] - Train Loss: 27929.222222 - Val Loss: 27108.908203 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [779/5000] - Train Loss: 27908.860948 - Val Loss: 27078.207248 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [780/5000] - Train Loss: 27858.394694 - Val Loss: 27052.182292 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [781/5000] - Train Loss: 27890.644423 - Val Loss: 27022.263238 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [782/5000] - Train Loss: 27832.064887 - Val Loss: 26995.760417 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [783/5000] - Train Loss: 27781.411838 - Val Loss: 26968.052300 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [784/5000] - Train Loss: 27768.830241 - Val Loss: 26934.420356 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [785/5000] - Train Loss: 27711.329915 - Val Loss: 26910.158420 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [786/5000] - Train Loss: 27698.367079 - Val Loss: 26883.605469 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [787/5000] - Train Loss: 27667.549425 - Val Loss: 26852.326606 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [788/5000] - Train Loss: 27678.112467 - Val Loss: 26822.974609 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [789/5000] - Train Loss: 27594.379449 - Val Loss: 26795.141276 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [790/5000] - Train Loss: 27594.510254 - Val Loss: 26765.099392 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [791/5000] - Train Loss: 27575.043566 - Val Loss: 26741.212240 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [792/5000] - Train Loss: 27540.705512 - Val Loss: 26710.752170 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [793/5000] - Train Loss: 27494.317057 - Val Loss: 26682.490017 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [794/5000] - Train Loss: 27479.076335 - Val Loss: 26652.904948 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [795/5000] - Train Loss: 27437.061903 - Val Loss: 26624.146701 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [796/5000] - Train Loss: 27405.309516 - Val Loss: 26599.191623 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [797/5000] - Train Loss: 27336.641222 - Val Loss: 26571.008464 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [798/5000] - Train Loss: 27347.881239 - Val Loss: 26542.323351 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [799/5000] - Train Loss: 27347.097493 - Val Loss: 26514.301432 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [800/5000] - Train Loss: 27317.581489 - Val Loss: 26489.742405 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [801/5000] - Train Loss: 27279.703830 - Val Loss: 26462.002170 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [802/5000] - Train Loss: 27262.539822 - Val Loss: 26431.608724 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [803/5000] - Train Loss: 27251.037652 - Val Loss: 26403.879557 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [804/5000] - Train Loss: 27195.250760 - Val Loss: 26376.160590 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [805/5000] - Train Loss: 27182.648600 - Val Loss: 26352.238715 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [806/5000] - Train Loss: 27148.813043 - Val Loss: 26317.762587 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [807/5000] - Train Loss: 27109.071181 - Val Loss: 26292.798394 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [808/5000] - Train Loss: 27073.530653 - Val Loss: 26265.820964 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [809/5000] - Train Loss: 27048.475152 - Val Loss: 26239.349175 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [810/5000] - Train Loss: 27072.534125 - Val Loss: 26212.162760 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [811/5000] - Train Loss: 27019.632758 - Val Loss: 26183.627170 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [812/5000] - Train Loss: 26984.841200 - Val Loss: 26153.229601 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [813/5000] - Train Loss: 26938.339789 - Val Loss: 26126.259332 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [814/5000] - Train Loss: 26911.273058 - Val Loss: 26103.408420 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [815/5000] - Train Loss: 26861.665527 - Val Loss: 26072.874132 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [816/5000] - Train Loss: 26857.034125 - Val Loss: 26046.278863 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [817/5000] - Train Loss: 26853.847711 - Val Loss: 26022.705946 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [818/5000] - Train Loss: 26827.811795 - Val Loss: 25990.266276 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [819/5000] - Train Loss: 26839.945855 - Val Loss: 25966.468750 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [820/5000] - Train Loss: 26761.196994 - Val Loss: 25935.361545 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [821/5000] - Train Loss: 26717.632433 - Val Loss: 25905.249783 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [822/5000] - Train Loss: 26737.055501 - Val Loss: 25881.134332 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [823/5000] - Train Loss: 26697.266927 - Val Loss: 25856.458333 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [824/5000] - Train Loss: 26654.704319 - Val Loss: 25829.283420 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [825/5000] - Train Loss: 26664.065158 - Val Loss: 25802.304036 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [826/5000] - Train Loss: 26607.692980 - Val Loss: 25777.985460 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [827/5000] - Train Loss: 26564.367079 - Val Loss: 25750.774740 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [828/5000] - Train Loss: 26588.594672 - Val Loss: 25725.430556 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [829/5000] - Train Loss: 26530.154026 - Val Loss: 25695.289714 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [830/5000] - Train Loss: 26484.407932 - Val Loss: 25668.534722 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [831/5000] - Train Loss: 26471.545844 - Val Loss: 25639.717014 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [832/5000] - Train Loss: 26442.338487 - Val Loss: 25615.572049 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [833/5000] - Train Loss: 26454.874946 - Val Loss: 25589.531467 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [834/5000] - Train Loss: 26408.104763 - Val Loss: 25565.109809 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [835/5000] - Train Loss: 26386.414171 - Val Loss: 25535.340712 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [836/5000] - Train Loss: 26338.305990 - Val Loss: 25506.296007 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [837/5000] - Train Loss: 26325.601617 - Val Loss: 25477.689453 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [838/5000] - Train Loss: 26336.427246 - Val Loss: 25454.180990 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [839/5000] - Train Loss: 26245.000054 - Val Loss: 25425.672743 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [840/5000] - Train Loss: 26247.302409 - Val Loss: 25401.013672 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [841/5000] - Train Loss: 26240.059625 - Val Loss: 25377.742405 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [842/5000] - Train Loss: 26227.328179 - Val Loss: 25349.633681 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [843/5000] - Train Loss: 26191.246094 - Val Loss: 25321.527561 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [844/5000] - Train Loss: 26145.291233 - Val Loss: 25295.524089 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [845/5000] - Train Loss: 26143.496582 - Val Loss: 25268.133247 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [846/5000] - Train Loss: 26071.806641 - Val Loss: 25242.085720 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [847/5000] - Train Loss: 26105.906250 - Val Loss: 25218.243924 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [848/5000] - Train Loss: 26028.684299 - Val Loss: 25188.614800 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [849/5000] - Train Loss: 26015.776150 - Val Loss: 25163.378255 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [850/5000] - Train Loss: 26000.497233 - Val Loss: 25136.586372 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [851/5000] - Train Loss: 25952.427192 - Val Loss: 25108.406033 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [852/5000] - Train Loss: 25961.647515 - Val Loss: 25081.454210 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [853/5000] - Train Loss: 25911.634983 - Val Loss: 25060.596137 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [854/5000] - Train Loss: 25875.690050 - Val Loss: 25030.304905 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [855/5000] - Train Loss: 25856.160048 - Val Loss: 25000.949002 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [856/5000] - Train Loss: 25859.360189 - Val Loss: 24979.646484 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [857/5000] - Train Loss: 25837.449273 - Val Loss: 24948.109809 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [858/5000] - Train Loss: 25780.084961 - Val Loss: 24922.857422 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [859/5000] - Train Loss: 25799.270020 - Val Loss: 24901.165799 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [860/5000] - Train Loss: 25746.917155 - Val Loss: 24873.245226 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [861/5000] - Train Loss: 25691.568305 - Val Loss: 24844.730686 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [862/5000] - Train Loss: 25684.463325 - Val Loss: 24815.615668 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [863/5000] - Train Loss: 25639.135091 - Val Loss: 24792.954427 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [864/5000] - Train Loss: 25670.783040 - Val Loss: 24769.199002 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [865/5000] - Train Loss: 25598.197428 - Val Loss: 24741.580729 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [866/5000] - Train Loss: 25532.767198 - Val Loss: 24713.921007 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [867/5000] - Train Loss: 25531.332248 - Val Loss: 24692.374349 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [868/5000] - Train Loss: 25490.773220 - Val Loss: 24662.786241 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [869/5000] - Train Loss: 25533.609755 - Val Loss: 24641.385634 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [870/5000] - Train Loss: 25488.390516 - Val Loss: 24617.657769 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [871/5000] - Train Loss: 25431.865506 - Val Loss: 24586.154731 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [872/5000] - Train Loss: 25446.395020 - Val Loss: 24560.901693 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [873/5000] - Train Loss: 25412.795844 - Val Loss: 24536.766059 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [874/5000] - Train Loss: 25373.389811 - Val Loss: 24513.080512 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [875/5000] - Train Loss: 25360.666667 - Val Loss: 24489.584201 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [876/5000] - Train Loss: 25356.979763 - Val Loss: 24460.971571 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [877/5000] - Train Loss: 25315.368869 - Val Loss: 24433.753255 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [878/5000] - Train Loss: 25310.969021 - Val Loss: 24413.436415 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [879/5000] - Train Loss: 25203.725911 - Val Loss: 24376.691840 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [880/5000] - Train Loss: 25268.815592 - Val Loss: 24359.463325 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [881/5000] - Train Loss: 25206.710395 - Val Loss: 24330.605469 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [882/5000] - Train Loss: 25171.731120 - Val Loss: 24299.864583 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [883/5000] - Train Loss: 25171.776638 - Val Loss: 24276.909288 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [884/5000] - Train Loss: 25121.621202 - Val Loss: 24250.549479 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [885/5000] - Train Loss: 25124.625217 - Val Loss: 24230.361328 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [886/5000] - Train Loss: 25088.083388 - Val Loss: 24197.261502 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [887/5000] - Train Loss: 25072.684245 - Val Loss: 24173.276042 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [888/5000] - Train Loss: 25036.187934 - Val Loss: 24150.382378 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [889/5000] - Train Loss: 25024.847928 - Val Loss: 24127.995660 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [890/5000] - Train Loss: 25011.475369 - Val Loss: 24101.135634 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [891/5000] - Train Loss: 24933.661730 - Val Loss: 24071.566840 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [892/5000] - Train Loss: 24903.351128 - Val Loss: 24050.343316 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [893/5000] - Train Loss: 24929.995877 - Val Loss: 24028.706163 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [894/5000] - Train Loss: 24873.345052 - Val Loss: 23996.337891 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [895/5000] - Train Loss: 24835.374946 - Val Loss: 23971.761068 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [896/5000] - Train Loss: 24811.965658 - Val Loss: 23950.643229 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [897/5000] - Train Loss: 24839.321018 - Val Loss: 23920.254991 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [898/5000] - Train Loss: 24813.903429 - Val Loss: 23900.487847 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [899/5000] - Train Loss: 24740.593153 - Val Loss: 23873.010417 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [900/5000] - Train Loss: 24762.174208 - Val Loss: 23844.725694 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [901/5000] - Train Loss: 24728.879883 - Val Loss: 23820.090278 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [902/5000] - Train Loss: 24658.054579 - Val Loss: 23795.703776 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [903/5000] - Train Loss: 24645.595378 - Val Loss: 23772.495443 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [904/5000] - Train Loss: 24650.414714 - Val Loss: 23740.326606 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [905/5000] - Train Loss: 24599.755805 - Val Loss: 23720.933160 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [906/5000] - Train Loss: 24604.935655 - Val Loss: 23695.520616 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [907/5000] - Train Loss: 24555.070855 - Val Loss: 23670.500868 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [908/5000] - Train Loss: 24527.081868 - Val Loss: 23642.294488 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [909/5000] - Train Loss: 24517.224609 - Val Loss: 23619.030599 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [910/5000] - Train Loss: 24476.568685 - Val Loss: 23599.203342 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [911/5000] - Train Loss: 24464.491970 - Val Loss: 23569.993056 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [912/5000] - Train Loss: 24465.523275 - Val Loss: 23546.975043 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [913/5000] - Train Loss: 24405.843099 - Val Loss: 23516.516276 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [914/5000] - Train Loss: 24402.013563 - Val Loss: 23494.587240 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [915/5000] - Train Loss: 24366.545356 - Val Loss: 23471.798611 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [916/5000] - Train Loss: 24373.825195 - Val Loss: 23445.107205 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [917/5000] - Train Loss: 24344.272135 - Val Loss: 23421.771484 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [918/5000] - Train Loss: 24280.547797 - Val Loss: 23401.240668 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [919/5000] - Train Loss: 24266.921821 - Val Loss: 23371.307509 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [920/5000] - Train Loss: 24229.832682 - Val Loss: 23348.919271 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [921/5000] - Train Loss: 24217.321452 - Val Loss: 23319.983507 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [922/5000] - Train Loss: 24199.819065 - Val Loss: 23294.580946 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [923/5000] - Train Loss: 24152.354872 - Val Loss: 23271.028429 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [924/5000] - Train Loss: 24135.644314 - Val Loss: 23252.059896 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [925/5000] - Train Loss: 24109.867893 - Val Loss: 23222.938368 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [926/5000] - Train Loss: 24102.778592 - Val Loss: 23203.175781 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [927/5000] - Train Loss: 24087.289117 - Val Loss: 23173.865668 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [928/5000] - Train Loss: 24075.286675 - Val Loss: 23151.964844 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [929/5000] - Train Loss: 24028.086155 - Val Loss: 23122.476345 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [930/5000] - Train Loss: 24004.123752 - Val Loss: 23105.310547 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [931/5000] - Train Loss: 24008.032064 - Val Loss: 23073.376302 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [932/5000] - Train Loss: 23952.053928 - Val Loss: 23057.614800 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [933/5000] - Train Loss: 23903.790039 - Val Loss: 23028.159071 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [934/5000] - Train Loss: 23897.752658 - Val Loss: 23005.831597 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [935/5000] - Train Loss: 23896.348633 - Val Loss: 22984.113064 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [936/5000] - Train Loss: 23870.061849 - Val Loss: 22951.004557 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [937/5000] - Train Loss: 23846.961806 - Val Loss: 22930.309028 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [938/5000] - Train Loss: 23809.449978 - Val Loss: 22904.003038 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [939/5000] - Train Loss: 23830.654785 - Val Loss: 22881.330729 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [940/5000] - Train Loss: 23763.905599 - Val Loss: 22850.844401 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [941/5000] - Train Loss: 23764.475857 - Val Loss: 22833.661024 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [942/5000] - Train Loss: 23737.719184 - Val Loss: 22803.285807 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [943/5000] - Train Loss: 23683.424696 - Val Loss: 22783.704210 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [944/5000] - Train Loss: 23628.717556 - Val Loss: 22755.064887 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [945/5000] - Train Loss: 23656.127550 - Val Loss: 22733.477648 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [946/5000] - Train Loss: 23610.430610 - Val Loss: 22705.929470 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [947/5000] - Train Loss: 23594.066732 - Val Loss: 22678.229167 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [948/5000] - Train Loss: 23543.613390 - Val Loss: 22662.165582 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [949/5000] - Train Loss: 23589.819390 - Val Loss: 22635.997830 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [950/5000] - Train Loss: 23541.081217 - Val Loss: 22612.133464 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [951/5000] - Train Loss: 23515.888455 - Val Loss: 22582.784722 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [952/5000] - Train Loss: 23529.815592 - Val Loss: 22563.648003 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [953/5000] - Train Loss: 23437.375217 - Val Loss: 22536.524089 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [954/5000] - Train Loss: 23458.274360 - Val Loss: 22514.894314 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [955/5000] - Train Loss: 23431.725043 - Val Loss: 22485.825738 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [956/5000] - Train Loss: 23411.448296 - Val Loss: 22464.626302 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [957/5000] - Train Loss: 23359.792697 - Val Loss: 22437.907552 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [958/5000] - Train Loss: 23337.686415 - Val Loss: 22417.871311 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [959/5000] - Train Loss: 23322.753526 - Val Loss: 22383.943793 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [960/5000] - Train Loss: 23292.748372 - Val Loss: 22359.526910 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [961/5000] - Train Loss: 23251.242513 - Val Loss: 22336.476562 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [962/5000] - Train Loss: 23245.568848 - Val Loss: 22311.656684 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [963/5000] - Train Loss: 23243.198785 - Val Loss: 22287.320747 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [964/5000] - Train Loss: 23200.036567 - Val Loss: 22262.455078 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [965/5000] - Train Loss: 23154.561144 - Val Loss: 22234.845486 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [966/5000] - Train Loss: 23172.692112 - Val Loss: 22205.102214 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [967/5000] - Train Loss: 23130.625814 - Val Loss: 22185.705946 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [968/5000] - Train Loss: 23134.645074 - Val Loss: 22162.703559 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [969/5000] - Train Loss: 23068.389160 - Val Loss: 22135.923394 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [970/5000] - Train Loss: 23062.424588 - Val Loss: 22107.933377 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [971/5000] - Train Loss: 23012.015028 - Val Loss: 22080.699870 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [972/5000] - Train Loss: 23015.057834 - Val Loss: 22061.140191 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [973/5000] - Train Loss: 23013.205349 - Val Loss: 22038.096788 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [974/5000] - Train Loss: 22938.960449 - Val Loss: 22013.807509 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [975/5000] - Train Loss: 22909.344944 - Val Loss: 21983.250434 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [976/5000] - Train Loss: 22912.634983 - Val Loss: 21956.863498 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [977/5000] - Train Loss: 22886.614475 - Val Loss: 21930.610894 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [978/5000] - Train Loss: 22850.305067 - Val Loss: 21906.850260 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [979/5000] - Train Loss: 22824.640191 - Val Loss: 21881.207899 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [980/5000] - Train Loss: 22836.342448 - Val Loss: 21852.509766 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [981/5000] - Train Loss: 22834.234592 - Val Loss: 21833.762370 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [982/5000] - Train Loss: 22774.040744 - Val Loss: 21803.921224 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [983/5000] - Train Loss: 22763.467882 - Val Loss: 21781.324436 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [984/5000] - Train Loss: 22729.415582 - Val Loss: 21753.616319 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [985/5000] - Train Loss: 22710.517687 - Val Loss: 21729.400825 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [986/5000] - Train Loss: 22664.871908 - Val Loss: 21709.882161 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [987/5000] - Train Loss: 22660.733398 - Val Loss: 21676.831597 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [988/5000] - Train Loss: 22626.465495 - Val Loss: 21647.113498 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [989/5000] - Train Loss: 22584.493164 - Val Loss: 21626.772569 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [990/5000] - Train Loss: 22569.007650 - Val Loss: 21596.070095 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [991/5000] - Train Loss: 22575.797526 - Val Loss: 21575.895399 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [992/5000] - Train Loss: 22531.825521 - Val Loss: 21550.876953 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [993/5000] - Train Loss: 22539.499023 - Val Loss: 21520.901910 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [994/5000] - Train Loss: 22501.465495 - Val Loss: 21488.376085 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [995/5000] - Train Loss: 22459.111925 - Val Loss: 21464.031467 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [996/5000] - Train Loss: 22418.579373 - Val Loss: 21434.153429 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [997/5000] - Train Loss: 22433.583116 - Val Loss: 21414.246962 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [998/5000] - Train Loss: 22413.773003 - Val Loss: 21390.079427 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [999/5000] - Train Loss: 22369.996039 - Val Loss: 21365.633030 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1000/5000] - Train Loss: 22343.153483 - Val Loss: 21337.189019 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1001/5000] - Train Loss: 22339.406576 - Val Loss: 21310.738932 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1002/5000] - Train Loss: 22285.062934 - Val Loss: 21278.520833 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1003/5000] - Train Loss: 22263.649523 - Val Loss: 21251.872613 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1004/5000] - Train Loss: 22261.448242 - Val Loss: 21228.256944 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1005/5000] - Train Loss: 22224.197266 - Val Loss: 21200.071615 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1006/5000] - Train Loss: 22177.824273 - Val Loss: 21169.946615 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1007/5000] - Train Loss: 22118.559462 - Val Loss: 21143.534505 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1008/5000] - Train Loss: 22139.424805 - Val Loss: 21113.234375 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1009/5000] - Train Loss: 22083.988770 - Val Loss: 21087.435547 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1010/5000] - Train Loss: 22081.190158 - Val Loss: 21071.193576 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1011/5000] - Train Loss: 22072.801541 - Val Loss: 21041.648655 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1012/5000] - Train Loss: 22015.306478 - Val Loss: 21024.082899 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1013/5000] - Train Loss: 21977.341200 - Val Loss: 20985.356337 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1014/5000] - Train Loss: 21985.054308 - Val Loss: 20953.978299 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1015/5000] - Train Loss: 21937.580187 - Val Loss: 20932.990234 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1016/5000] - Train Loss: 21895.734375 - Val Loss: 20906.242405 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1017/5000] - Train Loss: 21904.558214 - Val Loss: 20885.577908 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1018/5000] - Train Loss: 21873.020725 - Val Loss: 20858.768229 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1019/5000] - Train Loss: 21855.676053 - Val Loss: 20830.435330 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1020/5000] - Train Loss: 21825.686469 - Val Loss: 20802.919488 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1021/5000] - Train Loss: 21779.825087 - Val Loss: 20772.391493 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1022/5000] - Train Loss: 21794.520671 - Val Loss: 20750.213976 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1023/5000] - Train Loss: 21732.177463 - Val Loss: 20718.762804 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1024/5000] - Train Loss: 21775.284722 - Val Loss: 20697.597222 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1025/5000] - Train Loss: 21709.149577 - Val Loss: 20669.413628 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1026/5000] - Train Loss: 21683.303874 - Val Loss: 20646.690755 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1027/5000] - Train Loss: 21662.034071 - Val Loss: 20622.904514 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1028/5000] - Train Loss: 21580.816678 - Val Loss: 20597.605903 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1029/5000] - Train Loss: 21608.232476 - Val Loss: 20579.904297 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1030/5000] - Train Loss: 21596.308919 - Val Loss: 20541.621528 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1031/5000] - Train Loss: 21582.986491 - Val Loss: 20525.392144 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1032/5000] - Train Loss: 21488.364258 - Val Loss: 20494.750651 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1033/5000] - Train Loss: 21478.226562 - Val Loss: 20460.335286 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1034/5000] - Train Loss: 21474.619575 - Val Loss: 20437.187717 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1035/5000] - Train Loss: 21434.160319 - Val Loss: 20417.097222 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1036/5000] - Train Loss: 21421.953071 - Val Loss: 20390.710286 - Time: 1.37s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1037/5000] - Train Loss: 21365.779731 - Val Loss: 20361.444010 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1038/5000] - Train Loss: 21395.670681 - Val Loss: 20336.577474 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1039/5000] - Train Loss: 21355.779351 - Val Loss: 20317.282769 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1040/5000] - Train Loss: 21302.305827 - Val Loss: 20291.144314 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1041/5000] - Train Loss: 21308.107476 - Val Loss: 20263.063585 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1042/5000] - Train Loss: 21263.368490 - Val Loss: 20236.922092 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1043/5000] - Train Loss: 21252.528375 - Val Loss: 20216.080295 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1044/5000] - Train Loss: 21235.528158 - Val Loss: 20185.700087 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1045/5000] - Train Loss: 21221.022461 - Val Loss: 20171.416667 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1046/5000] - Train Loss: 21176.283040 - Val Loss: 20142.691406 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1047/5000] - Train Loss: 21174.732205 - Val Loss: 20118.652344 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1048/5000] - Train Loss: 21099.551487 - Val Loss: 20088.477431 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1049/5000] - Train Loss: 21114.658963 - Val Loss: 20067.310113 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1050/5000] - Train Loss: 21050.828451 - Val Loss: 20043.800347 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1051/5000] - Train Loss: 21049.030111 - Val Loss: 20017.748481 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1052/5000] - Train Loss: 21050.258843 - Val Loss: 19997.847005 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1053/5000] - Train Loss: 21043.463921 - Val Loss: 19971.642578 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1054/5000] - Train Loss: 20992.906141 - Val Loss: 19952.333984 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1055/5000] - Train Loss: 20937.958605 - Val Loss: 19919.718099 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1056/5000] - Train Loss: 20928.272786 - Val Loss: 19903.881727 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1057/5000] - Train Loss: 20915.608615 - Val Loss: 19879.465495 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1058/5000] - Train Loss: 20878.750543 - Val Loss: 19856.908637 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1059/5000] - Train Loss: 20872.755317 - Val Loss: 19836.209852 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1060/5000] - Train Loss: 20878.081434 - Val Loss: 19808.873481 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1061/5000] - Train Loss: 20824.584473 - Val Loss: 19782.291016 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1062/5000] - Train Loss: 20795.924588 - Val Loss: 19762.221788 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1063/5000] - Train Loss: 20790.347602 - Val Loss: 19738.723090 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1064/5000] - Train Loss: 20805.972385 - Val Loss: 19708.674045 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1065/5000] - Train Loss: 20734.249186 - Val Loss: 19693.251085 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1066/5000] - Train Loss: 20749.957791 - Val Loss: 19671.291450 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1067/5000] - Train Loss: 20706.187609 - Val Loss: 19652.299045 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1068/5000] - Train Loss: 20655.953776 - Val Loss: 19622.577908 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1069/5000] - Train Loss: 20681.757541 - Val Loss: 19596.676866 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1070/5000] - Train Loss: 20615.673882 - Val Loss: 19577.042101 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1071/5000] - Train Loss: 20605.869900 - Val Loss: 19556.709201 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1072/5000] - Train Loss: 20567.291612 - Val Loss: 19530.276259 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1073/5000] - Train Loss: 20554.815972 - Val Loss: 19512.881944 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1074/5000] - Train Loss: 20517.068142 - Val Loss: 19495.316189 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1075/5000] - Train Loss: 20574.019803 - Val Loss: 19470.702257 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1076/5000] - Train Loss: 20501.103895 - Val Loss: 19447.417752 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1077/5000] - Train Loss: 20513.503364 - Val Loss: 19430.791667 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1078/5000] - Train Loss: 20451.910048 - Val Loss: 19405.845052 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1079/5000] - Train Loss: 20442.548991 - Val Loss: 19382.407118 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1080/5000] - Train Loss: 20424.026259 - Val Loss: 19360.635851 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1081/5000] - Train Loss: 20440.323351 - Val Loss: 19336.382378 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1082/5000] - Train Loss: 20370.616699 - Val Loss: 19317.856554 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1083/5000] - Train Loss: 20343.176975 - Val Loss: 19299.635200 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1084/5000] - Train Loss: 20327.546278 - Val Loss: 19268.850477 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1085/5000] - Train Loss: 20292.276096 - Val Loss: 19251.776042 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1086/5000] - Train Loss: 20282.032389 - Val Loss: 19225.403429 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1087/5000] - Train Loss: 20281.145074 - Val Loss: 19202.710286 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1088/5000] - Train Loss: 20240.654351 - Val Loss: 19191.393446 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1089/5000] - Train Loss: 20228.612522 - Val Loss: 19165.887804 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1090/5000] - Train Loss: 20190.549696 - Val Loss: 19140.013455 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1091/5000] - Train Loss: 20180.505588 - Val Loss: 19120.184679 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1092/5000] - Train Loss: 20162.177897 - Val Loss: 19100.253689 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1093/5000] - Train Loss: 20153.196723 - Val Loss: 19075.359375 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1094/5000] - Train Loss: 20133.656087 - Val Loss: 19055.838325 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1095/5000] - Train Loss: 20111.428114 - Val Loss: 19031.942708 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1096/5000] - Train Loss: 20083.765299 - Val Loss: 19010.817491 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1097/5000] - Train Loss: 20067.901584 - Val Loss: 19000.385634 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1098/5000] - Train Loss: 20035.018175 - Val Loss: 18969.625868 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1099/5000] - Train Loss: 20027.449382 - Val Loss: 18948.701389 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1100/5000] - Train Loss: 19998.591037 - Val Loss: 18923.818793 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1101/5000] - Train Loss: 19975.132324 - Val Loss: 18905.230903 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1102/5000] - Train Loss: 19951.816949 - Val Loss: 18888.416450 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1103/5000] - Train Loss: 19922.288737 - Val Loss: 18866.764106 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1104/5000] - Train Loss: 19945.793674 - Val Loss: 18839.564453 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1105/5000] - Train Loss: 19859.736437 - Val Loss: 18821.878255 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1106/5000] - Train Loss: 19885.276204 - Val Loss: 18798.037543 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1107/5000] - Train Loss: 19853.622450 - Val Loss: 18792.433377 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1108/5000] - Train Loss: 19810.804253 - Val Loss: 18752.470486 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1109/5000] - Train Loss: 19817.178657 - Val Loss: 18740.573351 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1110/5000] - Train Loss: 19787.078776 - Val Loss: 18715.744575 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1111/5000] - Train Loss: 19775.162218 - Val Loss: 18696.141059 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1112/5000] - Train Loss: 19739.280328 - Val Loss: 18673.222656 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1113/5000] - Train Loss: 19715.884820 - Val Loss: 18659.556858 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1114/5000] - Train Loss: 19706.638780 - Val Loss: 18633.121528 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1115/5000] - Train Loss: 19694.233941 - Val Loss: 18614.032118 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1116/5000] - Train Loss: 19663.545898 - Val Loss: 18596.249783 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1117/5000] - Train Loss: 19659.721029 - Val Loss: 18576.090712 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1118/5000] - Train Loss: 19661.080512 - Val Loss: 18548.791233 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1119/5000] - Train Loss: 19614.233290 - Val Loss: 18537.237847 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1120/5000] - Train Loss: 19607.599284 - Val Loss: 18516.988281 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1121/5000] - Train Loss: 19537.605035 - Val Loss: 18492.770616 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1122/5000] - Train Loss: 19530.175510 - Val Loss: 18482.771267 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1123/5000] - Train Loss: 19545.330675 - Val Loss: 18456.390408 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1124/5000] - Train Loss: 19503.354980 - Val Loss: 18431.907986 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1125/5000] - Train Loss: 19481.505425 - Val Loss: 18407.916016 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1126/5000] - Train Loss: 19486.255317 - Val Loss: 18398.585720 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1127/5000] - Train Loss: 19470.664388 - Val Loss: 18370.413845 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1128/5000] - Train Loss: 19414.083605 - Val Loss: 18355.479167 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1129/5000] - Train Loss: 19387.188911 - Val Loss: 18335.382812 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1130/5000] - Train Loss: 19384.322049 - Val Loss: 18310.714627 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1131/5000] - Train Loss: 19377.484484 - Val Loss: 18296.753472 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1132/5000] - Train Loss: 19367.791233 - Val Loss: 18280.157118 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1133/5000] - Train Loss: 19310.960449 - Val Loss: 18249.751519 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1134/5000] - Train Loss: 19318.456868 - Val Loss: 18241.207682 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1135/5000] - Train Loss: 19337.428982 - Val Loss: 18210.228299 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1136/5000] - Train Loss: 19276.685384 - Val Loss: 18196.023220 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1137/5000] - Train Loss: 19250.218316 - Val Loss: 18167.088759 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1138/5000] - Train Loss: 19234.560113 - Val Loss: 18153.537543 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1139/5000] - Train Loss: 19229.659071 - Val Loss: 18136.557726 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1140/5000] - Train Loss: 19220.391927 - Val Loss: 18111.680122 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1141/5000] - Train Loss: 19176.261176 - Val Loss: 18098.797309 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1142/5000] - Train Loss: 19166.538411 - Val Loss: 18076.412543 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1143/5000] - Train Loss: 19155.937663 - Val Loss: 18055.348958 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1144/5000] - Train Loss: 19129.154405 - Val Loss: 18036.889540 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1145/5000] - Train Loss: 19095.057726 - Val Loss: 18018.695964 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1146/5000] - Train Loss: 19069.249240 - Val Loss: 18003.705946 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1147/5000] - Train Loss: 19071.917263 - Val Loss: 17989.582465 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1148/5000] - Train Loss: 19048.413466 - Val Loss: 17959.141710 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1149/5000] - Train Loss: 19033.721788 - Val Loss: 17936.838759 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1150/5000] - Train Loss: 19021.202474 - Val Loss: 17923.501085 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1151/5000] - Train Loss: 18999.096788 - Val Loss: 17909.120443 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1152/5000] - Train Loss: 18973.161350 - Val Loss: 17884.431207 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1153/5000] - Train Loss: 18973.449382 - Val Loss: 17865.075304 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1154/5000] - Train Loss: 18974.262044 - Val Loss: 17838.295790 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1155/5000] - Train Loss: 18889.564345 - Val Loss: 17823.718099 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1156/5000] - Train Loss: 18899.182834 - Val Loss: 17802.304036 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1157/5000] - Train Loss: 18886.708008 - Val Loss: 17784.551215 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1158/5000] - Train Loss: 18839.721734 - Val Loss: 17769.651042 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1159/5000] - Train Loss: 18821.798069 - Val Loss: 17745.355903 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1160/5000] - Train Loss: 18867.261773 - Val Loss: 17731.325738 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1161/5000] - Train Loss: 18813.133626 - Val Loss: 17712.309896 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1162/5000] - Train Loss: 18797.235026 - Val Loss: 17690.546658 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1163/5000] - Train Loss: 18770.235948 - Val Loss: 17666.252604 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1164/5000] - Train Loss: 18728.651476 - Val Loss: 17649.108724 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1165/5000] - Train Loss: 18721.240777 - Val Loss: 17631.306858 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1166/5000] - Train Loss: 18766.837511 - Val Loss: 17612.830078 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1167/5000] - Train Loss: 18702.689887 - Val Loss: 17601.931207 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1168/5000] - Train Loss: 18674.326280 - Val Loss: 17581.396050 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1169/5000] - Train Loss: 18635.199870 - Val Loss: 17561.852648 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1170/5000] - Train Loss: 18629.451172 - Val Loss: 17538.859158 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1171/5000] - Train Loss: 18613.316081 - Val Loss: 17522.862847 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1172/5000] - Train Loss: 18627.691081 - Val Loss: 17502.412543 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1173/5000] - Train Loss: 18584.978244 - Val Loss: 17480.616319 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1174/5000] - Train Loss: 18573.497993 - Val Loss: 17470.818576 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1175/5000] - Train Loss: 18563.592394 - Val Loss: 17457.995660 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1176/5000] - Train Loss: 18519.902452 - Val Loss: 17430.050998 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1177/5000] - Train Loss: 18489.288411 - Val Loss: 17410.969184 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1178/5000] - Train Loss: 18510.992730 - Val Loss: 17390.977756 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1179/5000] - Train Loss: 18507.020562 - Val Loss: 17369.241970 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1180/5000] - Train Loss: 18423.575250 - Val Loss: 17354.538411 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1181/5000] - Train Loss: 18464.347873 - Val Loss: 17335.074219 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1182/5000] - Train Loss: 18399.202040 - Val Loss: 17315.223416 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1183/5000] - Train Loss: 18403.101834 - Val Loss: 17303.179688 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1184/5000] - Train Loss: 18385.646701 - Val Loss: 17276.565321 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1185/5000] - Train Loss: 18376.750000 - Val Loss: 17260.367513 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1186/5000] - Train Loss: 18383.005208 - Val Loss: 17245.160590 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1187/5000] - Train Loss: 18339.667643 - Val Loss: 17228.352431 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1188/5000] - Train Loss: 18324.181152 - Val Loss: 17207.515734 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1189/5000] - Train Loss: 18297.526042 - Val Loss: 17193.408312 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1190/5000] - Train Loss: 18283.243056 - Val Loss: 17175.603190 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1191/5000] - Train Loss: 18291.145399 - Val Loss: 17151.541992 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1192/5000] - Train Loss: 18254.823351 - Val Loss: 17134.239583 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1193/5000] - Train Loss: 18224.492242 - Val Loss: 17115.430881 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1194/5000] - Train Loss: 18188.961426 - Val Loss: 17096.932509 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1195/5000] - Train Loss: 18182.205458 - Val Loss: 17075.488498 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1196/5000] - Train Loss: 18170.227431 - Val Loss: 17056.075521 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1197/5000] - Train Loss: 18133.728950 - Val Loss: 17038.217231 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1198/5000] - Train Loss: 18124.615723 - Val Loss: 17026.255859 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1199/5000] - Train Loss: 18148.969130 - Val Loss: 17004.787109 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1200/5000] - Train Loss: 18111.553657 - Val Loss: 16992.480794 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1201/5000] - Train Loss: 18121.800293 - Val Loss: 16968.180339 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1202/5000] - Train Loss: 18064.496419 - Val Loss: 16950.170573 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1203/5000] - Train Loss: 18053.877496 - Val Loss: 16933.903646 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1204/5000] - Train Loss: 18032.191461 - Val Loss: 16914.971788 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1205/5000] - Train Loss: 18015.183322 - Val Loss: 16898.955946 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1206/5000] - Train Loss: 17982.380588 - Val Loss: 16876.078559 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1207/5000] - Train Loss: 17987.247233 - Val Loss: 16856.964193 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1208/5000] - Train Loss: 17943.686578 - Val Loss: 16841.664280 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1209/5000] - Train Loss: 17948.422797 - Val Loss: 16832.181207 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1210/5000] - Train Loss: 17969.491211 - Val Loss: 16810.371853 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1211/5000] - Train Loss: 17920.224881 - Val Loss: 16795.449436 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1212/5000] - Train Loss: 17900.305556 - Val Loss: 16771.141819 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1213/5000] - Train Loss: 17912.003689 - Val Loss: 16755.110243 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1214/5000] - Train Loss: 17819.306532 - Val Loss: 16733.629449 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1215/5000] - Train Loss: 17854.975911 - Val Loss: 16724.695964 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1216/5000] - Train Loss: 17819.990343 - Val Loss: 16705.694661 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1217/5000] - Train Loss: 17834.497938 - Val Loss: 16693.634549 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1218/5000] - Train Loss: 17827.033746 - Val Loss: 16674.918077 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1219/5000] - Train Loss: 17770.091634 - Val Loss: 16645.217773 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1220/5000] - Train Loss: 17756.007216 - Val Loss: 16633.999783 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1221/5000] - Train Loss: 17732.503092 - Val Loss: 16612.479709 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1222/5000] - Train Loss: 17707.853516 - Val Loss: 16590.610026 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1223/5000] - Train Loss: 17729.065701 - Val Loss: 16577.590061 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1224/5000] - Train Loss: 17668.542209 - Val Loss: 16553.240668 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1225/5000] - Train Loss: 17655.775987 - Val Loss: 16543.813043 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1226/5000] - Train Loss: 17645.677355 - Val Loss: 16526.088216 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1227/5000] - Train Loss: 17648.783474 - Val Loss: 16513.277344 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1228/5000] - Train Loss: 17610.296387 - Val Loss: 16487.268880 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1229/5000] - Train Loss: 17596.673991 - Val Loss: 16469.429362 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1230/5000] - Train Loss: 17596.018121 - Val Loss: 16455.031901 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1231/5000] - Train Loss: 17575.584635 - Val Loss: 16441.413194 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1232/5000] - Train Loss: 17540.992133 - Val Loss: 16422.802951 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1233/5000] - Train Loss: 17536.703125 - Val Loss: 16407.303060 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1234/5000] - Train Loss: 17540.563585 - Val Loss: 16386.971246 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1235/5000] - Train Loss: 17515.694200 - Val Loss: 16374.839627 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1236/5000] - Train Loss: 17504.248589 - Val Loss: 16353.861220 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1237/5000] - Train Loss: 17472.642524 - Val Loss: 16337.654731 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1238/5000] - Train Loss: 17435.804091 - Val Loss: 16317.692817 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1239/5000] - Train Loss: 17433.193088 - Val Loss: 16308.932943 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1240/5000] - Train Loss: 17416.234484 - Val Loss: 16281.845920 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1241/5000] - Train Loss: 17399.343913 - Val Loss: 16269.248264 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1242/5000] - Train Loss: 17399.526638 - Val Loss: 16252.032118 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1243/5000] - Train Loss: 17373.459635 - Val Loss: 16237.543728 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1244/5000] - Train Loss: 17355.010145 - Val Loss: 16219.439453 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1245/5000] - Train Loss: 17375.706434 - Val Loss: 16200.981988 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1246/5000] - Train Loss: 17334.391330 - Val Loss: 16185.551649 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1247/5000] - Train Loss: 17305.095378 - Val Loss: 16164.633898 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1248/5000] - Train Loss: 17278.387614 - Val Loss: 16150.201823 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1249/5000] - Train Loss: 17277.793945 - Val Loss: 16137.380100 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1250/5000] - Train Loss: 17283.004340 - Val Loss: 16126.768338 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1251/5000] - Train Loss: 17246.826714 - Val Loss: 16106.849392 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1252/5000] - Train Loss: 17218.500977 - Val Loss: 16084.227539 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1253/5000] - Train Loss: 17195.651069 - Val Loss: 16069.758572 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1254/5000] - Train Loss: 17212.337782 - Val Loss: 16047.288737 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1255/5000] - Train Loss: 17191.438585 - Val Loss: 16035.694336 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1256/5000] - Train Loss: 17206.432183 - Val Loss: 16023.511068 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1257/5000] - Train Loss: 17146.371908 - Val Loss: 15996.303711 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1258/5000] - Train Loss: 17170.287760 - Val Loss: 15983.061632 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1259/5000] - Train Loss: 17123.027724 - Val Loss: 15967.343424 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1260/5000] - Train Loss: 17106.220215 - Val Loss: 15952.017578 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1261/5000] - Train Loss: 17084.517307 - Val Loss: 15936.895508 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1262/5000] - Train Loss: 17051.297472 - Val Loss: 15923.157878 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1263/5000] - Train Loss: 17044.696940 - Val Loss: 15898.243490 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1264/5000] - Train Loss: 17056.916558 - Val Loss: 15887.239149 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1265/5000] - Train Loss: 17017.069417 - Val Loss: 15872.105143 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1266/5000] - Train Loss: 17036.456489 - Val Loss: 15856.301107 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1267/5000] - Train Loss: 17009.767334 - Val Loss: 15832.420247 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1268/5000] - Train Loss: 16987.696723 - Val Loss: 15813.705512 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1269/5000] - Train Loss: 16972.420058 - Val Loss: 15802.505425 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1270/5000] - Train Loss: 16935.778402 - Val Loss: 15786.070312 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1271/5000] - Train Loss: 16929.265299 - Val Loss: 15770.414931 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1272/5000] - Train Loss: 16918.043484 - Val Loss: 15755.052409 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1273/5000] - Train Loss: 16895.333605 - Val Loss: 15734.381510 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1274/5000] - Train Loss: 16888.696804 - Val Loss: 15718.555664 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1275/5000] - Train Loss: 16874.468397 - Val Loss: 15701.255642 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1276/5000] - Train Loss: 16875.863390 - Val Loss: 15689.528212 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1277/5000] - Train Loss: 16867.305800 - Val Loss: 15672.083225 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1278/5000] - Train Loss: 16817.876329 - Val Loss: 15667.199327 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1279/5000] - Train Loss: 16829.865913 - Val Loss: 15639.019748 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1280/5000] - Train Loss: 16796.386610 - Val Loss: 15626.336589 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1281/5000] - Train Loss: 16789.070475 - Val Loss: 15608.141602 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1282/5000] - Train Loss: 16742.120090 - Val Loss: 15586.365560 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1283/5000] - Train Loss: 16719.311334 - Val Loss: 15572.987630 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1284/5000] - Train Loss: 16748.097195 - Val Loss: 15553.382921 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1285/5000] - Train Loss: 16722.402696 - Val Loss: 15549.130317 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1286/5000] - Train Loss: 16720.247640 - Val Loss: 15534.582574 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1287/5000] - Train Loss: 16706.011746 - Val Loss: 15518.043186 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1288/5000] - Train Loss: 16669.532227 - Val Loss: 15503.957357 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1289/5000] - Train Loss: 16674.010688 - Val Loss: 15482.975260 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1290/5000] - Train Loss: 16624.751085 - Val Loss: 15476.165582 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1291/5000] - Train Loss: 16655.585069 - Val Loss: 15453.373264 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1292/5000] - Train Loss: 16610.450141 - Val Loss: 15438.292209 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1293/5000] - Train Loss: 16579.953478 - Val Loss: 15417.685872 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1294/5000] - Train Loss: 16586.111491 - Val Loss: 15402.225694 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1295/5000] - Train Loss: 16544.096354 - Val Loss: 15392.328016 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1296/5000] - Train Loss: 16555.431858 - Val Loss: 15379.868707 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1297/5000] - Train Loss: 16537.878526 - Val Loss: 15366.561198 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1298/5000] - Train Loss: 16539.170492 - Val Loss: 15352.076389 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1299/5000] - Train Loss: 16510.267036 - Val Loss: 15331.328559 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1300/5000] - Train Loss: 16492.525228 - Val Loss: 15316.530165 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1301/5000] - Train Loss: 16484.430583 - Val Loss: 15297.300456 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1302/5000] - Train Loss: 16487.445936 - Val Loss: 15285.737413 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1303/5000] - Train Loss: 16466.111274 - Val Loss: 15262.747613 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1304/5000] - Train Loss: 16412.484158 - Val Loss: 15247.237522 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1305/5000] - Train Loss: 16440.514377 - Val Loss: 15234.920464 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1306/5000] - Train Loss: 16426.426297 - Val Loss: 15224.969727 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1307/5000] - Train Loss: 16382.960802 - Val Loss: 15207.104275 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1308/5000] - Train Loss: 16393.745958 - Val Loss: 15189.202582 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1309/5000] - Train Loss: 16351.835097 - Val Loss: 15178.128581 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1310/5000] - Train Loss: 16346.623725 - Val Loss: 15161.277995 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1311/5000] - Train Loss: 16338.909776 - Val Loss: 15148.362522 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1312/5000] - Train Loss: 16325.972114 - Val Loss: 15126.017361 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1313/5000] - Train Loss: 16321.645345 - Val Loss: 15114.264865 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1314/5000] - Train Loss: 16289.925971 - Val Loss: 15098.542101 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1315/5000] - Train Loss: 16298.386664 - Val Loss: 15082.092448 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1316/5000] - Train Loss: 16274.842475 - Val Loss: 15066.928602 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1317/5000] - Train Loss: 16276.379693 - Val Loss: 15053.159180 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1318/5000] - Train Loss: 16236.165771 - Val Loss: 15039.208116 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1319/5000] - Train Loss: 16230.206326 - Val Loss: 15023.104709 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1320/5000] - Train Loss: 16213.997965 - Val Loss: 15011.726562 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1321/5000] - Train Loss: 16185.836670 - Val Loss: 14994.710612 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1322/5000] - Train Loss: 16185.515462 - Val Loss: 14980.818793 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1323/5000] - Train Loss: 16170.109809 - Val Loss: 14968.106120 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1324/5000] - Train Loss: 16158.624620 - Val Loss: 14957.939236 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1325/5000] - Train Loss: 16122.769667 - Val Loss: 14939.072266 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1326/5000] - Train Loss: 16145.811225 - Val Loss: 14922.568902 - Time: 1.36s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1327/5000] - Train Loss: 16119.918891 - Val Loss: 14907.839193 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1328/5000] - Train Loss: 16124.891493 - Val Loss: 14893.313260 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1329/5000] - Train Loss: 16086.956353 - Val Loss: 14882.276476 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1330/5000] - Train Loss: 16068.369466 - Val Loss: 14862.324436 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1331/5000] - Train Loss: 16066.709147 - Val Loss: 14846.368924 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1332/5000] - Train Loss: 16011.734077 - Val Loss: 14841.440104 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1333/5000] - Train Loss: 16006.178684 - Val Loss: 14820.938911 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1334/5000] - Train Loss: 16024.149902 - Val Loss: 14802.831597 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1335/5000] - Train Loss: 15992.160834 - Val Loss: 14790.093533 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1336/5000] - Train Loss: 15997.236844 - Val Loss: 14778.828559 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1337/5000] - Train Loss: 15980.203044 - Val Loss: 14763.476671 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1338/5000] - Train Loss: 15994.498508 - Val Loss: 14755.289062 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1339/5000] - Train Loss: 15937.864339 - Val Loss: 14737.836263 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1340/5000] - Train Loss: 15927.751438 - Val Loss: 14718.484049 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1341/5000] - Train Loss: 15948.394531 - Val Loss: 14715.179145 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1342/5000] - Train Loss: 15930.804145 - Val Loss: 14696.556966 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1343/5000] - Train Loss: 15921.220920 - Val Loss: 14694.516710 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1344/5000] - Train Loss: 15885.539008 - Val Loss: 14676.834961 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1345/5000] - Train Loss: 15897.834717 - Val Loss: 14658.013672 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1346/5000] - Train Loss: 15850.884115 - Val Loss: 14646.750434 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1347/5000] - Train Loss: 15835.132867 - Val Loss: 14635.335503 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1348/5000] - Train Loss: 15843.696370 - Val Loss: 14615.598416 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1349/5000] - Train Loss: 15824.977024 - Val Loss: 14604.318034 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1350/5000] - Train Loss: 15813.858778 - Val Loss: 14588.220269 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1351/5000] - Train Loss: 15783.745117 - Val Loss: 14572.067274 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1352/5000] - Train Loss: 15790.261773 - Val Loss: 14562.418511 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1353/5000] - Train Loss: 15766.358968 - Val Loss: 14548.040473 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1354/5000] - Train Loss: 15737.938531 - Val Loss: 14535.484701 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1355/5000] - Train Loss: 15756.935384 - Val Loss: 14520.096246 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1356/5000] - Train Loss: 15744.166124 - Val Loss: 14509.128255 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1357/5000] - Train Loss: 15726.265001 - Val Loss: 14495.527452 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1358/5000] - Train Loss: 15703.639431 - Val Loss: 14474.027886 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1359/5000] - Train Loss: 15702.993056 - Val Loss: 14462.021484 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1360/5000] - Train Loss: 15667.503716 - Val Loss: 14456.497287 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1361/5000] - Train Loss: 15658.494927 - Val Loss: 14443.646159 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1362/5000] - Train Loss: 15659.202013 - Val Loss: 14428.576063 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1363/5000] - Train Loss: 15683.591526 - Val Loss: 14418.041341 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1364/5000] - Train Loss: 15621.285183 - Val Loss: 14403.059570 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1365/5000] - Train Loss: 15640.001465 - Val Loss: 14389.262153 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1366/5000] - Train Loss: 15597.582682 - Val Loss: 14374.422960 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1367/5000] - Train Loss: 15587.290826 - Val Loss: 14364.832899 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1368/5000] - Train Loss: 15594.531440 - Val Loss: 14348.214518 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1369/5000] - Train Loss: 15593.895725 - Val Loss: 14336.175130 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1370/5000] - Train Loss: 15553.047852 - Val Loss: 14323.372938 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1371/5000] - Train Loss: 15540.443604 - Val Loss: 14308.211155 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1372/5000] - Train Loss: 15536.636203 - Val Loss: 14298.071181 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1373/5000] - Train Loss: 15509.448676 - Val Loss: 14287.623481 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1374/5000] - Train Loss: 15505.933675 - Val Loss: 14273.032335 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1375/5000] - Train Loss: 15490.081841 - Val Loss: 14257.158637 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1376/5000] - Train Loss: 15498.023573 - Val Loss: 14241.789822 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1377/5000] - Train Loss: 15484.327555 - Val Loss: 14230.774089 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1378/5000] - Train Loss: 15468.785075 - Val Loss: 14215.247938 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1379/5000] - Train Loss: 15453.307319 - Val Loss: 14202.148220 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1380/5000] - Train Loss: 15421.183431 - Val Loss: 14182.428711 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1381/5000] - Train Loss: 15396.418891 - Val Loss: 14175.635200 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1382/5000] - Train Loss: 15407.311361 - Val Loss: 14166.193251 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1383/5000] - Train Loss: 15433.602892 - Val Loss: 14159.784505 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1384/5000] - Train Loss: 15385.080322 - Val Loss: 14146.447483 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1385/5000] - Train Loss: 15399.026204 - Val Loss: 14130.848958 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1386/5000] - Train Loss: 15368.889459 - Val Loss: 14114.495877 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1387/5000] - Train Loss: 15366.182997 - Val Loss: 14106.525825 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1388/5000] - Train Loss: 15354.259983 - Val Loss: 14093.538628 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1389/5000] - Train Loss: 15345.125624 - Val Loss: 14075.684896 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1390/5000] - Train Loss: 15339.647841 - Val Loss: 14069.931532 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1391/5000] - Train Loss: 15348.030328 - Val Loss: 14052.787326 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1392/5000] - Train Loss: 15305.912354 - Val Loss: 14041.020291 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1393/5000] - Train Loss: 15314.084310 - Val Loss: 14037.984049 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1394/5000] - Train Loss: 15247.374756 - Val Loss: 14016.332574 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1395/5000] - Train Loss: 15262.651937 - Val Loss: 14006.252387 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1396/5000] - Train Loss: 15248.576823 - Val Loss: 13993.190213 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1397/5000] - Train Loss: 15225.287408 - Val Loss: 13983.460612 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1398/5000] - Train Loss: 15205.240044 - Val Loss: 13967.026150 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1399/5000] - Train Loss: 15209.356527 - Val Loss: 13951.860677 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1400/5000] - Train Loss: 15248.240044 - Val Loss: 13948.526584 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1401/5000] - Train Loss: 15203.581814 - Val Loss: 13924.556641 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1402/5000] - Train Loss: 15171.750760 - Val Loss: 13915.045247 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1403/5000] - Train Loss: 15175.176595 - Val Loss: 13908.688911 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1404/5000] - Train Loss: 15155.891032 - Val Loss: 13889.840278 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1405/5000] - Train Loss: 15147.647407 - Val Loss: 13879.848741 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1406/5000] - Train Loss: 15140.500000 - Val Loss: 13875.118598 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1407/5000] - Train Loss: 15113.757487 - Val Loss: 13860.432617 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1408/5000] - Train Loss: 15081.171739 - Val Loss: 13842.469835 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1409/5000] - Train Loss: 15104.318414 - Val Loss: 13827.454861 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1410/5000] - Train Loss: 15102.730713 - Val Loss: 13819.919488 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1411/5000] - Train Loss: 15076.232910 - Val Loss: 13808.087348 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1412/5000] - Train Loss: 15064.004232 - Val Loss: 13799.665365 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1413/5000] - Train Loss: 15046.193468 - Val Loss: 13787.949544 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1414/5000] - Train Loss: 15045.618245 - Val Loss: 13772.521267 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1415/5000] - Train Loss: 15013.276232 - Val Loss: 13769.707682 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1416/5000] - Train Loss: 15015.643609 - Val Loss: 13760.689779 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1417/5000] - Train Loss: 15021.846056 - Val Loss: 13741.720812 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1418/5000] - Train Loss: 14993.472168 - Val Loss: 13725.983507 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1419/5000] - Train Loss: 14996.207086 - Val Loss: 13716.317166 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1420/5000] - Train Loss: 14976.923286 - Val Loss: 13714.087023 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1421/5000] - Train Loss: 14962.868327 - Val Loss: 13695.308377 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1422/5000] - Train Loss: 14947.941298 - Val Loss: 13680.920790 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1423/5000] - Train Loss: 14958.484158 - Val Loss: 13665.292426 - Time: 1.39s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1424/5000] - Train Loss: 14928.997369 - Val Loss: 13661.493815 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1425/5000] - Train Loss: 14929.397841 - Val Loss: 13646.194119 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1426/5000] - Train Loss: 14908.954780 - Val Loss: 13640.996311 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1427/5000] - Train Loss: 14941.581190 - Val Loss: 13635.387153 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1428/5000] - Train Loss: 14905.460856 - Val Loss: 13615.418837 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1429/5000] - Train Loss: 14884.227159 - Val Loss: 13602.198025 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1430/5000] - Train Loss: 14858.568387 - Val Loss: 13592.014757 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1431/5000] - Train Loss: 14854.890978 - Val Loss: 13578.118056 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1432/5000] - Train Loss: 14837.597168 - Val Loss: 13570.801866 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1433/5000] - Train Loss: 14831.197835 - Val Loss: 13562.382378 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1434/5000] - Train Loss: 14816.293674 - Val Loss: 13545.280707 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1435/5000] - Train Loss: 14833.052436 - Val Loss: 13544.598307 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1436/5000] - Train Loss: 14796.326823 - Val Loss: 13519.925347 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1437/5000] - Train Loss: 14780.998047 - Val Loss: 13510.956163 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1438/5000] - Train Loss: 14763.369276 - Val Loss: 13503.334310 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1439/5000] - Train Loss: 14777.042426 - Val Loss: 13488.468424 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1440/5000] - Train Loss: 14755.284261 - Val Loss: 13476.170790 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1441/5000] - Train Loss: 14753.346951 - Val Loss: 13467.542535 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1442/5000] - Train Loss: 14725.833659 - Val Loss: 13458.561849 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1443/5000] - Train Loss: 14721.594727 - Val Loss: 13447.838433 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1444/5000] - Train Loss: 14727.632704 - Val Loss: 13438.098850 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1445/5000] - Train Loss: 14710.598850 - Val Loss: 13425.109375 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1446/5000] - Train Loss: 14706.431234 - Val Loss: 13416.287543 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1447/5000] - Train Loss: 14697.012207 - Val Loss: 13409.428819 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1448/5000] - Train Loss: 14680.674750 - Val Loss: 13394.513780 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1449/5000] - Train Loss: 14656.334012 - Val Loss: 13384.298394 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1450/5000] - Train Loss: 14664.841498 - Val Loss: 13376.200738 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1451/5000] - Train Loss: 14639.910183 - Val Loss: 13358.422635 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1452/5000] - Train Loss: 14645.887017 - Val Loss: 13348.282444 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1453/5000] - Train Loss: 14615.277018 - Val Loss: 13341.802300 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1454/5000] - Train Loss: 14613.049018 - Val Loss: 13330.128798 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1455/5000] - Train Loss: 14635.656169 - Val Loss: 13312.160156 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1456/5000] - Train Loss: 14601.553141 - Val Loss: 13308.380968 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1457/5000] - Train Loss: 14577.389242 - Val Loss: 13296.812934 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1458/5000] - Train Loss: 14581.547906 - Val Loss: 13280.221897 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1459/5000] - Train Loss: 14575.106934 - Val Loss: 13271.605252 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1460/5000] - Train Loss: 14535.481174 - Val Loss: 13268.345161 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1461/5000] - Train Loss: 14548.708767 - Val Loss: 13257.482747 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1462/5000] - Train Loss: 14556.053982 - Val Loss: 13239.446181 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1463/5000] - Train Loss: 14538.212592 - Val Loss: 13239.443793 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1464/5000] - Train Loss: 14479.574137 - Val Loss: 13223.003147 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1465/5000] - Train Loss: 14518.778971 - Val Loss: 13216.446832 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1466/5000] - Train Loss: 14494.968533 - Val Loss: 13204.756944 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1467/5000] - Train Loss: 14492.560737 - Val Loss: 13191.207791 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1468/5000] - Train Loss: 14466.672770 - Val Loss: 13183.885851 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1469/5000] - Train Loss: 14466.685438 - Val Loss: 13185.477756 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1470/5000] - Train Loss: 14438.218370 - Val Loss: 13168.114475 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1471/5000] - Train Loss: 14414.965875 - Val Loss: 13152.392795 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1472/5000] - Train Loss: 14435.291070 - Val Loss: 13137.122938 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1473/5000] - Train Loss: 14456.366347 - Val Loss: 13137.587023 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1474/5000] - Train Loss: 14418.594455 - Val Loss: 13122.347005 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1475/5000] - Train Loss: 14406.510010 - Val Loss: 13114.316949 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1476/5000] - Train Loss: 14423.561876 - Val Loss: 13109.387153 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1477/5000] - Train Loss: 14419.031711 - Val Loss: 13085.709852 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1478/5000] - Train Loss: 14374.659695 - Val Loss: 13078.366536 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1479/5000] - Train Loss: 14368.802490 - Val Loss: 13075.495226 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1480/5000] - Train Loss: 14353.110840 - Val Loss: 13063.582465 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1481/5000] - Train Loss: 14359.862983 - Val Loss: 13056.824436 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1482/5000] - Train Loss: 14355.252441 - Val Loss: 13049.519423 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1483/5000] - Train Loss: 14320.664008 - Val Loss: 13036.671658 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1484/5000] - Train Loss: 14317.764648 - Val Loss: 13025.761936 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1485/5000] - Train Loss: 14329.020562 - Val Loss: 13017.234049 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1486/5000] - Train Loss: 14305.489719 - Val Loss: 13007.482747 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1487/5000] - Train Loss: 14320.955621 - Val Loss: 12994.083659 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1488/5000] - Train Loss: 14278.427599 - Val Loss: 12988.043511 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1489/5000] - Train Loss: 14257.568468 - Val Loss: 12979.465278 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1490/5000] - Train Loss: 14273.480170 - Val Loss: 12970.410048 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1491/5000] - Train Loss: 14251.339762 - Val Loss: 12960.740343 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1492/5000] - Train Loss: 14234.468370 - Val Loss: 12954.135851 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1493/5000] - Train Loss: 14237.231472 - Val Loss: 12946.566840 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1494/5000] - Train Loss: 14237.324951 - Val Loss: 12934.072049 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1495/5000] - Train Loss: 14225.403049 - Val Loss: 12931.617079 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1496/5000] - Train Loss: 14227.437880 - Val Loss: 12916.530599 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1497/5000] - Train Loss: 14216.384277 - Val Loss: 12903.986871 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1498/5000] - Train Loss: 14220.071967 - Val Loss: 12895.985569 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1499/5000] - Train Loss: 14200.128988 - Val Loss: 12887.057834 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1500/5000] - Train Loss: 14202.998264 - Val Loss: 12879.203342 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1501/5000] - Train Loss: 14183.482069 - Val Loss: 12865.247179 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1502/5000] - Train Loss: 14167.804389 - Val Loss: 12853.545790 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1503/5000] - Train Loss: 14186.604872 - Val Loss: 12847.870226 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1504/5000] - Train Loss: 14138.779405 - Val Loss: 12839.131293 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1505/5000] - Train Loss: 14135.173503 - Val Loss: 12834.497179 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1506/5000] - Train Loss: 14104.664714 - Val Loss: 12819.174913 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1507/5000] - Train Loss: 14126.082167 - Val Loss: 12804.196398 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1508/5000] - Train Loss: 14113.847331 - Val Loss: 12793.189019 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1509/5000] - Train Loss: 14110.160943 - Val Loss: 12797.140842 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1510/5000] - Train Loss: 14089.677355 - Val Loss: 12778.535482 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1511/5000] - Train Loss: 14090.729601 - Val Loss: 12770.323568 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1512/5000] - Train Loss: 14097.046604 - Val Loss: 12769.401801 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1513/5000] - Train Loss: 14067.269558 - Val Loss: 12765.711372 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1514/5000] - Train Loss: 14034.598741 - Val Loss: 12741.485460 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1515/5000] - Train Loss: 14036.608344 - Val Loss: 12738.234484 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1516/5000] - Train Loss: 14033.969618 - Val Loss: 12723.752279 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1517/5000] - Train Loss: 14041.574734 - Val Loss: 12717.245660 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1518/5000] - Train Loss: 14003.676270 - Val Loss: 12713.564345 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1519/5000] - Train Loss: 14005.556315 - Val Loss: 12704.818468 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1520/5000] - Train Loss: 14000.760444 - Val Loss: 12698.826823 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1521/5000] - Train Loss: 13997.818115 - Val Loss: 12682.960829 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1522/5000] - Train Loss: 13988.431505 - Val Loss: 12676.091146 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1523/5000] - Train Loss: 13956.520616 - Val Loss: 12666.814996 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1524/5000] - Train Loss: 13980.542128 - Val Loss: 12653.222005 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1525/5000] - Train Loss: 13969.251329 - Val Loss: 12646.081055 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1526/5000] - Train Loss: 13930.080458 - Val Loss: 12638.046766 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1527/5000] - Train Loss: 13951.947130 - Val Loss: 12629.960069 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1528/5000] - Train Loss: 13940.155572 - Val Loss: 12622.520182 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1529/5000] - Train Loss: 13904.276313 - Val Loss: 12614.554145 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1530/5000] - Train Loss: 13896.953125 - Val Loss: 12605.647244 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1531/5000] - Train Loss: 13908.615696 - Val Loss: 12591.695638 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1532/5000] - Train Loss: 13923.573188 - Val Loss: 12593.589410 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1533/5000] - Train Loss: 13906.518392 - Val Loss: 12578.985460 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1534/5000] - Train Loss: 13872.555501 - Val Loss: 12570.245117 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1535/5000] - Train Loss: 13866.246067 - Val Loss: 12563.797201 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1536/5000] - Train Loss: 13859.110080 - Val Loss: 12553.123915 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1537/5000] - Train Loss: 13863.105713 - Val Loss: 12550.112413 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1538/5000] - Train Loss: 13856.283990 - Val Loss: 12533.323785 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1539/5000] - Train Loss: 13849.597819 - Val Loss: 12530.896159 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1540/5000] - Train Loss: 13838.116401 - Val Loss: 12518.597982 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1541/5000] - Train Loss: 13809.524631 - Val Loss: 12503.094944 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1542/5000] - Train Loss: 13807.849338 - Val Loss: 12493.583876 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1543/5000] - Train Loss: 13816.249322 - Val Loss: 12496.909831 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1544/5000] - Train Loss: 13818.236030 - Val Loss: 12485.704427 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1545/5000] - Train Loss: 13796.918593 - Val Loss: 12467.009440 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1546/5000] - Train Loss: 13777.056613 - Val Loss: 12465.246419 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1547/5000] - Train Loss: 13786.923828 - Val Loss: 12453.030599 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1548/5000] - Train Loss: 13770.495822 - Val Loss: 12446.556749 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1549/5000] - Train Loss: 13753.122613 - Val Loss: 12436.663845 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1550/5000] - Train Loss: 13750.366374 - Val Loss: 12431.729709 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1551/5000] - Train Loss: 13752.969510 - Val Loss: 12420.935764 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1552/5000] - Train Loss: 13724.874647 - Val Loss: 12416.325846 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1553/5000] - Train Loss: 13725.239746 - Val Loss: 12411.040148 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1554/5000] - Train Loss: 13721.756972 - Val Loss: 12396.446832 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1555/5000] - Train Loss: 13717.764486 - Val Loss: 12387.470703 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1556/5000] - Train Loss: 13748.975803 - Val Loss: 12390.552083 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1557/5000] - Train Loss: 13695.254774 - Val Loss: 12379.583008 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1558/5000] - Train Loss: 13675.594618 - Val Loss: 12364.516385 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1559/5000] - Train Loss: 13672.043213 - Val Loss: 12363.600369 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1560/5000] - Train Loss: 13668.750054 - Val Loss: 12343.421224 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1561/5000] - Train Loss: 13659.802273 - Val Loss: 12337.601997 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1562/5000] - Train Loss: 13656.184706 - Val Loss: 12339.739692 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1563/5000] - Train Loss: 13660.064996 - Val Loss: 12328.240451 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1564/5000] - Train Loss: 13636.418213 - Val Loss: 12323.808485 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1565/5000] - Train Loss: 13626.064779 - Val Loss: 12317.814670 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1566/5000] - Train Loss: 13641.584473 - Val Loss: 12312.809787 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1567/5000] - Train Loss: 13618.521240 - Val Loss: 12300.259115 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1568/5000] - Train Loss: 13601.892144 - Val Loss: 12282.588867 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1569/5000] - Train Loss: 13589.565240 - Val Loss: 12273.579861 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1570/5000] - Train Loss: 13593.902262 - Val Loss: 12279.559787 - Time: 1.26s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1571/5000] - Train Loss: 13585.856147 - Val Loss: 12265.290256 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1572/5000] - Train Loss: 13579.377794 - Val Loss: 12247.092773 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1573/5000] - Train Loss: 13573.672038 - Val Loss: 12245.845161 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1574/5000] - Train Loss: 13574.259087 - Val Loss: 12240.618056 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1575/5000] - Train Loss: 13560.372531 - Val Loss: 12238.624674 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1576/5000] - Train Loss: 13541.788113 - Val Loss: 12222.766819 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1577/5000] - Train Loss: 13545.519911 - Val Loss: 12213.662760 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1578/5000] - Train Loss: 13540.739421 - Val Loss: 12211.270291 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1579/5000] - Train Loss: 13516.424832 - Val Loss: 12194.988281 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1580/5000] - Train Loss: 13498.205349 - Val Loss: 12190.649740 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1581/5000] - Train Loss: 13529.329427 - Val Loss: 12182.979709 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1582/5000] - Train Loss: 13499.505968 - Val Loss: 12176.925239 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1583/5000] - Train Loss: 13490.491428 - Val Loss: 12169.203451 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1584/5000] - Train Loss: 13489.272271 - Val Loss: 12162.942274 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1585/5000] - Train Loss: 13488.321560 - Val Loss: 12149.268663 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1586/5000] - Train Loss: 13473.874783 - Val Loss: 12141.223633 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1587/5000] - Train Loss: 13467.985324 - Val Loss: 12145.768663 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1588/5000] - Train Loss: 13476.696723 - Val Loss: 12129.030924 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1589/5000] - Train Loss: 13471.575602 - Val Loss: 12125.270616 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1590/5000] - Train Loss: 13458.121257 - Val Loss: 12117.902127 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1591/5000] - Train Loss: 13429.876845 - Val Loss: 12102.431532 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1592/5000] - Train Loss: 13435.592204 - Val Loss: 12104.080512 - Time: 1.24s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1593/5000] - Train Loss: 13408.212348 - Val Loss: 12099.741645 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1594/5000] - Train Loss: 13412.840956 - Val Loss: 12085.355577 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1595/5000] - Train Loss: 13405.788140 - Val Loss: 12085.015516 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1596/5000] - Train Loss: 13408.252740 - Val Loss: 12074.884115 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1597/5000] - Train Loss: 13391.122233 - Val Loss: 12064.474067 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1598/5000] - Train Loss: 13403.876926 - Val Loss: 12055.688043 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1599/5000] - Train Loss: 13372.077908 - Val Loss: 12047.680230 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1600/5000] - Train Loss: 13373.421875 - Val Loss: 12047.547092 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1601/5000] - Train Loss: 13379.658366 - Val Loss: 12031.796332 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1602/5000] - Train Loss: 13373.491645 - Val Loss: 12027.692817 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1603/5000] - Train Loss: 13325.659017 - Val Loss: 12020.110786 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1604/5000] - Train Loss: 13332.376302 - Val Loss: 12013.852756 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1605/5000] - Train Loss: 13357.314453 - Val Loss: 12006.215278 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1606/5000] - Train Loss: 13338.401286 - Val Loss: 11997.127062 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1607/5000] - Train Loss: 13313.796956 - Val Loss: 11988.647027 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1608/5000] - Train Loss: 13305.246067 - Val Loss: 11981.245117 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1609/5000] - Train Loss: 13291.669135 - Val Loss: 11981.887261 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1610/5000] - Train Loss: 13301.828776 - Val Loss: 11963.989366 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1611/5000] - Train Loss: 13290.572130 - Val Loss: 11960.817925 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1612/5000] - Train Loss: 13319.676839 - Val Loss: 11964.568902 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1613/5000] - Train Loss: 13271.745307 - Val Loss: 11945.617296 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1614/5000] - Train Loss: 13255.423964 - Val Loss: 11948.189996 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1615/5000] - Train Loss: 13285.556912 - Val Loss: 11930.405599 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1616/5000] - Train Loss: 13269.276476 - Val Loss: 11922.305447 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1617/5000] - Train Loss: 13257.085910 - Val Loss: 11923.602214 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1618/5000] - Train Loss: 13237.125298 - Val Loss: 11910.353407 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1619/5000] - Train Loss: 13246.699788 - Val Loss: 11912.487088 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1620/5000] - Train Loss: 13236.020182 - Val Loss: 11898.273112 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1621/5000] - Train Loss: 13227.130724 - Val Loss: 11890.726562 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1622/5000] - Train Loss: 13216.454644 - Val Loss: 11886.406901 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1623/5000] - Train Loss: 13200.115397 - Val Loss: 11872.489800 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1624/5000] - Train Loss: 13216.450656 - Val Loss: 11876.315213 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1625/5000] - Train Loss: 13193.110948 - Val Loss: 11857.982856 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1626/5000] - Train Loss: 13210.211073 - Val Loss: 11855.164280 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1627/5000] - Train Loss: 13187.160889 - Val Loss: 11845.176866 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1628/5000] - Train Loss: 13196.983643 - Val Loss: 11842.333550 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1629/5000] - Train Loss: 13188.352892 - Val Loss: 11838.833442 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1630/5000] - Train Loss: 13194.083713 - Val Loss: 11827.709635 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1631/5000] - Train Loss: 13153.556966 - Val Loss: 11828.635200 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1632/5000] - Train Loss: 13174.624078 - Val Loss: 11819.016059 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1633/5000] - Train Loss: 13178.843506 - Val Loss: 11809.704427 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1634/5000] - Train Loss: 13148.186334 - Val Loss: 11803.944336 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1635/5000] - Train Loss: 13137.959717 - Val Loss: 11794.446289 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1636/5000] - Train Loss: 13123.255561 - Val Loss: 11787.623806 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1637/5000] - Train Loss: 13137.559787 - Val Loss: 11777.672852 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1638/5000] - Train Loss: 13093.477349 - Val Loss: 11776.825955 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1639/5000] - Train Loss: 13093.511013 - Val Loss: 11762.227214 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1640/5000] - Train Loss: 13101.409451 - Val Loss: 11755.753364 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1641/5000] - Train Loss: 13067.330349 - Val Loss: 11755.780382 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1642/5000] - Train Loss: 13100.121121 - Val Loss: 11742.326714 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1643/5000] - Train Loss: 13081.154839 - Val Loss: 11741.544705 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1644/5000] - Train Loss: 13061.922390 - Val Loss: 11736.183051 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1645/5000] - Train Loss: 13067.844699 - Val Loss: 11734.804253 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1646/5000] - Train Loss: 13068.611952 - Val Loss: 11720.858724 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1647/5000] - Train Loss: 13082.481879 - Val Loss: 11718.787760 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1648/5000] - Train Loss: 13044.491428 - Val Loss: 11705.038303 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1649/5000] - Train Loss: 13042.257189 - Val Loss: 11696.797635 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1650/5000] - Train Loss: 13052.784288 - Val Loss: 11694.283203 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1651/5000] - Train Loss: 13044.364773 - Val Loss: 11684.564887 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1652/5000] - Train Loss: 13021.747667 - Val Loss: 11679.804253 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1653/5000] - Train Loss: 13016.533122 - Val Loss: 11683.002387 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1654/5000] - Train Loss: 13013.173014 - Val Loss: 11665.665473 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1655/5000] - Train Loss: 12995.485541 - Val Loss: 11662.339193 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1656/5000] - Train Loss: 13024.836155 - Val Loss: 11652.785482 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1657/5000] - Train Loss: 12999.812283 - Val Loss: 11646.049045 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1658/5000] - Train Loss: 13004.639567 - Val Loss: 11643.125217 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1659/5000] - Train Loss: 12963.938178 - Val Loss: 11638.222439 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1660/5000] - Train Loss: 12982.808404 - Val Loss: 11633.190755 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1661/5000] - Train Loss: 12976.865126 - Val Loss: 11625.637478 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1662/5000] - Train Loss: 12968.430935 - Val Loss: 11616.344293 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1663/5000] - Train Loss: 12961.334093 - Val Loss: 11612.762912 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1664/5000] - Train Loss: 12942.054579 - Val Loss: 11604.354058 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1665/5000] - Train Loss: 12929.005832 - Val Loss: 11597.927626 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1666/5000] - Train Loss: 12933.661458 - Val Loss: 11593.964410 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1667/5000] - Train Loss: 12959.133247 - Val Loss: 11587.656576 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1668/5000] - Train Loss: 12929.349745 - Val Loss: 11578.473416 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1669/5000] - Train Loss: 12923.264242 - Val Loss: 11572.149414 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1670/5000] - Train Loss: 12931.267931 - Val Loss: 11567.846354 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1671/5000] - Train Loss: 12897.543511 - Val Loss: 11567.679579 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1672/5000] - Train Loss: 12901.169162 - Val Loss: 11552.647678 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1673/5000] - Train Loss: 12886.977973 - Val Loss: 11549.684028 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1674/5000] - Train Loss: 12899.333713 - Val Loss: 11550.738390 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1675/5000] - Train Loss: 12894.547282 - Val Loss: 11540.591688 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1676/5000] - Train Loss: 12898.076497 - Val Loss: 11530.964084 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1677/5000] - Train Loss: 12866.292209 - Val Loss: 11523.008572 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1678/5000] - Train Loss: 12880.768094 - Val Loss: 11523.748155 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1679/5000] - Train Loss: 12879.164822 - Val Loss: 11517.361979 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1680/5000] - Train Loss: 12844.140164 - Val Loss: 11517.463433 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1681/5000] - Train Loss: 12855.910482 - Val Loss: 11516.264214 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1682/5000] - Train Loss: 12851.532335 - Val Loss: 11505.628255 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1683/5000] - Train Loss: 12827.242567 - Val Loss: 11500.445312 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1684/5000] - Train Loss: 12831.678033 - Val Loss: 11490.590061 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1685/5000] - Train Loss: 12837.123915 - Val Loss: 11486.856337 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1686/5000] - Train Loss: 12822.258816 - Val Loss: 11479.002279 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1687/5000] - Train Loss: 12832.678331 - Val Loss: 11466.894206 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1688/5000] - Train Loss: 12803.670844 - Val Loss: 11459.302517 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1689/5000] - Train Loss: 12799.974989 - Val Loss: 11458.280707 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1690/5000] - Train Loss: 12802.273139 - Val Loss: 11453.993273 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1691/5000] - Train Loss: 12807.152642 - Val Loss: 11449.656250 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1692/5000] - Train Loss: 12840.570231 - Val Loss: 11442.373155 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1693/5000] - Train Loss: 12782.826009 - Val Loss: 11439.733941 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1694/5000] - Train Loss: 12813.119548 - Val Loss: 11434.725911 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1695/5000] - Train Loss: 12767.117269 - Val Loss: 11431.889323 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1696/5000] - Train Loss: 12769.268772 - Val Loss: 11422.295356 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1697/5000] - Train Loss: 12768.078695 - Val Loss: 11405.631836 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1698/5000] - Train Loss: 12775.304498 - Val Loss: 11403.194987 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1699/5000] - Train Loss: 12745.344618 - Val Loss: 11404.423611 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1700/5000] - Train Loss: 12737.493842 - Val Loss: 11393.818142 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1701/5000] - Train Loss: 12746.958794 - Val Loss: 11396.863607 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1702/5000] - Train Loss: 12725.377550 - Val Loss: 11387.238824 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1703/5000] - Train Loss: 12724.126845 - Val Loss: 11388.645725 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1704/5000] - Train Loss: 12733.722873 - Val Loss: 11375.969293 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1705/5000] - Train Loss: 12723.328125 - Val Loss: 11370.333116 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1706/5000] - Train Loss: 12725.722629 - Val Loss: 11358.222548 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1707/5000] - Train Loss: 12725.878445 - Val Loss: 11353.509657 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1708/5000] - Train Loss: 12719.478407 - Val Loss: 11346.762587 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1709/5000] - Train Loss: 12702.749837 - Val Loss: 11349.742405 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1710/5000] - Train Loss: 12691.223117 - Val Loss: 11344.846680 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1711/5000] - Train Loss: 12691.678494 - Val Loss: 11339.836155 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1712/5000] - Train Loss: 12681.662191 - Val Loss: 11337.763563 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1713/5000] - Train Loss: 12669.107069 - Val Loss: 11334.296658 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1714/5000] - Train Loss: 12690.212782 - Val Loss: 11322.972873 - Time: 1.25s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1715/5000] - Train Loss: 12671.022380 - Val Loss: 11308.402344 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1716/5000] - Train Loss: 12646.283583 - Val Loss: 11305.942817 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1717/5000] - Train Loss: 12638.581000 - Val Loss: 11302.647352 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1718/5000] - Train Loss: 12654.260688 - Val Loss: 11302.453234 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1719/5000] - Train Loss: 12651.935384 - Val Loss: 11290.619900 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1720/5000] - Train Loss: 12635.604085 - Val Loss: 11297.714301 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1721/5000] - Train Loss: 12655.660807 - Val Loss: 11284.327582 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1722/5000] - Train Loss: 12631.515598 - Val Loss: 11276.447700 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1723/5000] - Train Loss: 12613.011366 - Val Loss: 11278.546007 - Time: 1.26s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1724/5000] - Train Loss: 12617.573975 - Val Loss: 11263.814887 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1725/5000] - Train Loss: 12623.095215 - Val Loss: 11263.167752 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1726/5000] - Train Loss: 12635.677517 - Val Loss: 11252.137804 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1727/5000] - Train Loss: 12601.468099 - Val Loss: 11250.253364 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1728/5000] - Train Loss: 12611.826470 - Val Loss: 11242.427843 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1729/5000] - Train Loss: 12580.651476 - Val Loss: 11234.957357 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1730/5000] - Train Loss: 12589.356500 - Val Loss: 11234.087131 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1731/5000] - Train Loss: 12595.865234 - Val Loss: 11226.110243 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1732/5000] - Train Loss: 12594.871419 - Val Loss: 11231.263021 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1733/5000] - Train Loss: 12565.960720 - Val Loss: 11221.060438 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1734/5000] - Train Loss: 12562.237006 - Val Loss: 11219.664714 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1735/5000] - Train Loss: 12566.917372 - Val Loss: 11208.980360 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1736/5000] - Train Loss: 12543.648546 - Val Loss: 11203.564670 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1737/5000] - Train Loss: 12559.099392 - Val Loss: 11190.601020 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1738/5000] - Train Loss: 12550.682671 - Val Loss: 11195.464627 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1739/5000] - Train Loss: 12545.453559 - Val Loss: 11186.872179 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1740/5000] - Train Loss: 12551.710314 - Val Loss: 11176.923177 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1741/5000] - Train Loss: 12527.852458 - Val Loss: 11173.046332 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1742/5000] - Train Loss: 12534.877821 - Val Loss: 11170.376302 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1743/5000] - Train Loss: 12529.139703 - Val Loss: 11168.138346 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1744/5000] - Train Loss: 12513.888726 - Val Loss: 11165.300130 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1745/5000] - Train Loss: 12518.725803 - Val Loss: 11153.673937 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1746/5000] - Train Loss: 12497.744303 - Val Loss: 11150.596571 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1747/5000] - Train Loss: 12521.915934 - Val Loss: 11145.428602 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1748/5000] - Train Loss: 12483.132378 - Val Loss: 11137.111111 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1749/5000] - Train Loss: 12500.231662 - Val Loss: 11144.017036 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1750/5000] - Train Loss: 12513.364231 - Val Loss: 11129.724501 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1751/5000] - Train Loss: 12499.499620 - Val Loss: 11131.627604 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1752/5000] - Train Loss: 12466.742513 - Val Loss: 11124.196072 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1753/5000] - Train Loss: 12477.337104 - Val Loss: 11119.330729 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1754/5000] - Train Loss: 12471.988118 - Val Loss: 11108.814128 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1755/5000] - Train Loss: 12481.160916 - Val Loss: 11111.109049 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1756/5000] - Train Loss: 12465.314263 - Val Loss: 11108.279188 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1757/5000] - Train Loss: 12451.861762 - Val Loss: 11098.561632 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1758/5000] - Train Loss: 12451.876085 - Val Loss: 11088.999891 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1759/5000] - Train Loss: 12455.025716 - Val Loss: 11085.212782 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1760/5000] - Train Loss: 12446.920627 - Val Loss: 11088.788194 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1761/5000] - Train Loss: 12463.312364 - Val Loss: 11071.525499 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1762/5000] - Train Loss: 12421.736057 - Val Loss: 11071.439670 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1763/5000] - Train Loss: 12425.728082 - Val Loss: 11062.788628 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1764/5000] - Train Loss: 12407.849908 - Val Loss: 11059.394531 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1765/5000] - Train Loss: 12439.572483 - Val Loss: 11065.006727 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1766/5000] - Train Loss: 12428.219754 - Val Loss: 11055.608181 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1767/5000] - Train Loss: 12403.199002 - Val Loss: 11048.315104 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1768/5000] - Train Loss: 12404.369385 - Val Loss: 11043.795681 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1769/5000] - Train Loss: 12390.206190 - Val Loss: 11043.716146 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1770/5000] - Train Loss: 12401.792074 - Val Loss: 11031.719944 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1771/5000] - Train Loss: 12404.324409 - Val Loss: 11035.862413 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1772/5000] - Train Loss: 12378.701796 - Val Loss: 11024.325521 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1773/5000] - Train Loss: 12394.904704 - Val Loss: 11025.514974 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1774/5000] - Train Loss: 12381.231337 - Val Loss: 11009.689562 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1775/5000] - Train Loss: 12363.230930 - Val Loss: 11014.326172 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1776/5000] - Train Loss: 12352.390408 - Val Loss: 11007.643555 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1777/5000] - Train Loss: 12370.917182 - Val Loss: 11009.118707 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1778/5000] - Train Loss: 12361.892144 - Val Loss: 11002.196181 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1779/5000] - Train Loss: 12369.998562 - Val Loss: 10994.142904 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1780/5000] - Train Loss: 12368.672146 - Val Loss: 10988.450521 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1781/5000] - Train Loss: 12353.832275 - Val Loss: 10981.061957 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1782/5000] - Train Loss: 12333.769830 - Val Loss: 10974.401042 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1783/5000] - Train Loss: 12330.437690 - Val Loss: 10976.717990 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1784/5000] - Train Loss: 12349.914605 - Val Loss: 10973.090495 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1785/5000] - Train Loss: 12321.206923 - Val Loss: 10966.307075 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1786/5000] - Train Loss: 12339.848145 - Val Loss: 10966.700521 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1787/5000] - Train Loss: 12327.502930 - Val Loss: 10959.948025 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1788/5000] - Train Loss: 12304.257975 - Val Loss: 10959.155165 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1789/5000] - Train Loss: 12301.664334 - Val Loss: 10938.389540 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1790/5000] - Train Loss: 12300.778781 - Val Loss: 10939.739800 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1791/5000] - Train Loss: 12315.992296 - Val Loss: 10936.255425 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1792/5000] - Train Loss: 12283.718397 - Val Loss: 10932.221897 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1793/5000] - Train Loss: 12291.784776 - Val Loss: 10923.097548 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1794/5000] - Train Loss: 12263.882867 - Val Loss: 10926.400065 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1795/5000] - Train Loss: 12274.205621 - Val Loss: 10921.649848 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1796/5000] - Train Loss: 12285.540337 - Val Loss: 10911.954102 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1797/5000] - Train Loss: 12257.515218 - Val Loss: 10914.507812 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1798/5000] - Train Loss: 12279.408420 - Val Loss: 10904.221463 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1799/5000] - Train Loss: 12250.509603 - Val Loss: 10895.040690 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1800/5000] - Train Loss: 12253.873020 - Val Loss: 10900.918077 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1801/5000] - Train Loss: 12270.214789 - Val Loss: 10896.416667 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1802/5000] - Train Loss: 12235.497342 - Val Loss: 10881.986437 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1803/5000] - Train Loss: 12231.782335 - Val Loss: 10881.238281 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1804/5000] - Train Loss: 12251.501899 - Val Loss: 10870.745117 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1805/5000] - Train Loss: 12235.053684 - Val Loss: 10871.411241 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1806/5000] - Train Loss: 12221.259060 - Val Loss: 10875.756185 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1807/5000] - Train Loss: 12248.251899 - Val Loss: 10859.659939 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1808/5000] - Train Loss: 12228.225857 - Val Loss: 10858.046115 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1809/5000] - Train Loss: 12233.004422 - Val Loss: 10856.348741 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1810/5000] - Train Loss: 12225.658610 - Val Loss: 10854.850477 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1811/5000] - Train Loss: 12227.968696 - Val Loss: 10862.000109 - Time: 1.37s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1812/5000] - Train Loss: 12215.713976 - Val Loss: 10851.277561 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1813/5000] - Train Loss: 12226.232476 - Val Loss: 10844.750543 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1814/5000] - Train Loss: 12208.471354 - Val Loss: 10839.327908 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1815/5000] - Train Loss: 12210.734592 - Val Loss: 10824.842556 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1816/5000] - Train Loss: 12188.393609 - Val Loss: 10826.164931 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1817/5000] - Train Loss: 12200.043267 - Val Loss: 10817.953668 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1818/5000] - Train Loss: 12208.156331 - Val Loss: 10815.411784 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1819/5000] - Train Loss: 12176.580811 - Val Loss: 10825.983290 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1820/5000] - Train Loss: 12172.766385 - Val Loss: 10806.931532 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1821/5000] - Train Loss: 12171.671143 - Val Loss: 10803.714627 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1822/5000] - Train Loss: 12156.213216 - Val Loss: 10806.241753 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1823/5000] - Train Loss: 12165.691542 - Val Loss: 10799.034180 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1824/5000] - Train Loss: 12160.767605 - Val Loss: 10793.324436 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1825/5000] - Train Loss: 12145.636583 - Val Loss: 10789.468099 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1826/5000] - Train Loss: 12163.391466 - Val Loss: 10789.013346 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1827/5000] - Train Loss: 12146.858263 - Val Loss: 10789.402778 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1828/5000] - Train Loss: 12153.154975 - Val Loss: 10783.499457 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1829/5000] - Train Loss: 12134.226725 - Val Loss: 10778.344727 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1830/5000] - Train Loss: 12169.387994 - Val Loss: 10768.156793 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1831/5000] - Train Loss: 12123.170790 - Val Loss: 10770.786784 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1832/5000] - Train Loss: 12141.812527 - Val Loss: 10760.533529 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1833/5000] - Train Loss: 12112.448459 - Val Loss: 10761.611545 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1834/5000] - Train Loss: 12118.634630 - Val Loss: 10761.315972 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1835/5000] - Train Loss: 12121.424642 - Val Loss: 10755.361111 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1836/5000] - Train Loss: 12103.291287 - Val Loss: 10750.908095 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1837/5000] - Train Loss: 12109.218804 - Val Loss: 10743.334744 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1838/5000] - Train Loss: 12120.261692 - Val Loss: 10738.182617 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1839/5000] - Train Loss: 12112.896729 - Val Loss: 10735.103624 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1840/5000] - Train Loss: 12100.914741 - Val Loss: 10727.879774 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1841/5000] - Train Loss: 12090.050863 - Val Loss: 10723.337782 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1842/5000] - Train Loss: 12085.826742 - Val Loss: 10728.761176 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1843/5000] - Train Loss: 12082.250434 - Val Loss: 10717.805990 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1844/5000] - Train Loss: 12059.636854 - Val Loss: 10715.378689 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1845/5000] - Train Loss: 12078.709635 - Val Loss: 10714.944987 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1846/5000] - Train Loss: 12082.906820 - Val Loss: 10708.433160 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1847/5000] - Train Loss: 12073.866211 - Val Loss: 10704.374783 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1848/5000] - Train Loss: 12062.751302 - Val Loss: 10698.791450 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1849/5000] - Train Loss: 12058.047933 - Val Loss: 10697.576606 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1850/5000] - Train Loss: 12052.269043 - Val Loss: 10689.893555 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1851/5000] - Train Loss: 12042.117106 - Val Loss: 10685.738173 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1852/5000] - Train Loss: 12033.323893 - Val Loss: 10673.371745 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1853/5000] - Train Loss: 12047.589681 - Val Loss: 10672.968750 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1854/5000] - Train Loss: 12043.737684 - Val Loss: 10671.945312 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1855/5000] - Train Loss: 12037.022759 - Val Loss: 10668.532227 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1856/5000] - Train Loss: 12011.911296 - Val Loss: 10664.791233 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1857/5000] - Train Loss: 12026.152289 - Val Loss: 10661.132161 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1858/5000] - Train Loss: 12023.538005 - Val Loss: 10661.703125 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1859/5000] - Train Loss: 12022.881293 - Val Loss: 10662.666775 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1860/5000] - Train Loss: 12010.594238 - Val Loss: 10659.556424 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1861/5000] - Train Loss: 12033.688612 - Val Loss: 10647.127713 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1862/5000] - Train Loss: 12011.731011 - Val Loss: 10646.965495 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1863/5000] - Train Loss: 12006.304389 - Val Loss: 10639.081055 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1864/5000] - Train Loss: 11997.175184 - Val Loss: 10637.010959 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1865/5000] - Train Loss: 11998.374268 - Val Loss: 10640.226128 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1866/5000] - Train Loss: 12003.833333 - Val Loss: 10626.547852 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1867/5000] - Train Loss: 12002.569499 - Val Loss: 10633.979818 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1868/5000] - Train Loss: 11997.695367 - Val Loss: 10639.483398 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1869/5000] - Train Loss: 12006.531169 - Val Loss: 10625.047418 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1870/5000] - Train Loss: 11983.152507 - Val Loss: 10628.544488 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1871/5000] - Train Loss: 11984.260769 - Val Loss: 10612.564779 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1872/5000] - Train Loss: 11977.612223 - Val Loss: 10610.570855 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1873/5000] - Train Loss: 11968.989773 - Val Loss: 10609.486654 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1874/5000] - Train Loss: 11980.946235 - Val Loss: 10600.101237 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1875/5000] - Train Loss: 11964.925890 - Val Loss: 10602.297309 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1876/5000] - Train Loss: 11958.092204 - Val Loss: 10590.456163 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1877/5000] - Train Loss: 11959.593424 - Val Loss: 10588.381510 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1878/5000] - Train Loss: 11954.856635 - Val Loss: 10582.364475 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1879/5000] - Train Loss: 11922.988607 - Val Loss: 10569.629340 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1880/5000] - Train Loss: 11947.576796 - Val Loss: 10570.610786 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1881/5000] - Train Loss: 11937.615614 - Val Loss: 10574.310330 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1882/5000] - Train Loss: 11913.259440 - Val Loss: 10566.776150 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1883/5000] - Train Loss: 11921.188992 - Val Loss: 10574.841688 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1884/5000] - Train Loss: 11931.790148 - Val Loss: 10565.033095 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1885/5000] - Train Loss: 11917.847900 - Val Loss: 10561.345703 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1886/5000] - Train Loss: 11929.298530 - Val Loss: 10557.093424 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1887/5000] - Train Loss: 11925.182699 - Val Loss: 10556.049696 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1888/5000] - Train Loss: 11885.867974 - Val Loss: 10553.593533 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1889/5000] - Train Loss: 11891.704210 - Val Loss: 10548.562391 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1890/5000] - Train Loss: 11920.433974 - Val Loss: 10534.374240 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1891/5000] - Train Loss: 11903.579590 - Val Loss: 10538.568468 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1892/5000] - Train Loss: 11902.278727 - Val Loss: 10530.190104 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1893/5000] - Train Loss: 11892.853814 - Val Loss: 10535.843099 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1894/5000] - Train Loss: 11911.376546 - Val Loss: 10530.306315 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1895/5000] - Train Loss: 11912.322862 - Val Loss: 10528.028212 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1896/5000] - Train Loss: 11890.663222 - Val Loss: 10525.386610 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1897/5000] - Train Loss: 11883.890137 - Val Loss: 10516.984266 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1898/5000] - Train Loss: 11880.825141 - Val Loss: 10509.446072 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1899/5000] - Train Loss: 11868.758762 - Val Loss: 10509.604601 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1900/5000] - Train Loss: 11868.156386 - Val Loss: 10506.660156 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1901/5000] - Train Loss: 11877.269341 - Val Loss: 10498.162435 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1902/5000] - Train Loss: 11856.907796 - Val Loss: 10506.639648 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1903/5000] - Train Loss: 11859.513970 - Val Loss: 10487.661133 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1904/5000] - Train Loss: 11839.331543 - Val Loss: 10489.493490 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1905/5000] - Train Loss: 11846.484863 - Val Loss: 10491.750651 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1906/5000] - Train Loss: 11842.336263 - Val Loss: 10483.945855 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1907/5000] - Train Loss: 11846.475586 - Val Loss: 10492.434028 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1908/5000] - Train Loss: 11839.241428 - Val Loss: 10479.789714 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1909/5000] - Train Loss: 11847.088704 - Val Loss: 10479.597548 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1910/5000] - Train Loss: 11839.778022 - Val Loss: 10476.996528 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1911/5000] - Train Loss: 11859.786323 - Val Loss: 10472.639865 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1912/5000] - Train Loss: 11828.559625 - Val Loss: 10468.168077 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1913/5000] - Train Loss: 11838.218316 - Val Loss: 10461.677300 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1914/5000] - Train Loss: 11829.355414 - Val Loss: 10461.280924 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1915/5000] - Train Loss: 11820.373888 - Val Loss: 10467.465820 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1916/5000] - Train Loss: 11831.596083 - Val Loss: 10464.145942 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1917/5000] - Train Loss: 11808.613905 - Val Loss: 10451.946181 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1918/5000] - Train Loss: 11806.312012 - Val Loss: 10446.484701 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1919/5000] - Train Loss: 11804.405952 - Val Loss: 10448.957899 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1920/5000] - Train Loss: 11817.505181 - Val Loss: 10436.552083 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1921/5000] - Train Loss: 11803.821615 - Val Loss: 10436.532444 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1922/5000] - Train Loss: 11786.622233 - Val Loss: 10428.407769 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1923/5000] - Train Loss: 11816.453044 - Val Loss: 10432.451497 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1924/5000] - Train Loss: 11796.181342 - Val Loss: 10430.386176 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1925/5000] - Train Loss: 11788.213949 - Val Loss: 10429.272135 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [1926/5000] - Train Loss: 11780.574436 - Val Loss: 10419.223850 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1927/5000] - Train Loss: 11765.924696 - Val Loss: 10415.914714 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1928/5000] - Train Loss: 11790.419244 - Val Loss: 10416.042318 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1929/5000] - Train Loss: 11774.633681 - Val Loss: 10408.643012 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1930/5000] - Train Loss: 11762.197157 - Val Loss: 10408.363715 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1931/5000] - Train Loss: 11784.614366 - Val Loss: 10414.799045 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1932/5000] - Train Loss: 11764.247152 - Val Loss: 10402.976345 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1933/5000] - Train Loss: 11757.705648 - Val Loss: 10400.204319 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1934/5000] - Train Loss: 11767.696940 - Val Loss: 10395.971246 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1935/5000] - Train Loss: 11770.482720 - Val Loss: 10396.581163 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1936/5000] - Train Loss: 11741.769586 - Val Loss: 10395.323459 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1937/5000] - Train Loss: 11777.899007 - Val Loss: 10382.112088 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1938/5000] - Train Loss: 11755.985406 - Val Loss: 10389.109484 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1939/5000] - Train Loss: 11763.399495 - Val Loss: 10388.412435 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1940/5000] - Train Loss: 11745.819933 - Val Loss: 10387.067708 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [1941/5000] - Train Loss: 11742.963298 - Val Loss: 10377.967556 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1942/5000] - Train Loss: 11733.323459 - Val Loss: 10377.957465 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1943/5000] - Train Loss: 11747.303168 - Val Loss: 10384.262153 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1944/5000] - Train Loss: 11744.053521 - Val Loss: 10374.964627 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1945/5000] - Train Loss: 11744.301731 - Val Loss: 10372.510417 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1946/5000] - Train Loss: 11715.876736 - Val Loss: 10365.182292 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1947/5000] - Train Loss: 11726.471463 - Val Loss: 10370.360894 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1948/5000] - Train Loss: 11719.612142 - Val Loss: 10363.037326 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1949/5000] - Train Loss: 11719.190294 - Val Loss: 10355.375651 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1950/5000] - Train Loss: 11703.498128 - Val Loss: 10346.480686 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1951/5000] - Train Loss: 11705.172038 - Val Loss: 10353.080946 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1952/5000] - Train Loss: 11720.878120 - Val Loss: 10344.068034 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1953/5000] - Train Loss: 11722.017117 - Val Loss: 10347.283854 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1954/5000] - Train Loss: 11711.854872 - Val Loss: 10345.286892 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1955/5000] - Train Loss: 11690.574707 - Val Loss: 10329.886610 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1956/5000] - Train Loss: 11692.364800 - Val Loss: 10343.175564 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1957/5000] - Train Loss: 11678.061496 - Val Loss: 10334.145182 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1958/5000] - Train Loss: 11683.220595 - Val Loss: 10327.457899 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1959/5000] - Train Loss: 11688.101725 - Val Loss: 10319.981554 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1960/5000] - Train Loss: 11692.120578 - Val Loss: 10323.283854 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1961/5000] - Train Loss: 11679.275391 - Val Loss: 10318.364149 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1962/5000] - Train Loss: 11672.749430 - Val Loss: 10319.385200 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1963/5000] - Train Loss: 11683.640516 - Val Loss: 10311.333225 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1964/5000] - Train Loss: 11669.587023 - Val Loss: 10305.984049 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1965/5000] - Train Loss: 11641.809760 - Val Loss: 10313.784939 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1966/5000] - Train Loss: 11672.897759 - Val Loss: 10310.082574 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1967/5000] - Train Loss: 11652.844293 - Val Loss: 10306.643338 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [1968/5000] - Train Loss: 11661.175456 - Val Loss: 10298.160156 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1969/5000] - Train Loss: 11640.413032 - Val Loss: 10293.450412 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1970/5000] - Train Loss: 11658.702203 - Val Loss: 10289.108724 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1971/5000] - Train Loss: 11644.490180 - Val Loss: 10290.776150 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1972/5000] - Train Loss: 11648.667589 - Val Loss: 10285.944553 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1973/5000] - Train Loss: 11640.747423 - Val Loss: 10290.373047 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1974/5000] - Train Loss: 11646.783067 - Val Loss: 10275.129340 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1975/5000] - Train Loss: 11620.286784 - Val Loss: 10270.304145 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1976/5000] - Train Loss: 11622.116943 - Val Loss: 10263.304905 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1977/5000] - Train Loss: 11631.723036 - Val Loss: 10275.115994 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1978/5000] - Train Loss: 11624.998562 - Val Loss: 10266.679145 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1979/5000] - Train Loss: 11618.607015 - Val Loss: 10261.161892 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1980/5000] - Train Loss: 11621.191162 - Val Loss: 10270.484701 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1981/5000] - Train Loss: 11617.781033 - Val Loss: 10257.928385 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1982/5000] - Train Loss: 11626.515082 - Val Loss: 10262.052843 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1983/5000] - Train Loss: 11613.610080 - Val Loss: 10260.750760 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1984/5000] - Train Loss: 11615.905680 - Val Loss: 10254.032769 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1985/5000] - Train Loss: 11614.720323 - Val Loss: 10255.058268 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1986/5000] - Train Loss: 11602.370117 - Val Loss: 10242.351671 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1987/5000] - Train Loss: 11587.364529 - Val Loss: 10245.147569 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1988/5000] - Train Loss: 11611.775960 - Val Loss: 10247.137804 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1989/5000] - Train Loss: 11595.357775 - Val Loss: 10229.110352 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1990/5000] - Train Loss: 11595.679009 - Val Loss: 10231.790799 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1991/5000] - Train Loss: 11592.993462 - Val Loss: 10231.783420 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1992/5000] - Train Loss: 11585.765869 - Val Loss: 10226.496419 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1993/5000] - Train Loss: 11580.071343 - Val Loss: 10223.708659 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1994/5000] - Train Loss: 11597.787706 - Val Loss: 10225.704644 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [1995/5000] - Train Loss: 11581.170546 - Val Loss: 10225.636610 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [1996/5000] - Train Loss: 11565.961426 - Val Loss: 10217.884223 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1997/5000] - Train Loss: 11563.633084 - Val Loss: 10217.880534 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1998/5000] - Train Loss: 11581.809977 - Val Loss: 10213.383681 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [1999/5000] - Train Loss: 11566.168240 - Val Loss: 10207.120334 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2000/5000] - Train Loss: 11558.514079 - Val Loss: 10204.226128 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2001/5000] - Train Loss: 11557.687636 - Val Loss: 10205.902778 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2002/5000] - Train Loss: 11574.617025 - Val Loss: 10201.858941 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2003/5000] - Train Loss: 11561.960368 - Val Loss: 10194.988498 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2004/5000] - Train Loss: 11555.118734 - Val Loss: 10195.698242 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2005/5000] - Train Loss: 11551.945231 - Val Loss: 10190.312826 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2006/5000] - Train Loss: 11561.197483 - Val Loss: 10194.207465 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2007/5000] - Train Loss: 11528.864882 - Val Loss: 10183.770942 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2008/5000] - Train Loss: 11558.122586 - Val Loss: 10186.245660 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2009/5000] - Train Loss: 11532.008247 - Val Loss: 10175.678602 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2010/5000] - Train Loss: 11535.736410 - Val Loss: 10176.551432 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2011/5000] - Train Loss: 11534.296360 - Val Loss: 10172.393446 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2012/5000] - Train Loss: 11513.289931 - Val Loss: 10167.302517 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2013/5000] - Train Loss: 11528.524550 - Val Loss: 10166.768446 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2014/5000] - Train Loss: 11529.336941 - Val Loss: 10166.622613 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2015/5000] - Train Loss: 11531.716146 - Val Loss: 10160.694878 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2016/5000] - Train Loss: 11525.978868 - Val Loss: 10158.513021 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2017/5000] - Train Loss: 11542.985786 - Val Loss: 10162.295464 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2018/5000] - Train Loss: 11519.600505 - Val Loss: 10163.086046 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2019/5000] - Train Loss: 11507.813368 - Val Loss: 10156.479709 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2020/5000] - Train Loss: 11525.715359 - Val Loss: 10156.902995 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2021/5000] - Train Loss: 11512.258898 - Val Loss: 10147.721029 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2022/5000] - Train Loss: 11509.870171 - Val Loss: 10146.796441 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2023/5000] - Train Loss: 11499.833822 - Val Loss: 10139.653537 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2024/5000] - Train Loss: 11502.394857 - Val Loss: 10136.175998 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2025/5000] - Train Loss: 11513.778347 - Val Loss: 10133.577582 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2026/5000] - Train Loss: 11473.770535 - Val Loss: 10137.561849 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2027/5000] - Train Loss: 11486.005561 - Val Loss: 10134.962999 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2028/5000] - Train Loss: 11462.849175 - Val Loss: 10129.145508 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2029/5000] - Train Loss: 11471.508762 - Val Loss: 10127.870768 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2030/5000] - Train Loss: 11476.477431 - Val Loss: 10130.385742 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2031/5000] - Train Loss: 11476.389811 - Val Loss: 10129.425239 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2032/5000] - Train Loss: 11479.896294 - Val Loss: 10121.570095 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2033/5000] - Train Loss: 11478.177816 - Val Loss: 10133.898220 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2034/5000] - Train Loss: 11498.351915 - Val Loss: 10121.282444 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2035/5000] - Train Loss: 11459.767008 - Val Loss: 10109.544813 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2036/5000] - Train Loss: 11488.151937 - Val Loss: 10108.565755 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2037/5000] - Train Loss: 11469.950114 - Val Loss: 10111.781684 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2038/5000] - Train Loss: 11459.202257 - Val Loss: 10109.870768 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2039/5000] - Train Loss: 11452.581000 - Val Loss: 10107.004666 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2040/5000] - Train Loss: 11460.671197 - Val Loss: 10101.442166 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2041/5000] - Train Loss: 11466.000868 - Val Loss: 10098.281793 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2042/5000] - Train Loss: 11461.296061 - Val Loss: 10093.205729 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2043/5000] - Train Loss: 11441.081434 - Val Loss: 10111.109158 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2044/5000] - Train Loss: 11445.883572 - Val Loss: 10093.548286 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2045/5000] - Train Loss: 11451.103597 - Val Loss: 10091.649523 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2046/5000] - Train Loss: 11444.574300 - Val Loss: 10089.616428 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2047/5000] - Train Loss: 11440.872694 - Val Loss: 10089.639431 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2048/5000] - Train Loss: 11445.778402 - Val Loss: 10091.145725 - Time: 1.26s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2049/5000] - Train Loss: 11432.282769 - Val Loss: 10080.164714 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2050/5000] - Train Loss: 11431.467936 - Val Loss: 10085.048611 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2051/5000] - Train Loss: 11429.622613 - Val Loss: 10072.188151 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2052/5000] - Train Loss: 11454.396593 - Val Loss: 10078.639865 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2053/5000] - Train Loss: 11430.137885 - Val Loss: 10072.865451 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2054/5000] - Train Loss: 11422.362061 - Val Loss: 10063.926541 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2055/5000] - Train Loss: 11428.678928 - Val Loss: 10063.457031 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2056/5000] - Train Loss: 11404.031738 - Val Loss: 10064.263021 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2057/5000] - Train Loss: 11404.378852 - Val Loss: 10053.800456 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2058/5000] - Train Loss: 11416.369168 - Val Loss: 10055.220486 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2059/5000] - Train Loss: 11412.781331 - Val Loss: 10054.253689 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2060/5000] - Train Loss: 11408.100559 - Val Loss: 10054.630100 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2061/5000] - Train Loss: 11396.419542 - Val Loss: 10046.344293 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2062/5000] - Train Loss: 11399.581868 - Val Loss: 10042.031576 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2063/5000] - Train Loss: 11403.598741 - Val Loss: 10052.289605 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2064/5000] - Train Loss: 11410.840251 - Val Loss: 10041.854492 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2065/5000] - Train Loss: 11400.370334 - Val Loss: 10039.391168 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2066/5000] - Train Loss: 11380.725694 - Val Loss: 10037.187934 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2067/5000] - Train Loss: 11382.760444 - Val Loss: 10038.502713 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2068/5000] - Train Loss: 11385.856689 - Val Loss: 10031.685981 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2069/5000] - Train Loss: 11378.053955 - Val Loss: 10035.789062 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2070/5000] - Train Loss: 11387.699571 - Val Loss: 10025.843859 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2071/5000] - Train Loss: 11366.202637 - Val Loss: 10026.106228 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2072/5000] - Train Loss: 11383.612576 - Val Loss: 10026.985352 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2073/5000] - Train Loss: 11369.702176 - Val Loss: 10023.916233 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2074/5000] - Train Loss: 11350.937771 - Val Loss: 10015.432292 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2075/5000] - Train Loss: 11359.973796 - Val Loss: 10007.773329 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2076/5000] - Train Loss: 11362.629150 - Val Loss: 10014.187826 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2077/5000] - Train Loss: 11359.727919 - Val Loss: 10012.355035 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2078/5000] - Train Loss: 11365.505344 - Val Loss: 10014.210286 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2079/5000] - Train Loss: 11353.115940 - Val Loss: 10006.180556 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2080/5000] - Train Loss: 11368.300618 - Val Loss: 10002.963542 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2081/5000] - Train Loss: 11351.776557 - Val Loss: 10000.463976 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2082/5000] - Train Loss: 11347.112929 - Val Loss: 9994.983941 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2083/5000] - Train Loss: 11355.548937 - Val Loss: 10001.903646 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2084/5000] - Train Loss: 11362.439941 - Val Loss: 10000.135308 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2085/5000] - Train Loss: 11345.728326 - Val Loss: 10001.302734 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2086/5000] - Train Loss: 11321.224121 - Val Loss: 9987.198242 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2087/5000] - Train Loss: 11343.493517 - Val Loss: 9983.834635 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2088/5000] - Train Loss: 11339.442735 - Val Loss: 9997.978516 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2089/5000] - Train Loss: 11342.928630 - Val Loss: 9983.213325 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2090/5000] - Train Loss: 11338.162489 - Val Loss: 9983.950412 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2091/5000] - Train Loss: 11333.776638 - Val Loss: 9978.289388 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2092/5000] - Train Loss: 11351.429769 - Val Loss: 9978.124349 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2093/5000] - Train Loss: 11321.886529 - Val Loss: 9978.542969 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2094/5000] - Train Loss: 11322.019016 - Val Loss: 9975.810004 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2095/5000] - Train Loss: 11320.449436 - Val Loss: 9966.867296 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2096/5000] - Train Loss: 11323.885688 - Val Loss: 9970.450955 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2097/5000] - Train Loss: 11321.618896 - Val Loss: 9976.883138 - Time: 1.24s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2098/5000] - Train Loss: 11311.246962 - Val Loss: 9974.537652 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2099/5000] - Train Loss: 11318.026855 - Val Loss: 9966.598524 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2100/5000] - Train Loss: 11318.414985 - Val Loss: 9960.606337 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2101/5000] - Train Loss: 11301.008789 - Val Loss: 9962.384440 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2102/5000] - Train Loss: 11305.922445 - Val Loss: 9956.668511 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2103/5000] - Train Loss: 11297.128798 - Val Loss: 9960.829536 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2104/5000] - Train Loss: 11315.865723 - Val Loss: 9961.312500 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2105/5000] - Train Loss: 11317.388048 - Val Loss: 9952.323025 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2106/5000] - Train Loss: 11316.264893 - Val Loss: 9955.023329 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2107/5000] - Train Loss: 11288.472738 - Val Loss: 9952.731337 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2108/5000] - Train Loss: 11300.357313 - Val Loss: 9946.921115 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2109/5000] - Train Loss: 11285.590495 - Val Loss: 9948.559462 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2110/5000] - Train Loss: 11286.907444 - Val Loss: 9943.374023 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2111/5000] - Train Loss: 11294.518609 - Val Loss: 9939.499457 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2112/5000] - Train Loss: 11288.040283 - Val Loss: 9938.981988 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2113/5000] - Train Loss: 11296.174642 - Val Loss: 9930.750977 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2114/5000] - Train Loss: 11274.406494 - Val Loss: 9927.606988 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2115/5000] - Train Loss: 11274.238037 - Val Loss: 9927.289822 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2116/5000] - Train Loss: 11287.702745 - Val Loss: 9926.262912 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2117/5000] - Train Loss: 11265.599555 - Val Loss: 9921.581923 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2118/5000] - Train Loss: 11276.813205 - Val Loss: 9927.134223 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2119/5000] - Train Loss: 11274.692274 - Val Loss: 9927.831923 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2120/5000] - Train Loss: 11261.984375 - Val Loss: 9920.920681 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2121/5000] - Train Loss: 11263.195801 - Val Loss: 9908.653863 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2122/5000] - Train Loss: 11253.112847 - Val Loss: 9908.948459 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2123/5000] - Train Loss: 11254.035319 - Val Loss: 9908.470812 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2124/5000] - Train Loss: 11268.927002 - Val Loss: 9909.496853 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2125/5000] - Train Loss: 11259.818848 - Val Loss: 9911.524523 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2126/5000] - Train Loss: 11260.447890 - Val Loss: 9902.724392 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2127/5000] - Train Loss: 11246.193658 - Val Loss: 9902.538954 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2128/5000] - Train Loss: 11259.876980 - Val Loss: 9897.841254 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2129/5000] - Train Loss: 11251.685954 - Val Loss: 9890.609484 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2130/5000] - Train Loss: 11252.269151 - Val Loss: 9898.134657 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2131/5000] - Train Loss: 11234.709147 - Val Loss: 9898.577908 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2132/5000] - Train Loss: 11239.607422 - Val Loss: 9895.599175 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2133/5000] - Train Loss: 11243.281494 - Val Loss: 9896.590169 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2134/5000] - Train Loss: 11216.462674 - Val Loss: 9883.273980 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2135/5000] - Train Loss: 11245.699354 - Val Loss: 9896.765625 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2136/5000] - Train Loss: 11246.886827 - Val Loss: 9889.316623 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2137/5000] - Train Loss: 11234.850532 - Val Loss: 9886.409722 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2138/5000] - Train Loss: 11209.828857 - Val Loss: 9896.579753 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2139/5000] - Train Loss: 11231.368490 - Val Loss: 9884.353516 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2140/5000] - Train Loss: 11222.476725 - Val Loss: 9868.596029 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2141/5000] - Train Loss: 11233.354574 - Val Loss: 9876.185330 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2142/5000] - Train Loss: 11214.729519 - Val Loss: 9882.401801 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2143/5000] - Train Loss: 11218.504991 - Val Loss: 9875.348307 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2144/5000] - Train Loss: 11210.502333 - Val Loss: 9883.588542 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2145/5000] - Train Loss: 11202.178901 - Val Loss: 9880.275282 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2146/5000] - Train Loss: 11233.881022 - Val Loss: 9866.232096 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2147/5000] - Train Loss: 11210.398410 - Val Loss: 9867.990126 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2148/5000] - Train Loss: 11201.522461 - Val Loss: 9862.542752 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2149/5000] - Train Loss: 11209.794488 - Val Loss: 9864.385851 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2150/5000] - Train Loss: 11217.341309 - Val Loss: 9875.959744 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2151/5000] - Train Loss: 11209.126899 - Val Loss: 9854.348199 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2152/5000] - Train Loss: 11199.093262 - Val Loss: 9854.899306 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2153/5000] - Train Loss: 11207.495714 - Val Loss: 9854.460938 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2154/5000] - Train Loss: 11209.383979 - Val Loss: 9850.808702 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2155/5000] - Train Loss: 11188.033393 - Val Loss: 9856.553277 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2156/5000] - Train Loss: 11194.685411 - Val Loss: 9852.044596 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2157/5000] - Train Loss: 11174.913086 - Val Loss: 9851.474175 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2158/5000] - Train Loss: 11187.561469 - Val Loss: 9845.120226 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2159/5000] - Train Loss: 11207.988336 - Val Loss: 9838.136719 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2160/5000] - Train Loss: 11188.604167 - Val Loss: 9840.918945 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2161/5000] - Train Loss: 11174.878282 - Val Loss: 9841.671984 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2162/5000] - Train Loss: 11172.959229 - Val Loss: 9834.318468 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2163/5000] - Train Loss: 11185.889350 - Val Loss: 9838.541341 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2164/5000] - Train Loss: 11186.161458 - Val Loss: 9832.306315 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2165/5000] - Train Loss: 11170.811659 - Val Loss: 9828.969184 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2166/5000] - Train Loss: 11175.041857 - Val Loss: 9831.352648 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2167/5000] - Train Loss: 11156.831000 - Val Loss: 9831.731554 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2168/5000] - Train Loss: 11152.174506 - Val Loss: 9820.184462 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2169/5000] - Train Loss: 11152.673855 - Val Loss: 9828.693576 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2170/5000] - Train Loss: 11155.373237 - Val Loss: 9819.354058 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2171/5000] - Train Loss: 11164.531413 - Val Loss: 9827.224935 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2172/5000] - Train Loss: 11153.764160 - Val Loss: 9814.834635 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2173/5000] - Train Loss: 11159.110433 - Val Loss: 9819.996311 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2174/5000] - Train Loss: 11163.275472 - Val Loss: 9815.028429 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2175/5000] - Train Loss: 11142.137316 - Val Loss: 9811.253689 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2176/5000] - Train Loss: 11156.552544 - Val Loss: 9810.407769 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2177/5000] - Train Loss: 11132.556803 - Val Loss: 9815.096246 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2178/5000] - Train Loss: 11163.059679 - Val Loss: 9803.996636 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2179/5000] - Train Loss: 11128.872206 - Val Loss: 9809.481011 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2180/5000] - Train Loss: 11130.155029 - Val Loss: 9806.242405 - Time: 1.25s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2181/5000] - Train Loss: 11126.023058 - Val Loss: 9804.755968 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2182/5000] - Train Loss: 11135.397217 - Val Loss: 9806.026476 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2183/5000] - Train Loss: 11141.858995 - Val Loss: 9803.366970 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2184/5000] - Train Loss: 11118.947537 - Val Loss: 9805.134440 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2185/5000] - Train Loss: 11112.834364 - Val Loss: 9790.925673 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2186/5000] - Train Loss: 11110.697374 - Val Loss: 9792.795464 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2187/5000] - Train Loss: 11121.251329 - Val Loss: 9788.636610 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2188/5000] - Train Loss: 11133.007107 - Val Loss: 9789.840712 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2189/5000] - Train Loss: 11118.144613 - Val Loss: 9787.723633 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2190/5000] - Train Loss: 11114.824599 - Val Loss: 9772.501736 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2191/5000] - Train Loss: 11112.012099 - Val Loss: 9782.737522 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2192/5000] - Train Loss: 11110.662435 - Val Loss: 9791.069010 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2193/5000] - Train Loss: 11125.427409 - Val Loss: 9780.694661 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2194/5000] - Train Loss: 11113.998589 - Val Loss: 9776.201931 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2195/5000] - Train Loss: 11107.454970 - Val Loss: 9773.211372 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2196/5000] - Train Loss: 11096.906006 - Val Loss: 9768.007053 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2197/5000] - Train Loss: 11092.468777 - Val Loss: 9776.302300 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2198/5000] - Train Loss: 11093.961127 - Val Loss: 9768.911350 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2199/5000] - Train Loss: 11104.680610 - Val Loss: 9759.130751 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2200/5000] - Train Loss: 11094.661919 - Val Loss: 9770.777452 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2201/5000] - Train Loss: 11097.336209 - Val Loss: 9766.580512 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2202/5000] - Train Loss: 11083.104899 - Val Loss: 9768.676541 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2203/5000] - Train Loss: 11094.159776 - Val Loss: 9767.147569 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2204/5000] - Train Loss: 11094.599772 - Val Loss: 9754.234592 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2205/5000] - Train Loss: 11083.754964 - Val Loss: 9751.745009 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2206/5000] - Train Loss: 11078.923069 - Val Loss: 9760.131293 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2207/5000] - Train Loss: 11093.423014 - Val Loss: 9752.872287 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2208/5000] - Train Loss: 11068.374783 - Val Loss: 9746.414822 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2209/5000] - Train Loss: 11089.391168 - Val Loss: 9746.191189 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2210/5000] - Train Loss: 11055.658474 - Val Loss: 9737.836589 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2211/5000] - Train Loss: 11078.821940 - Val Loss: 9748.138563 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2212/5000] - Train Loss: 11059.814453 - Val Loss: 9748.344184 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2213/5000] - Train Loss: 11070.003309 - Val Loss: 9740.590495 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2214/5000] - Train Loss: 11081.881592 - Val Loss: 9744.332574 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2215/5000] - Train Loss: 11064.001899 - Val Loss: 9740.187934 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2216/5000] - Train Loss: 11041.229357 - Val Loss: 9739.093967 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2217/5000] - Train Loss: 11062.754747 - Val Loss: 9734.925239 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2218/5000] - Train Loss: 11065.816081 - Val Loss: 9736.801975 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2219/5000] - Train Loss: 11069.447021 - Val Loss: 9729.407335 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2220/5000] - Train Loss: 11074.342068 - Val Loss: 9735.278429 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2221/5000] - Train Loss: 11038.447862 - Val Loss: 9730.290582 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2222/5000] - Train Loss: 11042.015679 - Val Loss: 9733.243815 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2223/5000] - Train Loss: 11053.860107 - Val Loss: 9724.310004 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2224/5000] - Train Loss: 11047.816271 - Val Loss: 9720.315972 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2225/5000] - Train Loss: 11059.532172 - Val Loss: 9726.542535 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2226/5000] - Train Loss: 11051.361979 - Val Loss: 9715.310221 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2227/5000] - Train Loss: 11058.104411 - Val Loss: 9710.629774 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2228/5000] - Train Loss: 11039.504530 - Val Loss: 9717.481988 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2229/5000] - Train Loss: 11036.890544 - Val Loss: 9712.819553 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2230/5000] - Train Loss: 11025.296902 - Val Loss: 9715.379557 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2231/5000] - Train Loss: 11027.132080 - Val Loss: 9706.015625 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2232/5000] - Train Loss: 11032.177083 - Val Loss: 9716.131076 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2233/5000] - Train Loss: 11025.074300 - Val Loss: 9705.146918 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2234/5000] - Train Loss: 11012.391168 - Val Loss: 9710.271159 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2235/5000] - Train Loss: 11047.543783 - Val Loss: 9703.517904 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2236/5000] - Train Loss: 11042.803928 - Val Loss: 9711.490885 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2237/5000] - Train Loss: 11027.081380 - Val Loss: 9703.340929 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2238/5000] - Train Loss: 10995.072537 - Val Loss: 9702.091037 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2239/5000] - Train Loss: 11018.430284 - Val Loss: 9692.400391 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2240/5000] - Train Loss: 11023.176053 - Val Loss: 9701.352322 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2241/5000] - Train Loss: 11027.185330 - Val Loss: 9684.274631 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2242/5000] - Train Loss: 11012.937256 - Val Loss: 9691.091037 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2243/5000] - Train Loss: 11008.417019 - Val Loss: 9687.669162 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2244/5000] - Train Loss: 11020.319336 - Val Loss: 9688.607205 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2245/5000] - Train Loss: 11008.786404 - Val Loss: 9691.082357 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2246/5000] - Train Loss: 11031.593126 - Val Loss: 9692.417969 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2247/5000] - Train Loss: 10995.138102 - Val Loss: 9689.009115 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2248/5000] - Train Loss: 11014.623752 - Val Loss: 9672.801649 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2249/5000] - Train Loss: 11019.424778 - Val Loss: 9690.022244 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2250/5000] - Train Loss: 11006.708198 - Val Loss: 9682.744900 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2251/5000] - Train Loss: 11004.623427 - Val Loss: 9680.936198 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2252/5000] - Train Loss: 10989.016683 - Val Loss: 9673.463542 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2253/5000] - Train Loss: 10989.386692 - Val Loss: 9675.839735 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2254/5000] - Train Loss: 10978.425049 - Val Loss: 9676.888780 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2255/5000] - Train Loss: 10994.106608 - Val Loss: 9675.113281 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2256/5000] - Train Loss: 10998.768202 - Val Loss: 9664.619141 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2257/5000] - Train Loss: 10985.331624 - Val Loss: 9665.484809 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2258/5000] - Train Loss: 10990.709229 - Val Loss: 9668.193034 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2259/5000] - Train Loss: 10974.988308 - Val Loss: 9663.989475 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2260/5000] - Train Loss: 10986.428819 - Val Loss: 9663.935872 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2261/5000] - Train Loss: 10987.871446 - Val Loss: 9658.428711 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2262/5000] - Train Loss: 10976.824571 - Val Loss: 9660.389540 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2263/5000] - Train Loss: 10978.507812 - Val Loss: 9660.728841 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2264/5000] - Train Loss: 10982.819092 - Val Loss: 9647.014214 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2265/5000] - Train Loss: 10984.058078 - Val Loss: 9654.503906 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2266/5000] - Train Loss: 10967.227268 - Val Loss: 9645.067925 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2267/5000] - Train Loss: 10960.741862 - Val Loss: 9645.745877 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2268/5000] - Train Loss: 10969.999403 - Val Loss: 9648.627496 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2269/5000] - Train Loss: 10975.031304 - Val Loss: 9651.440321 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2270/5000] - Train Loss: 10964.770643 - Val Loss: 9642.830404 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2271/5000] - Train Loss: 10964.497531 - Val Loss: 9647.130425 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2272/5000] - Train Loss: 10962.506944 - Val Loss: 9645.343316 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2273/5000] - Train Loss: 10946.605930 - Val Loss: 9640.442925 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2274/5000] - Train Loss: 10957.627197 - Val Loss: 9638.202908 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2275/5000] - Train Loss: 10944.896729 - Val Loss: 9632.021810 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2276/5000] - Train Loss: 10979.167860 - Val Loss: 9638.745660 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2277/5000] - Train Loss: 10938.414144 - Val Loss: 9636.451389 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2278/5000] - Train Loss: 10957.212945 - Val Loss: 9627.310547 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2279/5000] - Train Loss: 10946.300537 - Val Loss: 9631.523872 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2280/5000] - Train Loss: 10943.872423 - Val Loss: 9630.477648 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2281/5000] - Train Loss: 10941.623427 - Val Loss: 9629.093750 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2282/5000] - Train Loss: 10948.841309 - Val Loss: 9620.592448 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2283/5000] - Train Loss: 10930.020996 - Val Loss: 9619.525933 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2284/5000] - Train Loss: 10938.958388 - Val Loss: 9622.540148 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2285/5000] - Train Loss: 10935.130697 - Val Loss: 9622.543077 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2286/5000] - Train Loss: 10931.074164 - Val Loss: 9622.560113 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2287/5000] - Train Loss: 10938.162082 - Val Loss: 9630.288411 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2288/5000] - Train Loss: 10915.600450 - Val Loss: 9615.674696 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2289/5000] - Train Loss: 10916.612793 - Val Loss: 9618.567274 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2290/5000] - Train Loss: 10928.853950 - Val Loss: 9614.135308 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2291/5000] - Train Loss: 10915.453695 - Val Loss: 9610.947157 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2292/5000] - Train Loss: 10925.637994 - Val Loss: 9616.656684 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2293/5000] - Train Loss: 10915.576090 - Val Loss: 9609.481228 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2294/5000] - Train Loss: 10932.257975 - Val Loss: 9612.891493 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2295/5000] - Train Loss: 10915.522922 - Val Loss: 9612.630751 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2296/5000] - Train Loss: 10920.069227 - Val Loss: 9596.158963 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2297/5000] - Train Loss: 10916.200602 - Val Loss: 9606.378472 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2298/5000] - Train Loss: 10899.406901 - Val Loss: 9603.608507 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2299/5000] - Train Loss: 10912.150770 - Val Loss: 9603.895074 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2300/5000] - Train Loss: 10925.732666 - Val Loss: 9602.713542 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2301/5000] - Train Loss: 10900.695231 - Val Loss: 9600.417101 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2302/5000] - Train Loss: 10908.522190 - Val Loss: 9591.845920 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2303/5000] - Train Loss: 10903.985840 - Val Loss: 9591.172418 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2304/5000] - Train Loss: 10902.901069 - Val Loss: 9597.433377 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2305/5000] - Train Loss: 10901.120578 - Val Loss: 9597.746311 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2306/5000] - Train Loss: 10898.663574 - Val Loss: 9590.151150 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2307/5000] - Train Loss: 10890.315999 - Val Loss: 9581.749566 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2308/5000] - Train Loss: 10895.004774 - Val Loss: 9580.902018 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2309/5000] - Train Loss: 10888.185791 - Val Loss: 9578.649523 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2310/5000] - Train Loss: 10889.021918 - Val Loss: 9578.744141 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2311/5000] - Train Loss: 10886.076633 - Val Loss: 9577.491211 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2312/5000] - Train Loss: 10891.959310 - Val Loss: 9579.491211 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2313/5000] - Train Loss: 10891.826470 - Val Loss: 9580.410916 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2314/5000] - Train Loss: 10881.272298 - Val Loss: 9577.578668 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2315/5000] - Train Loss: 10870.637912 - Val Loss: 9578.918294 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2316/5000] - Train Loss: 10897.908556 - Val Loss: 9575.498698 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2317/5000] - Train Loss: 10895.017578 - Val Loss: 9564.007595 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2318/5000] - Train Loss: 10873.233534 - Val Loss: 9565.634983 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2319/5000] - Train Loss: 10864.995470 - Val Loss: 9571.482313 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2320/5000] - Train Loss: 10870.167046 - Val Loss: 9562.305556 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2321/5000] - Train Loss: 10880.439345 - Val Loss: 9571.741102 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2322/5000] - Train Loss: 10881.235297 - Val Loss: 9559.401042 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2323/5000] - Train Loss: 10880.344021 - Val Loss: 9563.964735 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2324/5000] - Train Loss: 10869.158474 - Val Loss: 9578.273980 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2325/5000] - Train Loss: 10862.882270 - Val Loss: 9572.343099 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2326/5000] - Train Loss: 10858.848253 - Val Loss: 9561.055773 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2327/5000] - Train Loss: 10864.424154 - Val Loss: 9564.600477 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2328/5000] - Train Loss: 10886.164524 - Val Loss: 9551.328668 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2329/5000] - Train Loss: 10856.055962 - Val Loss: 9552.921766 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2330/5000] - Train Loss: 10842.513916 - Val Loss: 9556.769531 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2331/5000] - Train Loss: 10828.371609 - Val Loss: 9546.582248 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2332/5000] - Train Loss: 10851.256402 - Val Loss: 9549.798069 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2333/5000] - Train Loss: 10857.425836 - Val Loss: 9542.388455 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2334/5000] - Train Loss: 10859.954807 - Val Loss: 9549.015082 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2335/5000] - Train Loss: 10837.591878 - Val Loss: 9544.000109 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2336/5000] - Train Loss: 10870.612413 - Val Loss: 9545.526693 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2337/5000] - Train Loss: 10842.632107 - Val Loss: 9539.026584 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2338/5000] - Train Loss: 10832.087429 - Val Loss: 9535.196398 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2339/5000] - Train Loss: 10828.830105 - Val Loss: 9544.555122 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2340/5000] - Train Loss: 10825.688802 - Val Loss: 9539.619900 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2341/5000] - Train Loss: 10836.444553 - Val Loss: 9535.396593 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2342/5000] - Train Loss: 10839.763075 - Val Loss: 9538.161350 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2343/5000] - Train Loss: 10831.412679 - Val Loss: 9531.351237 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2344/5000] - Train Loss: 10828.013211 - Val Loss: 9538.847656 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2345/5000] - Train Loss: 10831.036947 - Val Loss: 9536.888889 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2346/5000] - Train Loss: 10824.874647 - Val Loss: 9530.560221 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2347/5000] - Train Loss: 10826.435710 - Val Loss: 9527.904297 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2348/5000] - Train Loss: 10826.194960 - Val Loss: 9531.508355 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2349/5000] - Train Loss: 10839.088596 - Val Loss: 9519.406033 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2350/5000] - Train Loss: 10815.066433 - Val Loss: 9520.101128 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2351/5000] - Train Loss: 10829.124295 - Val Loss: 9518.173611 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2352/5000] - Train Loss: 10829.225098 - Val Loss: 9524.939345 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2353/5000] - Train Loss: 10836.136854 - Val Loss: 9527.288737 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2354/5000] - Train Loss: 10816.438694 - Val Loss: 9530.025825 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2355/5000] - Train Loss: 10801.791178 - Val Loss: 9525.141385 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2356/5000] - Train Loss: 10821.490479 - Val Loss: 9519.502062 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2357/5000] - Train Loss: 10806.803874 - Val Loss: 9511.207140 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2358/5000] - Train Loss: 10807.109863 - Val Loss: 9515.152235 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2359/5000] - Train Loss: 10811.895481 - Val Loss: 9508.855903 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2360/5000] - Train Loss: 10809.466607 - Val Loss: 9513.829861 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2361/5000] - Train Loss: 10799.985786 - Val Loss: 9511.683702 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2362/5000] - Train Loss: 10794.336833 - Val Loss: 9511.418511 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2363/5000] - Train Loss: 10804.198079 - Val Loss: 9504.290799 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2364/5000] - Train Loss: 10808.574843 - Val Loss: 9502.424696 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2365/5000] - Train Loss: 10793.428874 - Val Loss: 9506.142795 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2366/5000] - Train Loss: 10786.218506 - Val Loss: 9502.311415 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2367/5000] - Train Loss: 10792.906169 - Val Loss: 9503.657335 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2368/5000] - Train Loss: 10800.122694 - Val Loss: 9494.279622 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2369/5000] - Train Loss: 10797.257840 - Val Loss: 9500.990451 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2370/5000] - Train Loss: 10786.239827 - Val Loss: 9482.028320 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2371/5000] - Train Loss: 10803.751953 - Val Loss: 9494.862196 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2372/5000] - Train Loss: 10786.448296 - Val Loss: 9490.469835 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2373/5000] - Train Loss: 10786.354438 - Val Loss: 9489.332682 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2374/5000] - Train Loss: 10790.545410 - Val Loss: 9488.959852 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2375/5000] - Train Loss: 10793.834418 - Val Loss: 9486.394640 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2376/5000] - Train Loss: 10778.408691 - Val Loss: 9489.057183 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2377/5000] - Train Loss: 10759.751492 - Val Loss: 9475.372938 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2378/5000] - Train Loss: 10783.608046 - Val Loss: 9480.619466 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2379/5000] - Train Loss: 10780.237874 - Val Loss: 9473.849609 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2380/5000] - Train Loss: 10769.701172 - Val Loss: 9474.842231 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2381/5000] - Train Loss: 10772.322808 - Val Loss: 9481.953993 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2382/5000] - Train Loss: 10769.538086 - Val Loss: 9487.041992 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2383/5000] - Train Loss: 10779.137560 - Val Loss: 9470.841797 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2384/5000] - Train Loss: 10767.540473 - Val Loss: 9471.917426 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2385/5000] - Train Loss: 10767.056207 - Val Loss: 9472.423611 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2386/5000] - Train Loss: 10768.638211 - Val Loss: 9472.568902 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2387/5000] - Train Loss: 10760.090658 - Val Loss: 9478.230143 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2388/5000] - Train Loss: 10764.582520 - Val Loss: 9476.726562 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2389/5000] - Train Loss: 10769.078098 - Val Loss: 9468.022461 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2390/5000] - Train Loss: 10771.746446 - Val Loss: 9475.836046 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2391/5000] - Train Loss: 10765.295058 - Val Loss: 9463.230903 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2392/5000] - Train Loss: 10756.398817 - Val Loss: 9469.338759 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2393/5000] - Train Loss: 10756.131673 - Val Loss: 9461.113715 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2394/5000] - Train Loss: 10765.166043 - Val Loss: 9466.177843 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2395/5000] - Train Loss: 10744.880317 - Val Loss: 9462.611654 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2396/5000] - Train Loss: 10743.686252 - Val Loss: 9461.936523 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2397/5000] - Train Loss: 10755.439806 - Val Loss: 9462.823351 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2398/5000] - Train Loss: 10732.992242 - Val Loss: 9458.954427 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2399/5000] - Train Loss: 10751.101915 - Val Loss: 9464.918186 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2400/5000] - Train Loss: 10736.542535 - Val Loss: 9449.459310 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2401/5000] - Train Loss: 10743.988146 - Val Loss: 9446.780490 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2402/5000] - Train Loss: 10733.528483 - Val Loss: 9455.934570 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2403/5000] - Train Loss: 10765.894504 - Val Loss: 9464.782444 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2404/5000] - Train Loss: 10755.933051 - Val Loss: 9456.458116 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2405/5000] - Train Loss: 10734.475640 - Val Loss: 9444.657552 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2406/5000] - Train Loss: 10726.514974 - Val Loss: 9449.062826 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2407/5000] - Train Loss: 10736.557319 - Val Loss: 9448.445312 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2408/5000] - Train Loss: 10742.064345 - Val Loss: 9432.788845 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2409/5000] - Train Loss: 10737.961344 - Val Loss: 9457.671549 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2410/5000] - Train Loss: 10725.647515 - Val Loss: 9443.768663 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2411/5000] - Train Loss: 10731.048991 - Val Loss: 9442.148112 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2412/5000] - Train Loss: 10735.135579 - Val Loss: 9440.854275 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2413/5000] - Train Loss: 10728.441840 - Val Loss: 9440.001628 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2414/5000] - Train Loss: 10724.590685 - Val Loss: 9435.016493 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2415/5000] - Train Loss: 10714.712755 - Val Loss: 9435.060330 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2416/5000] - Train Loss: 10706.969781 - Val Loss: 9438.675239 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2417/5000] - Train Loss: 10725.810954 - Val Loss: 9432.208876 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2418/5000] - Train Loss: 10718.340061 - Val Loss: 9432.554036 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2419/5000] - Train Loss: 10714.322401 - Val Loss: 9430.888129 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2420/5000] - Train Loss: 10718.822944 - Val Loss: 9431.350477 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2421/5000] - Train Loss: 10708.134847 - Val Loss: 9431.018880 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2422/5000] - Train Loss: 10701.820828 - Val Loss: 9430.583550 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2423/5000] - Train Loss: 10715.315538 - Val Loss: 9430.367513 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2424/5000] - Train Loss: 10702.462375 - Val Loss: 9427.687174 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2425/5000] - Train Loss: 10709.676351 - Val Loss: 9420.695312 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2426/5000] - Train Loss: 10704.253282 - Val Loss: 9422.916450 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2427/5000] - Train Loss: 10703.380941 - Val Loss: 9426.537760 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2428/5000] - Train Loss: 10695.063639 - Val Loss: 9414.975694 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2429/5000] - Train Loss: 10702.374268 - Val Loss: 9416.993056 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2430/5000] - Train Loss: 10690.213976 - Val Loss: 9408.702582 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2431/5000] - Train Loss: 10691.324219 - Val Loss: 9416.844184 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2432/5000] - Train Loss: 10700.304009 - Val Loss: 9404.493815 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2433/5000] - Train Loss: 10705.201470 - Val Loss: 9413.413954 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2434/5000] - Train Loss: 10688.628988 - Val Loss: 9413.049805 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2435/5000] - Train Loss: 10679.368951 - Val Loss: 9415.912760 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2436/5000] - Train Loss: 10701.524523 - Val Loss: 9408.557292 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2437/5000] - Train Loss: 10681.119737 - Val Loss: 9415.379015 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2438/5000] - Train Loss: 10673.856527 - Val Loss: 9402.300347 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2439/5000] - Train Loss: 10666.459446 - Val Loss: 9401.337891 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2440/5000] - Train Loss: 10673.146403 - Val Loss: 9402.101780 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2441/5000] - Train Loss: 10672.449734 - Val Loss: 9398.084744 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2442/5000] - Train Loss: 10674.910292 - Val Loss: 9405.533095 - Time: 1.34s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2443/5000] - Train Loss: 10677.954644 - Val Loss: 9392.380751 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2444/5000] - Train Loss: 10678.446506 - Val Loss: 9404.753581 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2445/5000] - Train Loss: 10671.722195 - Val Loss: 9389.938802 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2446/5000] - Train Loss: 10659.201525 - Val Loss: 9398.084635 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2447/5000] - Train Loss: 10675.868110 - Val Loss: 9391.925239 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2448/5000] - Train Loss: 10669.593506 - Val Loss: 9394.996962 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2449/5000] - Train Loss: 10669.685411 - Val Loss: 9388.791341 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2450/5000] - Train Loss: 10656.175646 - Val Loss: 9383.553819 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2451/5000] - Train Loss: 10674.886203 - Val Loss: 9386.556532 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2452/5000] - Train Loss: 10670.857585 - Val Loss: 9383.178277 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2453/5000] - Train Loss: 10676.381104 - Val Loss: 9392.945095 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2454/5000] - Train Loss: 10669.182210 - Val Loss: 9393.305447 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2455/5000] - Train Loss: 10683.140788 - Val Loss: 9385.370117 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2456/5000] - Train Loss: 10669.724474 - Val Loss: 9375.075087 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2457/5000] - Train Loss: 10663.099040 - Val Loss: 9388.613281 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2458/5000] - Train Loss: 10639.067518 - Val Loss: 9384.597873 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2459/5000] - Train Loss: 10664.609185 - Val Loss: 9384.964952 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2460/5000] - Train Loss: 10645.152181 - Val Loss: 9378.101345 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2461/5000] - Train Loss: 10648.547119 - Val Loss: 9372.553494 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2462/5000] - Train Loss: 10649.020237 - Val Loss: 9383.824219 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2463/5000] - Train Loss: 10642.558078 - Val Loss: 9390.482856 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2464/5000] - Train Loss: 10659.429796 - Val Loss: 9379.993707 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2465/5000] - Train Loss: 10651.828885 - Val Loss: 9376.300347 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2466/5000] - Train Loss: 10660.018012 - Val Loss: 9370.709310 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2467/5000] - Train Loss: 10654.874891 - Val Loss: 9372.972873 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2468/5000] - Train Loss: 10643.214654 - Val Loss: 9370.809787 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2469/5000] - Train Loss: 10645.902534 - Val Loss: 9361.172201 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2470/5000] - Train Loss: 10644.774984 - Val Loss: 9367.696072 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2471/5000] - Train Loss: 10641.314480 - Val Loss: 9373.838976 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2472/5000] - Train Loss: 10624.831841 - Val Loss: 9362.814562 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2473/5000] - Train Loss: 10625.741781 - Val Loss: 9371.647027 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2474/5000] - Train Loss: 10648.157281 - Val Loss: 9357.664605 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2475/5000] - Train Loss: 10636.999973 - Val Loss: 9354.634766 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2476/5000] - Train Loss: 10638.329346 - Val Loss: 9362.135308 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2477/5000] - Train Loss: 10609.681559 - Val Loss: 9356.787760 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2478/5000] - Train Loss: 10620.560764 - Val Loss: 9356.229384 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2479/5000] - Train Loss: 10621.153592 - Val Loss: 9353.767144 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2480/5000] - Train Loss: 10613.024848 - Val Loss: 9355.285590 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2481/5000] - Train Loss: 10613.663059 - Val Loss: 9356.344510 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2482/5000] - Train Loss: 10607.508138 - Val Loss: 9350.274848 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2483/5000] - Train Loss: 10619.477159 - Val Loss: 9342.310764 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2484/5000] - Train Loss: 10620.397407 - Val Loss: 9352.361979 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2485/5000] - Train Loss: 10623.164280 - Val Loss: 9356.472982 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2486/5000] - Train Loss: 10599.222819 - Val Loss: 9341.523003 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2487/5000] - Train Loss: 10611.770237 - Val Loss: 9347.961263 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2488/5000] - Train Loss: 10605.718533 - Val Loss: 9341.105577 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2489/5000] - Train Loss: 10602.149848 - Val Loss: 9346.159071 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2490/5000] - Train Loss: 10616.802762 - Val Loss: 9344.370443 - Time: 1.24s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2491/5000] - Train Loss: 10607.388211 - Val Loss: 9336.526259 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2492/5000] - Train Loss: 10593.449707 - Val Loss: 9341.412326 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2493/5000] - Train Loss: 10606.901991 - Val Loss: 9334.894965 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2494/5000] - Train Loss: 10606.777669 - Val Loss: 9341.687500 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2495/5000] - Train Loss: 10597.670790 - Val Loss: 9339.137587 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2496/5000] - Train Loss: 10596.361545 - Val Loss: 9330.094076 - Time: 1.17s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2497/5000] - Train Loss: 10599.111192 - Val Loss: 9325.686740 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2498/5000] - Train Loss: 10591.074029 - Val Loss: 9331.510634 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2499/5000] - Train Loss: 10601.979085 - Val Loss: 9333.639106 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2500/5000] - Train Loss: 10570.967773 - Val Loss: 9335.940213 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2501/5000] - Train Loss: 10609.127740 - Val Loss: 9326.464952 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2502/5000] - Train Loss: 10590.757894 - Val Loss: 9330.182075 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2503/5000] - Train Loss: 10593.353678 - Val Loss: 9330.888129 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2504/5000] - Train Loss: 10583.225559 - Val Loss: 9327.278863 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2505/5000] - Train Loss: 10598.508192 - Val Loss: 9325.796007 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2506/5000] - Train Loss: 10587.681803 - Val Loss: 9323.361871 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2507/5000] - Train Loss: 10581.631076 - Val Loss: 9334.782661 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2508/5000] - Train Loss: 10584.512722 - Val Loss: 9325.612847 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2509/5000] - Train Loss: 10604.410482 - Val Loss: 9323.669596 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2510/5000] - Train Loss: 10596.277913 - Val Loss: 9322.868164 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2511/5000] - Train Loss: 10576.492839 - Val Loss: 9316.449219 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2512/5000] - Train Loss: 10572.804742 - Val Loss: 9317.129774 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2513/5000] - Train Loss: 10590.029785 - Val Loss: 9316.448134 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2514/5000] - Train Loss: 10574.523980 - Val Loss: 9316.034180 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2515/5000] - Train Loss: 10576.609728 - Val Loss: 9314.294162 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2516/5000] - Train Loss: 10571.526828 - Val Loss: 9314.380751 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2517/5000] - Train Loss: 10584.447971 - Val Loss: 9309.300022 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2518/5000] - Train Loss: 10558.621419 - Val Loss: 9307.488607 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2519/5000] - Train Loss: 10552.803087 - Val Loss: 9315.107747 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2520/5000] - Train Loss: 10560.871419 - Val Loss: 9308.848958 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2521/5000] - Train Loss: 10544.409342 - Val Loss: 9308.522461 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2522/5000] - Train Loss: 10580.020020 - Val Loss: 9311.499566 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2523/5000] - Train Loss: 10561.582004 - Val Loss: 9305.489149 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2524/5000] - Train Loss: 10557.615614 - Val Loss: 9301.331706 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2525/5000] - Train Loss: 10544.859782 - Val Loss: 9300.163086 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2526/5000] - Train Loss: 10567.853407 - Val Loss: 9302.475260 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2527/5000] - Train Loss: 10539.247396 - Val Loss: 9301.387478 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2528/5000] - Train Loss: 10559.523410 - Val Loss: 9300.670356 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2529/5000] - Train Loss: 10552.627360 - Val Loss: 9303.979709 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2530/5000] - Train Loss: 10551.329020 - Val Loss: 9296.943359 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2531/5000] - Train Loss: 10562.911323 - Val Loss: 9308.841363 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2532/5000] - Train Loss: 10545.778158 - Val Loss: 9297.456597 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2533/5000] - Train Loss: 10549.305990 - Val Loss: 9299.757053 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2534/5000] - Train Loss: 10544.258111 - Val Loss: 9300.733615 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2535/5000] - Train Loss: 10569.531847 - Val Loss: 9295.309028 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2536/5000] - Train Loss: 10543.068549 - Val Loss: 9293.272461 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2537/5000] - Train Loss: 10560.051785 - Val Loss: 9288.402669 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2538/5000] - Train Loss: 10543.974609 - Val Loss: 9295.256510 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2539/5000] - Train Loss: 10550.425130 - Val Loss: 9287.489800 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2540/5000] - Train Loss: 10528.096842 - Val Loss: 9284.435872 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2541/5000] - Train Loss: 10536.450467 - Val Loss: 9281.048286 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2542/5000] - Train Loss: 10555.004395 - Val Loss: 9282.986003 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2543/5000] - Train Loss: 10541.640354 - Val Loss: 9279.998915 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2544/5000] - Train Loss: 10535.605143 - Val Loss: 9286.739149 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2545/5000] - Train Loss: 10542.139567 - Val Loss: 9285.594293 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2546/5000] - Train Loss: 10536.520833 - Val Loss: 9279.477214 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2547/5000] - Train Loss: 10521.242025 - Val Loss: 9277.895399 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2548/5000] - Train Loss: 10531.809923 - Val Loss: 9275.447808 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2549/5000] - Train Loss: 10526.153564 - Val Loss: 9274.754015 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2550/5000] - Train Loss: 10523.274875 - Val Loss: 9274.999240 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2551/5000] - Train Loss: 10535.187609 - Val Loss: 9272.725803 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2552/5000] - Train Loss: 10525.095106 - Val Loss: 9275.922309 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2553/5000] - Train Loss: 10527.869710 - Val Loss: 9272.346354 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2554/5000] - Train Loss: 10533.162516 - Val Loss: 9269.972656 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2555/5000] - Train Loss: 10521.584608 - Val Loss: 9264.063802 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2556/5000] - Train Loss: 10524.020860 - Val Loss: 9277.320964 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2557/5000] - Train Loss: 10507.669406 - Val Loss: 9271.814562 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2558/5000] - Train Loss: 10534.072835 - Val Loss: 9270.940972 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2559/5000] - Train Loss: 10510.941922 - Val Loss: 9266.083767 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2560/5000] - Train Loss: 10515.118245 - Val Loss: 9262.638021 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2561/5000] - Train Loss: 10512.315321 - Val Loss: 9259.861871 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2562/5000] - Train Loss: 10511.919461 - Val Loss: 9257.566623 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2563/5000] - Train Loss: 10504.493761 - Val Loss: 9257.118815 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2564/5000] - Train Loss: 10500.546794 - Val Loss: 9263.821506 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2565/5000] - Train Loss: 10492.471056 - Val Loss: 9258.956597 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2566/5000] - Train Loss: 10502.066488 - Val Loss: 9250.746636 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2567/5000] - Train Loss: 10494.166938 - Val Loss: 9265.938368 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2568/5000] - Train Loss: 10516.560113 - Val Loss: 9255.027778 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2569/5000] - Train Loss: 10499.895209 - Val Loss: 9256.377496 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2570/5000] - Train Loss: 10505.480577 - Val Loss: 9251.609158 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2571/5000] - Train Loss: 10502.759060 - Val Loss: 9247.257053 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2572/5000] - Train Loss: 10489.299669 - Val Loss: 9243.042643 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2573/5000] - Train Loss: 10489.754259 - Val Loss: 9254.868815 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2574/5000] - Train Loss: 10500.805284 - Val Loss: 9252.601454 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2575/5000] - Train Loss: 10499.891330 - Val Loss: 9247.115126 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2576/5000] - Train Loss: 10490.286458 - Val Loss: 9239.025282 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2577/5000] - Train Loss: 10502.543240 - Val Loss: 9250.978407 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2578/5000] - Train Loss: 10476.543050 - Val Loss: 9241.842665 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2579/5000] - Train Loss: 10477.914280 - Val Loss: 9243.662218 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2580/5000] - Train Loss: 10492.774550 - Val Loss: 9246.553819 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2581/5000] - Train Loss: 10490.393989 - Val Loss: 9238.543728 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2582/5000] - Train Loss: 10493.464817 - Val Loss: 9242.188260 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2583/5000] - Train Loss: 10486.862983 - Val Loss: 9239.695095 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2584/5000] - Train Loss: 10485.363091 - Val Loss: 9238.795030 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2585/5000] - Train Loss: 10470.944038 - Val Loss: 9232.599826 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2586/5000] - Train Loss: 10484.298638 - Val Loss: 9234.922852 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2587/5000] - Train Loss: 10483.756158 - Val Loss: 9236.335069 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2588/5000] - Train Loss: 10466.611030 - Val Loss: 9234.098524 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2589/5000] - Train Loss: 10484.820747 - Val Loss: 9233.877713 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2590/5000] - Train Loss: 10469.960802 - Val Loss: 9237.889757 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2591/5000] - Train Loss: 10466.405843 - Val Loss: 9229.209201 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2592/5000] - Train Loss: 10472.940158 - Val Loss: 9225.263129 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2593/5000] - Train Loss: 10464.941678 - Val Loss: 9227.294271 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2594/5000] - Train Loss: 10474.189426 - Val Loss: 9227.776367 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2595/5000] - Train Loss: 10484.208550 - Val Loss: 9231.077040 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2596/5000] - Train Loss: 10473.497125 - Val Loss: 9234.904188 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2597/5000] - Train Loss: 10464.511285 - Val Loss: 9218.613607 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2598/5000] - Train Loss: 10467.730686 - Val Loss: 9215.886285 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2599/5000] - Train Loss: 10469.773193 - Val Loss: 9218.022678 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2600/5000] - Train Loss: 10457.830675 - Val Loss: 9218.248806 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2601/5000] - Train Loss: 10471.832194 - Val Loss: 9219.269640 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2602/5000] - Train Loss: 10453.508274 - Val Loss: 9214.455078 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2603/5000] - Train Loss: 10463.838026 - Val Loss: 9219.949219 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2604/5000] - Train Loss: 10464.857422 - Val Loss: 9220.776801 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2605/5000] - Train Loss: 10465.101373 - Val Loss: 9210.525825 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2606/5000] - Train Loss: 10463.766113 - Val Loss: 9222.301215 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2607/5000] - Train Loss: 10459.071859 - Val Loss: 9214.329536 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2608/5000] - Train Loss: 10456.925212 - Val Loss: 9205.925456 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2609/5000] - Train Loss: 10448.126899 - Val Loss: 9217.834310 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2610/5000] - Train Loss: 10452.285916 - Val Loss: 9212.404948 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2611/5000] - Train Loss: 10453.316243 - Val Loss: 9212.292101 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2612/5000] - Train Loss: 10459.504991 - Val Loss: 9209.157444 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2613/5000] - Train Loss: 10464.691054 - Val Loss: 9210.948134 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2614/5000] - Train Loss: 10464.586372 - Val Loss: 9207.047201 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2615/5000] - Train Loss: 10458.113607 - Val Loss: 9201.964084 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2616/5000] - Train Loss: 10448.683838 - Val Loss: 9209.024306 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2617/5000] - Train Loss: 10438.438477 - Val Loss: 9216.183811 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2618/5000] - Train Loss: 10457.059652 - Val Loss: 9214.791124 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2619/5000] - Train Loss: 10426.518148 - Val Loss: 9197.673611 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2620/5000] - Train Loss: 10434.339654 - Val Loss: 9198.740234 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2621/5000] - Train Loss: 10445.338135 - Val Loss: 9191.505208 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2622/5000] - Train Loss: 10433.649495 - Val Loss: 9189.906359 - Time: 1.33s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2623/5000] - Train Loss: 10434.918294 - Val Loss: 9198.131510 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2624/5000] - Train Loss: 10435.065647 - Val Loss: 9193.118490 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2625/5000] - Train Loss: 10438.751465 - Val Loss: 9197.117839 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2626/5000] - Train Loss: 10431.994222 - Val Loss: 9198.481554 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2627/5000] - Train Loss: 10428.768066 - Val Loss: 9189.321072 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2628/5000] - Train Loss: 10445.056641 - Val Loss: 9193.920356 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2629/5000] - Train Loss: 10442.097168 - Val Loss: 9189.189562 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2630/5000] - Train Loss: 10425.825656 - Val Loss: 9202.927517 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2631/5000] - Train Loss: 10416.003825 - Val Loss: 9187.431207 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2632/5000] - Train Loss: 10433.256104 - Val Loss: 9193.927951 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2633/5000] - Train Loss: 10440.242160 - Val Loss: 9192.041124 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2634/5000] - Train Loss: 10419.285156 - Val Loss: 9187.125543 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2635/5000] - Train Loss: 10440.249485 - Val Loss: 9198.514106 - Time: 1.35s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2636/5000] - Train Loss: 10415.459500 - Val Loss: 9182.255968 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2637/5000] - Train Loss: 10419.350586 - Val Loss: 9194.674045 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2638/5000] - Train Loss: 10425.154541 - Val Loss: 9184.791124 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2639/5000] - Train Loss: 10414.658149 - Val Loss: 9182.668077 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2640/5000] - Train Loss: 10414.709744 - Val Loss: 9181.950955 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2641/5000] - Train Loss: 10424.853706 - Val Loss: 9182.338216 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2642/5000] - Train Loss: 10403.265137 - Val Loss: 9181.936957 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2643/5000] - Train Loss: 10413.877984 - Val Loss: 9176.733941 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2644/5000] - Train Loss: 10412.329997 - Val Loss: 9174.598850 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2645/5000] - Train Loss: 10410.779839 - Val Loss: 9174.186957 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2646/5000] - Train Loss: 10414.367703 - Val Loss: 9173.244466 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2647/5000] - Train Loss: 10407.555420 - Val Loss: 9178.548286 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2648/5000] - Train Loss: 10397.716281 - Val Loss: 9168.962240 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2649/5000] - Train Loss: 10415.543647 - Val Loss: 9170.777561 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2650/5000] - Train Loss: 10410.298340 - Val Loss: 9172.717122 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2651/5000] - Train Loss: 10406.707899 - Val Loss: 9168.978407 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2652/5000] - Train Loss: 10399.708767 - Val Loss: 9168.080078 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2653/5000] - Train Loss: 10390.710042 - Val Loss: 9173.512370 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2654/5000] - Train Loss: 10393.252441 - Val Loss: 9174.894857 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2655/5000] - Train Loss: 10399.965034 - Val Loss: 9173.332899 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2656/5000] - Train Loss: 10399.002360 - Val Loss: 9165.223307 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2657/5000] - Train Loss: 10394.190457 - Val Loss: 9163.045681 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2658/5000] - Train Loss: 10387.565131 - Val Loss: 9157.807834 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2659/5000] - Train Loss: 10383.964708 - Val Loss: 9159.621745 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2660/5000] - Train Loss: 10407.304660 - Val Loss: 9154.229926 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2661/5000] - Train Loss: 10386.728787 - Val Loss: 9165.159071 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2662/5000] - Train Loss: 10399.876194 - Val Loss: 9159.956055 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2663/5000] - Train Loss: 10383.543321 - Val Loss: 9158.064562 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2664/5000] - Train Loss: 10384.414551 - Val Loss: 9154.712240 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2665/5000] - Train Loss: 10378.347493 - Val Loss: 9156.490994 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2666/5000] - Train Loss: 10389.829102 - Val Loss: 9155.991970 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2667/5000] - Train Loss: 10383.196506 - Val Loss: 9155.601237 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2668/5000] - Train Loss: 10368.008002 - Val Loss: 9152.837565 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2669/5000] - Train Loss: 10386.935927 - Val Loss: 9152.103950 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2670/5000] - Train Loss: 10400.295546 - Val Loss: 9149.663845 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2671/5000] - Train Loss: 10369.214545 - Val Loss: 9145.116753 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2672/5000] - Train Loss: 10389.600315 - Val Loss: 9151.099392 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2673/5000] - Train Loss: 10374.942383 - Val Loss: 9162.443793 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2674/5000] - Train Loss: 10365.305962 - Val Loss: 9153.964735 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2675/5000] - Train Loss: 10382.644179 - Val Loss: 9155.922201 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2676/5000] - Train Loss: 10374.542860 - Val Loss: 9148.597114 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2677/5000] - Train Loss: 10367.534044 - Val Loss: 9146.758138 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2678/5000] - Train Loss: 10375.023546 - Val Loss: 9148.731662 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2679/5000] - Train Loss: 10357.896756 - Val Loss: 9150.513455 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2680/5000] - Train Loss: 10359.360135 - Val Loss: 9147.564019 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 9 epochs.\n",
      "Epoch [2681/5000] - Train Loss: 10379.444607 - Val Loss: 9139.046441 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2682/5000] - Train Loss: 10353.638021 - Val Loss: 9143.433702 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2683/5000] - Train Loss: 10354.996718 - Val Loss: 9143.534180 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2684/5000] - Train Loss: 10366.980089 - Val Loss: 9132.886610 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2685/5000] - Train Loss: 10361.895426 - Val Loss: 9139.712782 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2686/5000] - Train Loss: 10343.230604 - Val Loss: 9131.313802 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2687/5000] - Train Loss: 10351.563639 - Val Loss: 9141.398329 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2688/5000] - Train Loss: 10371.325765 - Val Loss: 9134.691298 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2689/5000] - Train Loss: 10361.105767 - Val Loss: 9135.757921 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2690/5000] - Train Loss: 10372.395779 - Val Loss: 9126.432943 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2691/5000] - Train Loss: 10363.431831 - Val Loss: 9126.254991 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2692/5000] - Train Loss: 10355.056125 - Val Loss: 9134.320855 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2693/5000] - Train Loss: 10351.881429 - Val Loss: 9127.745985 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2694/5000] - Train Loss: 10354.697428 - Val Loss: 9132.799913 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2695/5000] - Train Loss: 10348.695530 - Val Loss: 9130.694987 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2696/5000] - Train Loss: 10339.265462 - Val Loss: 9135.682183 - Time: 1.24s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2697/5000] - Train Loss: 10371.480170 - Val Loss: 9134.634766 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2698/5000] - Train Loss: 10353.094347 - Val Loss: 9132.401259 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2699/5000] - Train Loss: 10354.545356 - Val Loss: 9118.274740 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2700/5000] - Train Loss: 10367.516547 - Val Loss: 9131.168186 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2701/5000] - Train Loss: 10351.855306 - Val Loss: 9125.803060 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2702/5000] - Train Loss: 10346.423774 - Val Loss: 9119.401693 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2703/5000] - Train Loss: 10339.022027 - Val Loss: 9125.869575 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2704/5000] - Train Loss: 10358.808322 - Val Loss: 9123.465495 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2705/5000] - Train Loss: 10345.166531 - Val Loss: 9117.902018 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2706/5000] - Train Loss: 10348.058105 - Val Loss: 9122.431641 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2707/5000] - Train Loss: 10332.722331 - Val Loss: 9117.667643 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2708/5000] - Train Loss: 10355.575765 - Val Loss: 9123.928819 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2709/5000] - Train Loss: 10343.203668 - Val Loss: 9138.232530 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2710/5000] - Train Loss: 10333.446018 - Val Loss: 9122.356120 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2711/5000] - Train Loss: 10357.168945 - Val Loss: 9119.149306 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2712/5000] - Train Loss: 10332.358046 - Val Loss: 9118.254015 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2713/5000] - Train Loss: 10322.912625 - Val Loss: 9115.413086 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2714/5000] - Train Loss: 10342.816759 - Val Loss: 9121.840603 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2715/5000] - Train Loss: 10346.095649 - Val Loss: 9117.995551 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2716/5000] - Train Loss: 10316.171387 - Val Loss: 9121.987956 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2717/5000] - Train Loss: 10335.263943 - Val Loss: 9111.119792 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2718/5000] - Train Loss: 10314.205675 - Val Loss: 9113.408637 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2719/5000] - Train Loss: 10318.961100 - Val Loss: 9106.273763 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2720/5000] - Train Loss: 10336.706868 - Val Loss: 9107.495009 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2721/5000] - Train Loss: 10340.761447 - Val Loss: 9104.262912 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2722/5000] - Train Loss: 10316.915826 - Val Loss: 9110.190321 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2723/5000] - Train Loss: 10329.611735 - Val Loss: 9100.802626 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2724/5000] - Train Loss: 10324.663222 - Val Loss: 9105.460503 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2725/5000] - Train Loss: 10312.819227 - Val Loss: 9104.988824 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2726/5000] - Train Loss: 10318.931993 - Val Loss: 9105.821398 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2727/5000] - Train Loss: 10316.013048 - Val Loss: 9105.294054 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2728/5000] - Train Loss: 10327.799099 - Val Loss: 9101.971897 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2729/5000] - Train Loss: 10348.259576 - Val Loss: 9107.845378 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2730/5000] - Train Loss: 10316.447917 - Val Loss: 9111.649523 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2731/5000] - Train Loss: 10314.661296 - Val Loss: 9101.592339 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2732/5000] - Train Loss: 10308.588542 - Val Loss: 9097.710395 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2733/5000] - Train Loss: 10318.997206 - Val Loss: 9101.415256 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2734/5000] - Train Loss: 10312.944689 - Val Loss: 9100.859809 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2735/5000] - Train Loss: 10318.232992 - Val Loss: 9096.969510 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2736/5000] - Train Loss: 10311.812364 - Val Loss: 9096.521050 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2737/5000] - Train Loss: 10298.278456 - Val Loss: 9091.631619 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2738/5000] - Train Loss: 10297.282905 - Val Loss: 9097.885851 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2739/5000] - Train Loss: 10317.093560 - Val Loss: 9102.567383 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2740/5000] - Train Loss: 10306.415690 - Val Loss: 9094.157010 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2741/5000] - Train Loss: 10293.989475 - Val Loss: 9093.914931 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2742/5000] - Train Loss: 10327.280436 - Val Loss: 9088.586697 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2743/5000] - Train Loss: 10306.892171 - Val Loss: 9093.625434 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2744/5000] - Train Loss: 10300.256076 - Val Loss: 9103.281576 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2745/5000] - Train Loss: 10309.577176 - Val Loss: 9106.464844 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2746/5000] - Train Loss: 10298.803250 - Val Loss: 9099.867839 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2747/5000] - Train Loss: 10304.162679 - Val Loss: 9081.981445 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2748/5000] - Train Loss: 10300.447211 - Val Loss: 9085.371636 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2749/5000] - Train Loss: 10297.817220 - Val Loss: 9082.906901 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2750/5000] - Train Loss: 10295.969401 - Val Loss: 9081.212565 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2751/5000] - Train Loss: 10297.371094 - Val Loss: 9094.015625 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2752/5000] - Train Loss: 10301.051622 - Val Loss: 9095.042860 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2753/5000] - Train Loss: 10281.609294 - Val Loss: 9086.800130 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2754/5000] - Train Loss: 10293.641412 - Val Loss: 9080.841037 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2755/5000] - Train Loss: 10283.430962 - Val Loss: 9082.535048 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2756/5000] - Train Loss: 10273.819363 - Val Loss: 9078.299154 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2757/5000] - Train Loss: 10280.869005 - Val Loss: 9079.170573 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2758/5000] - Train Loss: 10274.306993 - Val Loss: 9077.347548 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2759/5000] - Train Loss: 10289.209554 - Val Loss: 9082.634006 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2760/5000] - Train Loss: 10290.511854 - Val Loss: 9072.091471 - Time: 1.34s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2761/5000] - Train Loss: 10293.723958 - Val Loss: 9081.092882 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2762/5000] - Train Loss: 10275.791721 - Val Loss: 9079.274306 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2763/5000] - Train Loss: 10282.291314 - Val Loss: 9072.107856 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2764/5000] - Train Loss: 10281.023790 - Val Loss: 9068.870551 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2765/5000] - Train Loss: 10287.087891 - Val Loss: 9081.824436 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2766/5000] - Train Loss: 10275.232368 - Val Loss: 9077.904188 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2767/5000] - Train Loss: 10284.413032 - Val Loss: 9069.582248 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2768/5000] - Train Loss: 10269.082791 - Val Loss: 9079.038086 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2769/5000] - Train Loss: 10276.341715 - Val Loss: 9064.610894 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2770/5000] - Train Loss: 10278.769314 - Val Loss: 9068.819878 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2771/5000] - Train Loss: 10269.427436 - Val Loss: 9078.266385 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2772/5000] - Train Loss: 10285.260796 - Val Loss: 9072.306098 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2773/5000] - Train Loss: 10275.063070 - Val Loss: 9069.702691 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2774/5000] - Train Loss: 10272.957411 - Val Loss: 9067.983507 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2775/5000] - Train Loss: 10278.338352 - Val Loss: 9070.501736 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2776/5000] - Train Loss: 10262.230306 - Val Loss: 9062.996528 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2777/5000] - Train Loss: 10272.141900 - Val Loss: 9061.228082 - Time: 1.35s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2778/5000] - Train Loss: 10269.289415 - Val Loss: 9059.932726 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2779/5000] - Train Loss: 10272.856527 - Val Loss: 9058.339627 - Time: 1.24s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2780/5000] - Train Loss: 10260.079536 - Val Loss: 9057.536024 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2781/5000] - Train Loss: 10266.198947 - Val Loss: 9053.901042 - Time: 1.23s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2782/5000] - Train Loss: 10271.053792 - Val Loss: 9059.532986 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2783/5000] - Train Loss: 10250.852729 - Val Loss: 9049.484592 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2784/5000] - Train Loss: 10260.039931 - Val Loss: 9049.983507 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2785/5000] - Train Loss: 10263.563151 - Val Loss: 9061.458876 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2786/5000] - Train Loss: 10251.431532 - Val Loss: 9054.341688 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2787/5000] - Train Loss: 10241.873698 - Val Loss: 9059.208116 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2788/5000] - Train Loss: 10248.048204 - Val Loss: 9050.897135 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2789/5000] - Train Loss: 10249.479085 - Val Loss: 9055.747287 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2790/5000] - Train Loss: 10255.688341 - Val Loss: 9050.884766 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2791/5000] - Train Loss: 10248.474854 - Val Loss: 9056.653754 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2792/5000] - Train Loss: 10248.012885 - Val Loss: 9044.569444 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2793/5000] - Train Loss: 10244.072401 - Val Loss: 9047.638346 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2794/5000] - Train Loss: 10258.881185 - Val Loss: 9048.443142 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2795/5000] - Train Loss: 10254.975993 - Val Loss: 9049.825629 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2796/5000] - Train Loss: 10257.759603 - Val Loss: 9048.245334 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2797/5000] - Train Loss: 10254.746474 - Val Loss: 9047.406141 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2798/5000] - Train Loss: 10247.348660 - Val Loss: 9047.526042 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2799/5000] - Train Loss: 10241.546034 - Val Loss: 9043.621853 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2800/5000] - Train Loss: 10231.622152 - Val Loss: 9046.284614 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2801/5000] - Train Loss: 10230.599067 - Val Loss: 9038.798503 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2802/5000] - Train Loss: 10229.643528 - Val Loss: 9043.356337 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2803/5000] - Train Loss: 10234.415148 - Val Loss: 9042.537652 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2804/5000] - Train Loss: 10236.189507 - Val Loss: 9042.239041 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2805/5000] - Train Loss: 10225.661784 - Val Loss: 9043.309136 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2806/5000] - Train Loss: 10229.725911 - Val Loss: 9033.632487 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2807/5000] - Train Loss: 10237.998372 - Val Loss: 9039.436849 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2808/5000] - Train Loss: 10231.638265 - Val Loss: 9042.578559 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2809/5000] - Train Loss: 10233.067003 - Val Loss: 9053.414931 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2810/5000] - Train Loss: 10235.146729 - Val Loss: 9045.720703 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2811/5000] - Train Loss: 10243.897624 - Val Loss: 9038.559028 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2812/5000] - Train Loss: 10215.446587 - Val Loss: 9037.557183 - Time: 1.26s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2813/5000] - Train Loss: 10235.610189 - Val Loss: 9035.314996 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2814/5000] - Train Loss: 10231.400255 - Val Loss: 9032.526801 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2815/5000] - Train Loss: 10226.153212 - Val Loss: 9036.621202 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2816/5000] - Train Loss: 10226.633464 - Val Loss: 9033.472765 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2817/5000] - Train Loss: 10227.840305 - Val Loss: 9034.171007 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2818/5000] - Train Loss: 10229.040663 - Val Loss: 9029.346897 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2819/5000] - Train Loss: 10233.083469 - Val Loss: 9026.761285 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2820/5000] - Train Loss: 10224.207221 - Val Loss: 9018.455404 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2821/5000] - Train Loss: 10218.153375 - Val Loss: 9022.892687 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2822/5000] - Train Loss: 10240.960965 - Val Loss: 9027.903212 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2823/5000] - Train Loss: 10225.275445 - Val Loss: 9021.717122 - Time: 1.24s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2824/5000] - Train Loss: 10217.998291 - Val Loss: 9023.873698 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2825/5000] - Train Loss: 10212.449192 - Val Loss: 9017.593750 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2826/5000] - Train Loss: 10210.953722 - Val Loss: 9011.814779 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2827/5000] - Train Loss: 10227.714464 - Val Loss: 9028.784614 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2828/5000] - Train Loss: 10225.363336 - Val Loss: 9019.864475 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2829/5000] - Train Loss: 10212.136420 - Val Loss: 9015.526693 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2830/5000] - Train Loss: 10213.460802 - Val Loss: 9012.777778 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2831/5000] - Train Loss: 10208.869873 - Val Loss: 9012.113824 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2832/5000] - Train Loss: 10208.986464 - Val Loss: 9011.935438 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2833/5000] - Train Loss: 10207.355740 - Val Loss: 9013.358724 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2834/5000] - Train Loss: 10203.976590 - Val Loss: 9027.727431 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2835/5000] - Train Loss: 10227.677979 - Val Loss: 9009.364149 - Time: 1.30s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2836/5000] - Train Loss: 10213.061306 - Val Loss: 9012.746962 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2837/5000] - Train Loss: 10206.585314 - Val Loss: 9007.568034 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2838/5000] - Train Loss: 10212.469510 - Val Loss: 9013.787543 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2839/5000] - Train Loss: 10197.829346 - Val Loss: 9013.962891 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2840/5000] - Train Loss: 10199.102458 - Val Loss: 9007.362630 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2841/5000] - Train Loss: 10206.660699 - Val Loss: 9008.109918 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2842/5000] - Train Loss: 10204.424045 - Val Loss: 9012.270942 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2843/5000] - Train Loss: 10189.167535 - Val Loss: 9003.967448 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2844/5000] - Train Loss: 10203.308214 - Val Loss: 9012.539714 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2845/5000] - Train Loss: 10206.846408 - Val Loss: 9002.485026 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2846/5000] - Train Loss: 10201.752143 - Val Loss: 9006.850152 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2847/5000] - Train Loss: 10204.441596 - Val Loss: 9004.697157 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2848/5000] - Train Loss: 10191.067898 - Val Loss: 9009.730143 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2849/5000] - Train Loss: 10206.677951 - Val Loss: 8999.537109 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2850/5000] - Train Loss: 10194.595161 - Val Loss: 9004.639431 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2851/5000] - Train Loss: 10190.764431 - Val Loss: 8997.606120 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2852/5000] - Train Loss: 10178.570936 - Val Loss: 8997.287652 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2853/5000] - Train Loss: 10194.135064 - Val Loss: 9006.153863 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2854/5000] - Train Loss: 10192.410292 - Val Loss: 9002.315430 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2855/5000] - Train Loss: 10179.802355 - Val Loss: 9004.742839 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2856/5000] - Train Loss: 10194.232015 - Val Loss: 8996.679688 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2857/5000] - Train Loss: 10186.279297 - Val Loss: 9003.355143 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2858/5000] - Train Loss: 10193.245388 - Val Loss: 9006.273003 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2859/5000] - Train Loss: 10189.364583 - Val Loss: 8993.970052 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2860/5000] - Train Loss: 10179.939643 - Val Loss: 8991.805773 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2861/5000] - Train Loss: 10174.880588 - Val Loss: 8991.749457 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2862/5000] - Train Loss: 10183.001302 - Val Loss: 9003.561957 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2863/5000] - Train Loss: 10202.373996 - Val Loss: 8989.996853 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2864/5000] - Train Loss: 10175.962836 - Val Loss: 8997.543403 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2865/5000] - Train Loss: 10196.504367 - Val Loss: 8992.117730 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2866/5000] - Train Loss: 10193.453613 - Val Loss: 8992.191732 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2867/5000] - Train Loss: 10173.790527 - Val Loss: 8988.818576 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2868/5000] - Train Loss: 10186.945801 - Val Loss: 8989.732096 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2869/5000] - Train Loss: 10177.057509 - Val Loss: 8990.761502 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2870/5000] - Train Loss: 10187.862983 - Val Loss: 8992.205295 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2871/5000] - Train Loss: 10185.729519 - Val Loss: 8988.599935 - Time: 1.22s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2872/5000] - Train Loss: 10190.861328 - Val Loss: 8995.229275 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2873/5000] - Train Loss: 10170.182156 - Val Loss: 8994.806641 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2874/5000] - Train Loss: 10175.199137 - Val Loss: 8999.457357 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2875/5000] - Train Loss: 10166.981038 - Val Loss: 8996.310655 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2876/5000] - Train Loss: 10176.330187 - Val Loss: 8984.775391 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2877/5000] - Train Loss: 10174.220785 - Val Loss: 8985.064779 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2878/5000] - Train Loss: 10168.515462 - Val Loss: 8989.667535 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2879/5000] - Train Loss: 10155.475450 - Val Loss: 8989.618598 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2880/5000] - Train Loss: 10174.527805 - Val Loss: 8979.625543 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2881/5000] - Train Loss: 10162.441786 - Val Loss: 8982.233941 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2882/5000] - Train Loss: 10162.448676 - Val Loss: 8988.200412 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2883/5000] - Train Loss: 10168.637695 - Val Loss: 8985.362847 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2884/5000] - Train Loss: 10152.029758 - Val Loss: 8983.472439 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2885/5000] - Train Loss: 10165.268745 - Val Loss: 8980.810113 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2886/5000] - Train Loss: 10167.996121 - Val Loss: 8981.240126 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2887/5000] - Train Loss: 10177.880968 - Val Loss: 8970.957031 - Time: 1.32s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2888/5000] - Train Loss: 10143.103923 - Val Loss: 8981.248589 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2889/5000] - Train Loss: 10166.052517 - Val Loss: 8975.582248 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2890/5000] - Train Loss: 10157.401340 - Val Loss: 8983.345052 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2891/5000] - Train Loss: 10169.882080 - Val Loss: 8966.395182 - Time: 1.21s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2892/5000] - Train Loss: 10145.072510 - Val Loss: 8962.809462 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2893/5000] - Train Loss: 10177.356337 - Val Loss: 8981.391276 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2894/5000] - Train Loss: 10181.829942 - Val Loss: 8973.382053 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2895/5000] - Train Loss: 10164.690918 - Val Loss: 8974.420139 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2896/5000] - Train Loss: 10158.299127 - Val Loss: 8973.754015 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2897/5000] - Train Loss: 10153.955377 - Val Loss: 8974.928602 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2898/5000] - Train Loss: 10153.895237 - Val Loss: 8962.240560 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2899/5000] - Train Loss: 10151.013889 - Val Loss: 8966.756727 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2900/5000] - Train Loss: 10158.092394 - Val Loss: 8961.903212 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2901/5000] - Train Loss: 10152.144151 - Val Loss: 8976.412977 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2902/5000] - Train Loss: 10155.688314 - Val Loss: 8960.538737 - Time: 1.28s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2903/5000] - Train Loss: 10160.918891 - Val Loss: 8971.253364 - Time: 1.23s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2904/5000] - Train Loss: 10139.916531 - Val Loss: 8978.382161 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2905/5000] - Train Loss: 10145.270101 - Val Loss: 8962.093859 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2906/5000] - Train Loss: 10130.182753 - Val Loss: 8967.008898 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2907/5000] - Train Loss: 10162.640055 - Val Loss: 8962.004991 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2908/5000] - Train Loss: 10140.690891 - Val Loss: 8954.877496 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2909/5000] - Train Loss: 10144.226128 - Val Loss: 8966.437174 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2910/5000] - Train Loss: 10133.956353 - Val Loss: 8968.284831 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2911/5000] - Train Loss: 10147.666206 - Val Loss: 8962.666884 - Time: 1.26s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2912/5000] - Train Loss: 10146.348172 - Val Loss: 8963.464952 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2913/5000] - Train Loss: 10131.620687 - Val Loss: 8956.420356 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2914/5000] - Train Loss: 10135.242540 - Val Loss: 8964.403971 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2915/5000] - Train Loss: 10140.893473 - Val Loss: 8956.952799 - Time: 1.31s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2916/5000] - Train Loss: 10141.490180 - Val Loss: 8965.600803 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2917/5000] - Train Loss: 10140.812419 - Val Loss: 8949.875434 - Time: 1.31s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2918/5000] - Train Loss: 10134.324680 - Val Loss: 8961.412869 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2919/5000] - Train Loss: 10138.826470 - Val Loss: 8962.390191 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2920/5000] - Train Loss: 10137.649794 - Val Loss: 8949.190104 - Time: 1.27s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2921/5000] - Train Loss: 10133.325195 - Val Loss: 8947.571072 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2922/5000] - Train Loss: 10149.270725 - Val Loss: 8963.184679 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2923/5000] - Train Loss: 10126.788764 - Val Loss: 8948.388780 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2924/5000] - Train Loss: 10129.964437 - Val Loss: 8947.656576 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2925/5000] - Train Loss: 10146.028537 - Val Loss: 8955.324978 - Time: 1.32s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2926/5000] - Train Loss: 10129.149333 - Val Loss: 8948.568793 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2927/5000] - Train Loss: 10125.881944 - Val Loss: 8947.290365 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2928/5000] - Train Loss: 10138.456462 - Val Loss: 8946.152669 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2929/5000] - Train Loss: 10135.041721 - Val Loss: 8948.201606 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2930/5000] - Train Loss: 10127.665799 - Val Loss: 8942.531576 - Time: 1.26s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2931/5000] - Train Loss: 10127.185167 - Val Loss: 8937.148980 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2932/5000] - Train Loss: 10124.121691 - Val Loss: 8953.851671 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2933/5000] - Train Loss: 10118.241075 - Val Loss: 8946.755100 - Time: 1.25s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2934/5000] - Train Loss: 10117.544189 - Val Loss: 8948.743381 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2935/5000] - Train Loss: 10115.303630 - Val Loss: 8950.537218 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2936/5000] - Train Loss: 10119.946859 - Val Loss: 8939.094401 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2937/5000] - Train Loss: 10130.506809 - Val Loss: 8939.850369 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2938/5000] - Train Loss: 10109.365750 - Val Loss: 8941.288954 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2939/5000] - Train Loss: 10122.970947 - Val Loss: 8942.964627 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2940/5000] - Train Loss: 10123.045681 - Val Loss: 8936.857530 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2941/5000] - Train Loss: 10102.766276 - Val Loss: 8935.774197 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2942/5000] - Train Loss: 10109.419461 - Val Loss: 8944.214627 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2943/5000] - Train Loss: 10117.440620 - Val Loss: 8943.473090 - Time: 1.22s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2944/5000] - Train Loss: 10115.457791 - Val Loss: 8931.905599 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2945/5000] - Train Loss: 10120.192844 - Val Loss: 8942.418077 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2946/5000] - Train Loss: 10118.590495 - Val Loss: 8937.275282 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2947/5000] - Train Loss: 10108.182102 - Val Loss: 8936.823568 - Time: 1.33s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2948/5000] - Train Loss: 10116.207520 - Val Loss: 8929.583442 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2949/5000] - Train Loss: 10116.750868 - Val Loss: 8927.991102 - Time: 1.19s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2950/5000] - Train Loss: 10111.139893 - Val Loss: 8932.630534 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2951/5000] - Train Loss: 10107.786377 - Val Loss: 8930.466146 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2952/5000] - Train Loss: 10109.059543 - Val Loss: 8935.912652 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2953/5000] - Train Loss: 10117.728597 - Val Loss: 8931.125760 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2954/5000] - Train Loss: 10108.397678 - Val Loss: 8925.983073 - Time: 1.18s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2955/5000] - Train Loss: 10103.954481 - Val Loss: 8924.896918 - Time: 1.29s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2956/5000] - Train Loss: 10120.723443 - Val Loss: 8926.512912 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2957/5000] - Train Loss: 10093.388563 - Val Loss: 8927.959635 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2958/5000] - Train Loss: 10105.010362 - Val Loss: 8925.028320 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2959/5000] - Train Loss: 10110.219103 - Val Loss: 8923.222982 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2960/5000] - Train Loss: 10103.446316 - Val Loss: 8928.935981 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2961/5000] - Train Loss: 10088.905138 - Val Loss: 8914.279297 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2962/5000] - Train Loss: 10092.799940 - Val Loss: 8927.203885 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2963/5000] - Train Loss: 10106.252387 - Val Loss: 8920.455512 - Time: 1.21s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2964/5000] - Train Loss: 10090.704156 - Val Loss: 8922.154622 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2965/5000] - Train Loss: 10083.030436 - Val Loss: 8921.301649 - Time: 1.29s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2966/5000] - Train Loss: 10101.576579 - Val Loss: 8925.052951 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2967/5000] - Train Loss: 10095.529839 - Val Loss: 8915.618381 - Time: 1.28s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2968/5000] - Train Loss: 10117.769558 - Val Loss: 8922.974826 - Time: 1.17s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2969/5000] - Train Loss: 10093.078478 - Val Loss: 8922.661458 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2970/5000] - Train Loss: 10083.069010 - Val Loss: 8917.686306 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 9 epochs.\n",
      "Epoch [2971/5000] - Train Loss: 10090.092231 - Val Loss: 8910.170356 - Time: 1.20s\n",
      "‚úÖ Model improved! Saving checkpoint.\n",
      "Epoch [2972/5000] - Train Loss: 10076.418457 - Val Loss: 8913.121202 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 1 epochs.\n",
      "Epoch [2973/5000] - Train Loss: 10100.162001 - Val Loss: 8913.719076 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 2 epochs.\n",
      "Epoch [2974/5000] - Train Loss: 10092.551893 - Val Loss: 8921.272895 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 3 epochs.\n",
      "Epoch [2975/5000] - Train Loss: 10098.173910 - Val Loss: 8929.434896 - Time: 1.45s\n",
      "‚ö†Ô∏è No improvement for 4 epochs.\n",
      "Epoch [2976/5000] - Train Loss: 10082.484972 - Val Loss: 8914.792318 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 5 epochs.\n",
      "Epoch [2977/5000] - Train Loss: 10082.081163 - Val Loss: 8915.684462 - Time: 1.30s\n",
      "‚ö†Ô∏è No improvement for 6 epochs.\n",
      "Epoch [2978/5000] - Train Loss: 10090.613498 - Val Loss: 8913.138238 - Time: 1.19s\n",
      "‚ö†Ô∏è No improvement for 7 epochs.\n",
      "Epoch [2979/5000] - Train Loss: 10091.145942 - Val Loss: 8921.384657 - Time: 1.18s\n",
      "‚ö†Ô∏è No improvement for 8 epochs.\n",
      "Epoch [2980/5000] - Train Loss: 10078.645155 - Val Loss: 8913.051107 - Time: 1.27s\n",
      "‚ö†Ô∏è No improvement for 9 epochs.\n",
      "Epoch [2981/5000] - Train Loss: 10084.885118 - Val Loss: 8912.695747 - Time: 1.20s\n",
      "‚ö†Ô∏è No improvement for 10 epochs.\n",
      "‚èπÔ∏è Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "train_model(model, X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor, epochs=5000, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_rrmse_t(gt, pred):\n",
    "    \"\"\"\n",
    "    Compute Temporal RRMSE (Lower is better).\n",
    "    Formula: RRMSE_T = ||pred - gt||_2 / ||gt||_2\n",
    "    \"\"\"\n",
    "    return torch.norm(pred - gt, p=2) / torch.norm(gt, p=2)\n",
    "\n",
    "def compute_rrmse_s(gt, pred, fs=512):\n",
    "    \"\"\"\n",
    "    Compute Spectral RRMSE (Lower is better).\n",
    "    Formula: RRMSE_S = ||PSD(pred) - PSD(gt)||_2 / ||PSD(gt)||_2\n",
    "    \"\"\"\n",
    "    def compute_psd(signal):\n",
    "        f, psd = welch(signal, fs=fs, nperseg=256)  # Power Spectral Density\n",
    "        return torch.tensor(psd, dtype=torch.float32)\n",
    "\n",
    "    psd_gt = compute_psd(gt.cpu().numpy())\n",
    "    psd_pred = compute_psd(pred.cpu().numpy())\n",
    "\n",
    "    return torch.norm(psd_pred - psd_gt, p=2) / torch.norm(psd_gt, p=2)\n",
    "\n",
    "def compute_cc(gt, pred):\n",
    "    \"\"\"\n",
    "    Compute Correlation Coefficient (Higher is better).\n",
    "    Formula: CC = Cov(gt, pred) / (std(gt) * std(pred))\n",
    "    \"\"\"\n",
    "    gt_mean, pred_mean = torch.mean(gt), torch.mean(pred)\n",
    "    numerator = torch.sum((gt - gt_mean) * (pred - pred_mean))\n",
    "    denominator = torch.sqrt(torch.sum((gt - gt_mean) ** 2) * torch.sum((pred - pred_mean) ** 2))\n",
    "\n",
    "    return numerator / (denominator + 1e-8)  # Avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_snr(model, X_test_final, y_test_final):\n",
    "    \"\"\"\n",
    "    Evaluate model performance per SNR level using pre-split test data.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    snr_metrics = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Move test data to GPU\n",
    "        X_test_tensor = torch.tensor(X_test_final, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test_final, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "        # Compute metrics\n",
    "        rrmse_t = compute_rrmse_t(y_test_tensor, y_pred_tensor).cpu().item()\n",
    "        rrmse_s = compute_rrmse_s(y_test_tensor, y_pred_tensor).cpu().item()\n",
    "        cc = compute_cc(y_test_tensor, y_pred_tensor).cpu().item()\n",
    "\n",
    "        # Store results\n",
    "        snr_metrics[\"Overall\"] = {\n",
    "            \"RRMSE_T\": rrmse_t,\n",
    "            \"RRMSE_S\": rrmse_s,\n",
    "            \"CC\": cc\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Overall Test Set Evaluation: RRMSE_T = {rrmse_t:.4f}, RRMSE_S = {rrmse_s:.4f}, CC = {cc:.4f}\")\n",
    "\n",
    "    return snr_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics(snr_metrics):\n",
    "    \"\"\"\n",
    "    Compute the final average performance of RRMSE_T, RRMSE_S, and CC across all SNRs.\n",
    "    \"\"\"\n",
    "    avg_rrmse_t = sum([snr_metrics[snr][\"RRMSE_T\"] for snr in snr_metrics]) / len(snr_metrics)\n",
    "    avg_rrmse_s = sum([snr_metrics[snr][\"RRMSE_S\"] for snr in snr_metrics]) / len(snr_metrics)\n",
    "    avg_cc = sum([snr_metrics[snr][\"CC\"] for snr in snr_metrics]) / len(snr_metrics)\n",
    "    \n",
    "    print(\"\\nüîπ **Final Average Results Across All SNRs** üîπ\")\n",
    "    print(f\"‚úÖ Average RRMSE_T: {avg_rrmse_t:.4f} (Lower is better)\")\n",
    "    print(f\"‚úÖ Average RRMSE_S: {avg_rrmse_s:.4f} (Lower is better)\")\n",
    "    print(f\"‚úÖ Average CC: {avg_cc:.4f} (Higher is better)\")\n",
    "\n",
    "    return avg_rrmse_t, avg_rrmse_s, avg_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Evaluating SNR Level: -7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîπ Evaluating SNR Level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Get test data from pre-split dataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m X_test_snr \u001b[38;5;241m=\u001b[39m \u001b[43mX_test_list\u001b[49m[snr_idx]  \u001b[38;5;66;03m# Noisy EEG from test set\u001b[39;00m\n\u001b[1;32m     38\u001b[0m y_test_snr \u001b[38;5;241m=\u001b[39m y_test_list[snr_idx]  \u001b[38;5;66;03m# Clean EEG from test set\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors and reshape for LSTM\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_list' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "# Function to compute RRMSE\n",
    "def compute_rrmse(denoised, clean):\n",
    "    return np.sqrt(np.mean((denoised - clean) ** 2)) / np.sqrt(np.mean(clean ** 2))\n",
    "\n",
    "# Function to compute RRMSE in the Spectrum Domain\n",
    "def compute_rrmse_spectrum(denoised, clean):\n",
    "    fft_clean = np.abs(fft(clean))  # Compute FFT\n",
    "    fft_denoised = np.abs(fft(denoised))\n",
    "    return compute_rrmse(fft_denoised, fft_clean)\n",
    "\n",
    "# Function to compute Correlation Coefficient (CC)\n",
    "def compute_cc(denoised, clean):\n",
    "    try:\n",
    "        return pearsonr(denoised.flatten(), clean.flatten())[0]\n",
    "    except:\n",
    "        return 0  # Handle errors gracefully\n",
    "\n",
    "# Store results\n",
    "snr_metrics = {}\n",
    "\n",
    "# Lists to store metrics for computing overall averages\n",
    "all_rrmse_t = []\n",
    "all_rrmse_s = []\n",
    "all_cc = []\n",
    "\n",
    "# Loop through each SNR level using pre-split test data\n",
    "with torch.no_grad():\n",
    "    for snr_idx, snr in enumerate(sorted(synthetic_eeg_eog.keys())):\n",
    "        print(f\"üîπ Evaluating SNR Level: {snr}\")\n",
    "\n",
    "        # Get test data from pre-split dataset\n",
    "        X_test_snr = X_test_list[snr_idx]  # Noisy EEG from test set\n",
    "        y_test_snr = y_test_list[snr_idx]  # Clean EEG from test set\n",
    "\n",
    "        # Convert to PyTorch tensors and reshape for LSTM\n",
    "        X_test_tensor = torch.tensor(X_test_snr, dtype=torch.float32).unsqueeze(-1).to(device)  # (batch, 512, 1)\n",
    "        y_test_tensor = torch.tensor(y_test_snr, dtype=torch.float32).unsqueeze(-1).to(device)  # (batch, 512, 1)\n",
    "\n",
    "        # Get model predictions\n",
    "        y_pred_tensor = model(X_test_tensor).cpu().detach().numpy()\n",
    "        y_pred_tensor = y_pred_tensor.reshape(y_test_snr.shape)  # Ensure correct shape\n",
    "\n",
    "        # Compute metrics\n",
    "        rrmse_t_list = [compute_rrmse(y_pred_tensor[i], y_test_snr[i]) for i in range(len(y_test_snr))]\n",
    "        rrmse_s_list = [compute_rrmse_spectrum(y_pred_tensor[i], y_test_snr[i]) for i in range(len(y_test_snr))]\n",
    "        cc_list = [compute_cc(y_pred_tensor[i], y_test_snr[i]) for i in range(len(y_test_snr))]\n",
    "\n",
    "        # Store results for this SNR level\n",
    "        snr_metrics[snr] = {\n",
    "            \"RRMSE-T\": np.mean(rrmse_t_list),\n",
    "            \"RRMSE-S\": np.mean(rrmse_s_list),\n",
    "            \"CC\": np.mean(cc_list)\n",
    "        }\n",
    "\n",
    "        # Append values for overall averages\n",
    "        all_rrmse_t.extend(rrmse_t_list)\n",
    "        all_rrmse_s.extend(rrmse_s_list)\n",
    "        all_cc.extend(cc_list)\n",
    "\n",
    "# Compute Overall Averages\n",
    "overall_rrmse_t = np.mean(all_rrmse_t)\n",
    "overall_rrmse_s = np.mean(all_rrmse_s)\n",
    "overall_cc = np.mean(all_cc)\n",
    "\n",
    "# Print Results in Table Format\n",
    "print(\"\\nüîπ **Final Evaluation Per SNR Level:**\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"| SNR  |  RRMSE-T  |  RRMSE-S  |   CC   |\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "for snr in sorted(snr_metrics.keys()):\n",
    "    print(f\"| {snr:3d}  |  {snr_metrics[snr]['RRMSE-T']:.6f}  |  {snr_metrics[snr]['RRMSE-S']:.6f}  |  {snr_metrics[snr]['CC']:.6f}  |\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "# Print Overall Averages\n",
    "print(\"\\nüîπ **Overall Averages:**\")\n",
    "print(f\"‚úÖ RRMSE-T (Time Domain): {overall_rrmse_t:.6f}\")\n",
    "print(f\"‚úÖ RRMSE-S (Spectrum Domain): {overall_rrmse_s:.6f}\")\n",
    "print(f\"‚úÖ Correlation Coefficient (CC): {overall_cc:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ **Final Evaluation Per SNR Level:**\n",
      "-----------------------------------------------------\n",
      "| SNR  |  RRMSE-T  |  RRMSE-S  |   CC   |\n",
      "-----------------------------------------------------\n",
      "|  -7  |  0.550397  |  0.370512  |  0.834759  |\n",
      "|  -6  |  0.517964  |  0.353434  |  0.854145  |\n",
      "|  -5  |  0.476425  |  0.329753  |  0.877256  |\n",
      "|  -4  |  0.450259  |  0.313647  |  0.891114  |\n",
      "|  -3  |  0.426534  |  0.301200  |  0.902818  |\n",
      "|  -2  |  0.404915  |  0.288622  |  0.913014  |\n",
      "|  -1  |  0.384711  |  0.277257  |  0.921995  |\n",
      "|   0  |  0.369178  |  0.269370  |  0.928729  |\n",
      "|   1  |  0.352729  |  0.259815  |  0.935396  |\n",
      "|   2  |  0.340849  |  0.254089  |  0.940113  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "üîπ **Overall Averages:**\n",
      "‚úÖ RRMSE-T (Time Domain): 0.427394\n",
      "‚úÖ RRMSE-S (Spectrum Domain): 0.301769\n",
      "‚úÖ Correlation Coefficient (CC): 0.899935\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "# ---------- Metric Functions ----------\n",
    "def compute_rrmse(denoised, clean):\n",
    "    return np.sqrt(np.mean((denoised - clean) ** 2)) / np.sqrt(np.mean(clean ** 2))\n",
    "\n",
    "def compute_rrmse_spectrum(denoised, clean):\n",
    "    fft_clean = np.abs(fft(clean))\n",
    "    fft_denoised = np.abs(fft(denoised))\n",
    "    return compute_rrmse(fft_denoised, fft_clean)\n",
    "\n",
    "def compute_cc(denoised, clean):\n",
    "    try:\n",
    "        return pearsonr(denoised.flatten(), clean.flatten())[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ---------- Evaluation ----------\n",
    "test_clean = Y_test_tensor.cpu().numpy()\n",
    "test_noisy = X_test_tensor.cpu().numpy()\n",
    "snr_array = snr_labels_test  # already in numpy format\n",
    "\n",
    "snr_metrics = {}\n",
    "all_rrmse_t, all_rrmse_s, all_cc = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for snr in sorted(np.unique(snr_array)):\n",
    "        indices = np.where(snr_array == snr)[0]\n",
    "        X_test_snr = X_test_tensor[indices].to(device)        # (N_snr, 1024, 1)\n",
    "        Y_test_snr = Y_test_tensor[indices].to(device)        # (N_snr, 1024, 1)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_tensor = model(X_test_snr).cpu().numpy()\n",
    "        y_true_numpy = Y_test_snr.cpu().numpy()\n",
    "\n",
    "        # Metrics\n",
    "        rrmse_t_list = [compute_rrmse(y_pred_tensor[i], y_true_numpy[i]) for i in range(len(y_true_numpy))]\n",
    "        rrmse_s_list = [compute_rrmse_spectrum(y_pred_tensor[i], y_true_numpy[i]) for i in range(len(y_true_numpy))]\n",
    "        cc_list = [compute_cc(y_pred_tensor[i], y_true_numpy[i]) for i in range(len(y_true_numpy))]\n",
    "\n",
    "        # Store\n",
    "        snr_metrics[snr] = {\n",
    "            \"RRMSE-T\": np.mean(rrmse_t_list),\n",
    "            \"RRMSE-S\": np.mean(rrmse_s_list),\n",
    "            \"CC\": np.mean(cc_list)\n",
    "        }\n",
    "\n",
    "        all_rrmse_t.extend(rrmse_t_list)\n",
    "        all_rrmse_s.extend(rrmse_s_list)\n",
    "        all_cc.extend(cc_list)\n",
    "\n",
    "# ---------- Results ----------\n",
    "print(\"\\nüîπ **Final Evaluation Per SNR Level:**\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"| SNR  |  RRMSE-T  |  RRMSE-S  |   CC   |\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "for snr in sorted(snr_metrics.keys()):\n",
    "    print(f\"| {snr:3d}  |  {snr_metrics[snr]['RRMSE-T']:.6f}  |  {snr_metrics[snr]['RRMSE-S']:.6f}  |  {snr_metrics[snr]['CC']:.6f}  |\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\nüîπ **Overall Averages:**\")\n",
    "print(f\"‚úÖ RRMSE-T (Time Domain): {np.mean(all_rrmse_t):.6f}\")\n",
    "print(f\"‚úÖ RRMSE-S (Spectrum Domain): {np.mean(all_rrmse_s):.6f}\")\n",
    "print(f\"‚úÖ Correlation Coefficient (CC): {np.mean(all_cc):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ‚úÖ SNR level and segment index you want to visualize\n",
    "snr_level = -5\n",
    "segment_idx = 0  # 0th segment within this SNR level\n",
    "\n",
    "# ‚úÖ Get indices where test samples have this SNR\n",
    "snr_indices = np.where(snr_labels_test == snr_level)[0]\n",
    "\n",
    "if len(snr_indices) == 0:\n",
    "    print(f\"‚ùå No test samples found for SNR {snr_level}\")\n",
    "else:\n",
    "    true_index = snr_indices[segment_idx]\n",
    "\n",
    "    # ‚úÖ Extract segments\n",
    "    noisy_segment = X_test_tensor[true_index].cpu().numpy().squeeze()\n",
    "    clean_segment = Y_test_tensor[true_index].cpu().numpy().squeeze()\n",
    "\n",
    "    # ‚úÖ Denoise that one sample (model must accept input shape (1, 1024, 1))\n",
    "    noisy_input = X_test_tensor[true_index].unsqueeze(0).to(device)  # shape: (1, 1024, 1)\n",
    "    denoised_output = model(noisy_input).cpu().detach().numpy().squeeze()\n",
    "\n",
    "    # ‚úÖ Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(clean_segment, label=\"Clean EEG\", color=\"blue\", linestyle=\"dashed\", linewidth=1.5)\n",
    "    plt.plot(noisy_segment, label=\"Contaminated EEG\", color=\"red\", alpha=0.6)\n",
    "    plt.plot(denoised_output, label=\"Denoised EEG\", color=\"green\", linewidth=1.5)\n",
    "\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"EEG Signal Amplitude\")\n",
    "    plt.title(f\"EEG Denoising - SNR {snr_level}, Segment {segment_idx}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean EEG Plotting Points:\n",
      "(0, 615.7932739257812)\n",
      "(1, 717.6267700195312)\n",
      "(2, 799.8013305664062)\n",
      "(3, 882.2861328125)\n",
      "(4, 917.1929931640625)\n",
      "(5, 917.880126953125)\n",
      "(6, 849.228271484375)\n",
      "(7, 739.8196411132812)\n",
      "(8, 603.4371337890625)\n",
      "(9, 486.0830993652344)\n",
      "(10, 410.14349365234375)\n",
      "(11, 382.2594909667969)\n",
      "(12, 382.06640625)\n",
      "(13, 377.4629211425781)\n",
      "(14, 341.6598815917969)\n",
      "(15, 265.3277587890625)\n",
      "(16, 157.08447265625)\n",
      "(17, 34.6849250793457)\n",
      "(18, -85.33229064941406)\n",
      "(19, -192.61618041992188)\n",
      "(20, -281.6571350097656)\n",
      "(21, -348.5924377441406)\n",
      "(22, -391.1279602050781)\n",
      "(23, -412.0375671386719)\n",
      "(24, -421.7405090332031)\n",
      "(25, -434.9580078125)\n",
      "(26, -461.3686218261719)\n",
      "(27, -496.5245666503906)\n",
      "(28, -521.220458984375)\n",
      "(29, -512.365966796875)\n",
      "(30, -459.5452575683594)\n",
      "(31, -375.6746826171875)\n",
      "(32, -292.8109436035156)\n",
      "(33, -244.12380981445312)\n",
      "(34, -243.45860290527344)\n",
      "(35, -276.6315002441406)\n",
      "(36, -311.09326171875)\n",
      "(37, -317.9304504394531)\n",
      "(38, -290.9862060546875)\n",
      "(39, -249.67294311523438)\n",
      "(40, -223.42872619628906)\n",
      "(41, -228.88478088378906)\n",
      "(42, -256.1031188964844)\n",
      "(43, -273.7987060546875)\n",
      "(44, -249.9356231689453)\n",
      "(45, -173.18020629882812)\n",
      "(46, -60.416908264160156)\n",
      "(47, 54.56154251098633)\n",
      "(48, 142.75558471679688)\n",
      "(49, 196.8204345703125)\n",
      "(50, 232.03721618652344)\n",
      "(51, 272.00018310546875)\n",
      "(52, 330.08929443359375)\n",
      "(53, 399.7206726074219)\n",
      "(54, 459.0373229980469)\n",
      "(55, 485.1178283691406)\n",
      "(56, 467.0323181152344)\n",
      "(57, 409.3472900390625)\n",
      "(58, 325.8441162109375)\n",
      "(59, 230.15802001953125)\n",
      "(60, 130.6614227294922)\n",
      "(61, 31.75555419921875)\n",
      "(62, -62.29111862182617)\n",
      "(63, -146.35621643066406)\n",
      "(64, -217.880615234375)\n",
      "(65, -280.8421325683594)\n",
      "(66, -344.8582458496094)\n",
      "(67, -418.0355529785156)\n",
      "(68, -498.5115966796875)\n",
      "(69, -572.3929443359375)\n",
      "(70, -621.7596435546875)\n",
      "(71, -638.1774291992188)\n",
      "(72, -631.4524536132812)\n",
      "(73, -625.4901123046875)\n",
      "(74, -642.47998046875)\n",
      "(75, -686.1466064453125)\n",
      "(76, -736.94970703125)\n",
      "(77, -764.1067504882812)\n",
      "(78, -746.646240234375)\n",
      "(79, -688.5316162109375)\n",
      "(80, -616.3301391601562)\n",
      "(81, -560.6580200195312)\n",
      "(82, -534.8707885742188)\n",
      "(83, -526.7638549804688)\n",
      "(84, -509.3504333496094)\n",
      "(85, -462.2789611816406)\n",
      "(86, -387.31817626953125)\n",
      "(87, -306.1834411621094)\n",
      "(88, -242.55970764160156)\n",
      "(89, -202.8377685546875)\n",
      "(90, -171.09803771972656)\n",
      "(91, -122.57030487060547)\n",
      "(92, -45.090145111083984)\n",
      "(93, 48.609683990478516)\n",
      "(94, 128.05714416503906)\n",
      "(95, 166.72772216796875)\n",
      "(96, 161.826171875)\n",
      "(97, 136.70933532714844)\n",
      "(98, 124.00485229492188)\n",
      "(99, 142.17562866210938)\n",
      "(100, 183.40834045410156)\n",
      "(101, 222.03616333007812)\n",
      "(102, 236.73780822753906)\n",
      "(103, 229.19107055664062)\n",
      "(104, 224.6282196044922)\n",
      "(105, 253.68093872070312)\n",
      "(106, 329.1041259765625)\n",
      "(107, 434.6459655761719)\n",
      "(108, 533.96875)\n",
      "(109, 592.6111450195312)\n",
      "(110, 596.9832763671875)\n",
      "(111, 557.7296142578125)\n",
      "(112, 497.2120666503906)\n",
      "(113, 432.4076232910156)\n",
      "(114, 366.50592041015625)\n",
      "(115, 294.1950988769531)\n",
      "(116, 214.25228881835938)\n",
      "(117, 137.73199462890625)\n",
      "(118, 84.37976837158203)\n",
      "(119, 69.97311401367188)\n",
      "(120, 94.61483001708984)\n",
      "(121, 141.06222534179688)\n",
      "(122, 184.41876220703125)\n",
      "(123, 205.98464965820312)\n",
      "(124, 201.7353515625)\n",
      "(125, 180.61399841308594)\n",
      "(126, 155.51878356933594)\n",
      "(127, 134.35372924804688)\n",
      "(128, 117.04795837402344)\n",
      "(129, 99.0141830444336)\n",
      "(130, 76.89901733398438)\n",
      "(131, 51.819580078125)\n",
      "(132, 28.480667114257812)\n",
      "(133, 11.89073657989502)\n",
      "(134, 4.597432613372803)\n",
      "(135, 5.8949294090271)\n",
      "(136, 12.486988067626953)\n",
      "(137, 19.503780364990234)\n",
      "(138, 21.665081024169922)\n",
      "(139, 15.044418334960938)\n",
      "(140, -0.6621143817901611)\n",
      "(141, -21.062788009643555)\n",
      "(142, -39.014427185058594)\n",
      "(143, -49.47746276855469)\n",
      "(144, -54.228492736816406)\n",
      "(145, -62.170101165771484)\n",
      "(146, -83.57682800292969)\n",
      "(147, -121.46833801269531)\n",
      "(148, -166.64044189453125)\n",
      "(149, -201.27633666992188)\n",
      "(150, -209.942626953125)\n",
      "(151, -190.57858276367188)\n",
      "(152, -156.9758758544922)\n",
      "(153, -129.8434600830078)\n",
      "(154, -122.09160614013672)\n",
      "(155, -128.91883850097656)\n",
      "(156, -130.40750122070312)\n",
      "(157, -105.36461639404297)\n",
      "(158, -46.69402313232422)\n",
      "(159, 32.82086181640625)\n",
      "(160, 108.52816772460938)\n",
      "(161, 159.8153076171875)\n",
      "(162, 182.38775634765625)\n",
      "(163, 188.3682861328125)\n",
      "(164, 194.9197540283203)\n",
      "(165, 210.54432678222656)\n",
      "(166, 229.37387084960938)\n",
      "(167, 237.2749786376953)\n",
      "(168, 224.50047302246094)\n",
      "(169, 194.96669006347656)\n",
      "(170, 165.18580627441406)\n",
      "(171, 153.823486328125)\n",
      "(172, 169.5596160888672)\n",
      "(173, 205.6819610595703)\n",
      "(174, 244.4400634765625)\n",
      "(175, 267.6523742675781)\n",
      "(176, 266.3428649902344)\n",
      "(177, 243.9805450439453)\n",
      "(178, 212.7340545654297)\n",
      "(179, 186.22418212890625)\n",
      "(180, 173.1626434326172)\n",
      "(181, 174.39151000976562)\n",
      "(182, 183.40126037597656)\n",
      "(183, 189.1964569091797)\n",
      "(184, 180.3574981689453)\n",
      "(185, 149.38525390625)\n",
      "(186, 96.03034973144531)\n",
      "(187, 27.973896026611328)\n",
      "(188, -41.982444763183594)\n",
      "(189, -101.14070129394531)\n",
      "(190, -141.6659393310547)\n",
      "(191, -162.1128692626953)\n",
      "(192, -165.27865600585938)\n",
      "(193, -154.77999877929688)\n",
      "(194, -133.61907958984375)\n",
      "(195, -105.87737274169922)\n",
      "(196, -79.28530883789062)\n",
      "(197, -64.87149047851562)\n",
      "(198, -72.029296875)\n",
      "(199, -101.76438903808594)\n",
      "(200, -143.7847900390625)\n",
      "(201, -181.34397888183594)\n",
      "(202, -202.00457763671875)\n",
      "(203, -206.982666015625)\n",
      "(204, -211.3828125)\n",
      "(205, -233.59815979003906)\n",
      "(206, -280.3924865722656)\n",
      "(207, -338.58697509765625)\n",
      "(208, -380.5975341796875)\n",
      "(209, -381.4631042480469)\n",
      "(210, -336.31414794921875)\n",
      "(211, -266.0166320800781)\n",
      "(212, -206.41770935058594)\n",
      "(213, -187.88943481445312)\n",
      "(214, -218.53582763671875)\n",
      "(215, -281.8294372558594)\n",
      "(216, -348.9301452636719)\n",
      "(217, -396.373046875)\n",
      "(218, -416.9648132324219)\n",
      "(219, -417.9280700683594)\n",
      "(220, -410.3741760253906)\n",
      "(221, -400.0714416503906)\n",
      "(222, -386.93414306640625)\n",
      "(223, -372.2132263183594)\n",
      "(224, -365.0832824707031)\n",
      "(225, -380.5286560058594)\n",
      "(226, -427.9593505859375)\n",
      "(227, -499.01800537109375)\n",
      "(228, -565.8261108398438)\n",
      "(229, -594.3358154296875)\n",
      "(230, -565.944091796875)\n",
      "(231, -492.65631103515625)\n",
      "(232, -413.55963134765625)\n",
      "(233, -372.42535400390625)\n",
      "(234, -389.8138427734375)\n",
      "(235, -448.33001708984375)\n",
      "(236, -502.0851135253906)\n",
      "(237, -505.542724609375)\n",
      "(238, -443.4222412109375)\n",
      "(239, -341.76287841796875)\n",
      "(240, -252.21417236328125)\n",
      "(241, -219.3128204345703)\n",
      "(242, -252.01382446289062)\n",
      "(243, -318.0863952636719)\n",
      "(244, -364.91033935546875)\n",
      "(245, -352.8065490722656)\n",
      "(246, -279.08746337890625)\n",
      "(247, -177.74163818359375)\n",
      "(248, -96.14189910888672)\n",
      "(249, -65.0970230102539)\n",
      "(250, -81.95732116699219)\n",
      "(251, -116.55421447753906)\n",
      "(252, -134.0139923095703)\n",
      "(253, -117.85681915283203)\n",
      "(254, -78.16154479980469)\n",
      "(255, -41.086734771728516)\n",
      "(256, -28.961956024169922)\n",
      "(257, -45.460693359375)\n",
      "(258, -75.33768463134766)\n",
      "(259, -96.75987243652344)\n",
      "(260, -96.4832992553711)\n",
      "(261, -77.17586517333984)\n",
      "(262, -53.298030853271484)\n",
      "(263, -40.185482025146484)\n",
      "(264, -44.58320617675781)\n",
      "(265, -62.12242126464844)\n",
      "(266, -81.39620971679688)\n",
      "(267, -90.25431823730469)\n",
      "(268, -80.25089263916016)\n",
      "(269, -48.262142181396484)\n",
      "(270, 3.2581074237823486)\n",
      "(271, 66.19298553466797)\n",
      "(272, 127.61708068847656)\n",
      "(273, 173.18646240234375)\n",
      "(274, 192.88670349121094)\n",
      "(275, 186.072998046875)\n",
      "(276, 161.83547973632812)\n",
      "(277, 133.43641662597656)\n",
      "(278, 110.16275787353516)\n",
      "(279, 92.43404388427734)\n",
      "(280, 73.86328887939453)\n",
      "(281, 48.48679733276367)\n",
      "(282, 17.067054748535156)\n",
      "(283, -12.889813423156738)\n",
      "(284, -33.34885025024414)\n",
      "(285, -42.57090377807617)\n",
      "(286, -46.23941421508789)\n",
      "(287, -51.63492202758789)\n",
      "(288, -60.12248992919922)\n",
      "(289, -65.31040954589844)\n",
      "(290, -59.44654846191406)\n",
      "(291, -42.84630584716797)\n",
      "(292, -27.33135223388672)\n",
      "(293, -28.736713409423828)\n",
      "(294, -53.045310974121094)\n",
      "(295, -87.47470092773438)\n",
      "(296, -105.50667572021484)\n",
      "(297, -84.26981353759766)\n",
      "(298, -22.040151596069336)\n",
      "(299, 57.92661666870117)\n",
      "(300, 121.30592346191406)\n",
      "(301, 144.67385864257812)\n",
      "(302, 129.2014617919922)\n",
      "(303, 95.89435577392578)\n",
      "(304, 66.95796203613281)\n",
      "(305, 49.0149040222168)\n",
      "(306, 32.083126068115234)\n",
      "(307, 4.608586311340332)\n",
      "(308, -29.430532455444336)\n",
      "(309, -47.884185791015625)\n",
      "(310, -26.83993148803711)\n",
      "(311, 36.39280700683594)\n",
      "(312, 113.689208984375)\n",
      "(313, 160.74571228027344)\n",
      "(314, 147.35015869140625)\n",
      "(315, 80.61775970458984)\n",
      "(316, 2.1190617084503174)\n",
      "(317, -40.76555633544922)\n",
      "(318, -28.513351440429688)\n",
      "(319, 17.429656982421875)\n",
      "(320, 52.40154266357422)\n",
      "(321, 43.639076232910156)\n",
      "(322, -4.379968643188477)\n",
      "(323, -53.88747787475586)\n",
      "(324, -63.62674331665039)\n",
      "(325, -20.88286018371582)\n",
      "(326, 49.30111312866211)\n",
      "(327, 104.39392852783203)\n",
      "(328, 117.49974060058594)\n",
      "(329, 97.03532409667969)\n",
      "(330, 78.02678680419922)\n",
      "(331, 92.94320678710938)\n",
      "(332, 145.79917907714844)\n",
      "(333, 209.60536193847656)\n",
      "(334, 247.83018493652344)\n",
      "(335, 241.597412109375)\n",
      "(336, 201.01119995117188)\n",
      "(337, 153.2694854736328)\n",
      "(338, 119.50381469726562)\n",
      "(339, 100.46310424804688)\n",
      "(340, 82.03623962402344)\n",
      "(341, 53.76068878173828)\n",
      "(342, 22.424219131469727)\n",
      "(343, 8.049464225769043)\n",
      "(344, 25.721206665039062)\n",
      "(345, 69.83052062988281)\n",
      "(346, 115.61734771728516)\n",
      "(347, 137.77450561523438)\n",
      "(348, 130.6076202392578)\n",
      "(349, 112.16178894042969)\n",
      "(350, 108.07958221435547)\n",
      "(351, 128.44679260253906)\n",
      "(352, 157.44976806640625)\n",
      "(353, 165.35519409179688)\n",
      "(354, 133.41488647460938)\n",
      "(355, 70.94268035888672)\n",
      "(356, 9.734610557556152)\n",
      "(357, -20.305652618408203)\n",
      "(358, -14.53455924987793)\n",
      "(359, 3.50580096244812)\n",
      "(360, 2.373993158340454)\n",
      "(361, -30.32615089416504)\n",
      "(362, -76.69863891601562)\n",
      "(363, -102.64836120605469)\n",
      "(364, -86.03627014160156)\n",
      "(365, -35.762149810791016)\n",
      "(366, 14.193328857421875)\n",
      "(367, 31.345857620239258)\n",
      "(368, 10.551429748535156)\n",
      "(369, -21.791105270385742)\n",
      "(370, -28.590208053588867)\n",
      "(371, 8.848615646362305)\n",
      "(372, 76.77318572998047)\n",
      "(373, 140.8357391357422)\n",
      "(374, 173.6306610107422)\n",
      "(375, 175.31309509277344)\n",
      "(376, 170.80905151367188)\n",
      "(377, 186.51321411132812)\n",
      "(378, 226.18824768066406)\n",
      "(379, 266.1217041015625)\n",
      "(380, 273.7082214355469)\n",
      "(381, 234.42312622070312)\n",
      "(382, 165.3142547607422)\n",
      "(383, 103.95537567138672)\n",
      "(384, 81.34807586669922)\n",
      "(385, 99.74468994140625)\n",
      "(386, 132.26683044433594)\n",
      "(387, 143.77369689941406)\n",
      "(388, 116.61610412597656)\n",
      "(389, 61.886940002441406)\n",
      "(390, 8.970535278320312)\n",
      "(391, -17.05008316040039)\n",
      "(392, -12.317506790161133)\n",
      "(393, 6.420737266540527)\n",
      "(394, 17.47942543029785)\n",
      "(395, 11.392581939697266)\n",
      "(396, -3.4743802547454834)\n",
      "(397, -9.60086727142334)\n",
      "(398, 5.214639663696289)\n",
      "(399, 39.239871978759766)\n",
      "(400, 79.4661636352539)\n",
      "(401, 111.49092102050781)\n",
      "(402, 127.81328582763672)\n",
      "(403, 128.8772735595703)\n",
      "(404, 118.35526275634766)\n",
      "(405, 98.72017669677734)\n",
      "(406, 71.44181060791016)\n",
      "(407, 40.529178619384766)\n",
      "(408, 14.307663917541504)\n",
      "(409, 1.9886606931686401)\n",
      "(410, 7.103142261505127)\n",
      "(411, 23.864633560180664)\n",
      "(412, 40.92997360229492)\n",
      "(413, 50.764652252197266)\n",
      "(414, 57.286224365234375)\n",
      "(415, 74.73970031738281)\n",
      "(416, 117.26153564453125)\n",
      "(417, 186.25148010253906)\n",
      "(418, 265.318115234375)\n",
      "(419, 327.534423828125)\n",
      "(420, 350.8110656738281)\n",
      "(421, 331.1945495605469)\n",
      "(422, 285.05474853515625)\n",
      "(423, 239.01071166992188)\n",
      "(424, 214.7799530029297)\n",
      "(425, 219.0247039794922)\n",
      "(426, 243.89938354492188)\n",
      "(427, 276.1084899902344)\n",
      "(428, 306.8092041015625)\n",
      "(429, 335.2657470703125)\n",
      "(430, 364.6781005859375)\n",
      "(431, 394.82489013671875)\n",
      "(432, 417.9360046386719)\n",
      "(433, 421.32427978515625)\n",
      "(434, 394.9439392089844)\n",
      "(435, 338.4942321777344)\n",
      "(436, 263.1538391113281)\n",
      "(437, 186.80723571777344)\n",
      "(438, 125.73855590820312)\n",
      "(439, 87.6172866821289)\n",
      "(440, 69.24681091308594)\n",
      "(441, 59.76102066040039)\n",
      "(442, 47.122955322265625)\n",
      "(443, 24.56751251220703)\n",
      "(444, -5.822320938110352)\n",
      "(445, -33.81577682495117)\n",
      "(446, -45.680381774902344)\n",
      "(447, -30.93040657043457)\n",
      "(448, 11.70910358428955)\n",
      "(449, 72.08148956298828)\n",
      "(450, 131.80230712890625)\n",
      "(451, 172.09170532226562)\n",
      "(452, 182.7747039794922)\n",
      "(453, 167.71849060058594)\n",
      "(454, 143.25997924804688)\n",
      "(455, 129.7769775390625)\n",
      "(456, 140.6405029296875)\n",
      "(457, 174.79296875)\n",
      "(458, 217.59471130371094)\n",
      "(459, 249.8011932373047)\n",
      "(460, 259.4629211425781)\n",
      "(461, 249.32012939453125)\n",
      "(462, 234.68870544433594)\n",
      "(463, 232.9665985107422)\n",
      "(464, 251.48440551757812)\n",
      "(465, 281.9931335449219)\n",
      "(466, 305.9705810546875)\n",
      "(467, 307.6071472167969)\n",
      "(468, 285.6659240722656)\n",
      "(469, 255.62454223632812)\n",
      "(470, 239.84815979003906)\n",
      "(471, 252.1310577392578)\n",
      "(472, 287.1565856933594)\n",
      "(473, 322.7530517578125)\n",
      "(474, 333.9109191894531)\n",
      "(475, 308.9877014160156)\n",
      "(476, 256.6630554199219)\n",
      "(477, 198.62472534179688)\n",
      "(478, 153.33096313476562)\n",
      "(479, 122.89877319335938)\n",
      "(480, 92.9689712524414)\n",
      "(481, 45.790672302246094)\n",
      "(482, -23.48314094543457)\n",
      "(483, -99.92584991455078)\n",
      "(484, -157.15982055664062)\n",
      "(485, -175.1227569580078)\n",
      "(486, -154.04360961914062)\n",
      "(487, -113.98698425292969)\n",
      "(488, -80.12444305419922)\n",
      "(489, -64.81928253173828)\n",
      "(490, -60.12279510498047)\n",
      "(491, -46.31455612182617)\n",
      "(492, -9.673382759094238)\n",
      "(493, 44.66248321533203)\n",
      "(494, 95.25423431396484)\n",
      "(495, 120.87364196777344)\n",
      "(496, 118.35231018066406)\n",
      "(497, 107.52142333984375)\n",
      "(498, 118.3687744140625)\n",
      "(499, 169.0020751953125)\n",
      "(500, 250.33010864257812)\n",
      "(501, 329.0697326660156)\n",
      "(502, 367.67626953125)\n",
      "(503, 347.90936279296875)\n",
      "(504, 282.2604675292969)\n",
      "(505, 206.016845703125)\n",
      "(506, 156.15481567382812)\n",
      "(507, 151.12591552734375)\n",
      "(508, 183.74549865722656)\n",
      "(509, 229.44070434570312)\n",
      "(510, 262.1266174316406)\n",
      "(511, 266.68023681640625)\n",
      "(512, 241.67681884765625)\n",
      "(513, 193.98306274414062)\n",
      "(514, 131.8194580078125)\n",
      "(515, 61.58099365234375)\n",
      "(516, -10.9826078414917)\n",
      "(517, -78.86473083496094)\n",
      "(518, -134.6040496826172)\n",
      "(519, -173.74652099609375)\n",
      "(520, -197.696044921875)\n",
      "(521, -212.85610961914062)\n",
      "(522, -226.22549438476562)\n",
      "(523, -240.97328186035156)\n",
      "(524, -255.51284790039062)\n",
      "(525, -266.7360534667969)\n",
      "(526, -274.0447692871094)\n",
      "(527, -280.17718505859375)\n",
      "(528, -287.8558654785156)\n",
      "(529, -295.3679504394531)\n",
      "(530, -295.8643798828125)\n",
      "(531, -282.3152160644531)\n",
      "(532, -254.94044494628906)\n",
      "(533, -224.76953125)\n",
      "(534, -208.92332458496094)\n",
      "(535, -219.32225036621094)\n",
      "(536, -252.29891967773438)\n",
      "(537, -287.2519836425781)\n",
      "(538, -296.90643310546875)\n",
      "(539, -263.607666015625)\n",
      "(540, -191.22244262695312)\n",
      "(541, -104.46321868896484)\n",
      "(542, -35.51988220214844)\n",
      "(543, -6.248565673828125)\n",
      "(544, -17.046192169189453)\n",
      "(545, -48.9471321105957)\n",
      "(546, -76.67060852050781)\n",
      "(547, -83.51538848876953)\n",
      "(548, -68.64153289794922)\n",
      "(549, -43.138526916503906)\n",
      "(550, -19.165857315063477)\n",
      "(551, -0.5739632248878479)\n",
      "(552, 18.56218910217285)\n",
      "(553, 47.31258773803711)\n",
      "(554, 88.75877380371094)\n",
      "(555, 135.27947998046875)\n",
      "(556, 171.48703002929688)\n",
      "(557, 182.4698944091797)\n",
      "(558, 161.68795776367188)\n",
      "(559, 113.52650451660156)\n",
      "(560, 49.744529724121094)\n",
      "(561, -16.97282600402832)\n",
      "(562, -77.93975067138672)\n",
      "(563, -129.49595642089844)\n",
      "(564, -171.0315399169922)\n",
      "(565, -202.7845916748047)\n",
      "(566, -225.4490509033203)\n",
      "(567, -241.28204345703125)\n",
      "(568, -254.74404907226562)\n",
      "(569, -270.9324645996094)\n",
      "(570, -292.2089538574219)\n",
      "(571, -315.44012451171875)\n",
      "(572, -332.37310791015625)\n",
      "(573, -333.721435546875)\n",
      "(574, -314.81512451171875)\n",
      "(575, -279.3107604980469)\n",
      "(576, -238.45697021484375)\n",
      "(577, -206.11082458496094)\n",
      "(578, -192.29266357421875)\n",
      "(579, -198.86895751953125)\n",
      "(580, -219.55929565429688)\n",
      "(581, -243.91519165039062)\n",
      "(582, -262.8214111328125)\n",
      "(583, -272.52099609375)\n",
      "(584, -275.2344665527344)\n",
      "(585, -276.3719177246094)\n",
      "(586, -280.0248107910156)\n",
      "(587, -285.2325439453125)\n",
      "(588, -285.05059814453125)\n",
      "(589, -269.0935363769531)\n",
      "(590, -228.555419921875)\n",
      "(591, -161.19393920898438)\n",
      "(592, -73.6623764038086)\n",
      "(593, 20.218523025512695)\n",
      "(594, 104.52073669433594)\n",
      "(595, 167.03880310058594)\n",
      "(596, 203.0015411376953)\n",
      "(597, 215.21368408203125)\n",
      "(598, 211.3988800048828)\n",
      "(599, 200.899658203125)\n",
      "(600, 192.49400329589844)\n",
      "(601, 193.44558715820312)\n",
      "(602, 208.3935089111328)\n",
      "(603, 237.0869140625)\n",
      "(604, 271.8780822753906)\n",
      "(605, 297.59356689453125)\n",
      "(606, 295.9201965332031)\n",
      "(607, 253.51551818847656)\n",
      "(608, 169.5985107421875)\n",
      "(609, 57.930450439453125)\n",
      "(610, -59.06739044189453)\n",
      "(611, -160.991455078125)\n",
      "(612, -238.20077514648438)\n",
      "(613, -292.98199462890625)\n",
      "(614, -332.8208312988281)\n",
      "(615, -361.3576354980469)\n",
      "(616, -374.3769836425781)\n",
      "(617, -364.21307373046875)\n",
      "(618, -329.08001708984375)\n",
      "(619, -279.4588928222656)\n",
      "(620, -235.48387145996094)\n",
      "(621, -216.16207885742188)\n",
      "(622, -227.88833618164062)\n",
      "(623, -260.76141357421875)\n",
      "(624, -295.548583984375)\n",
      "(625, -316.07183837890625)\n",
      "(626, -317.7610168457031)\n",
      "(627, -306.3663330078125)\n",
      "(628, -288.89141845703125)\n",
      "(629, -265.0931091308594)\n",
      "(630, -227.25070190429688)\n",
      "(631, -168.64280700683594)\n",
      "(632, -93.3507308959961)\n",
      "(633, -18.245237350463867)\n",
      "(634, 36.060585021972656)\n",
      "(635, 59.093990325927734)\n",
      "(636, 58.29616928100586)\n",
      "(637, 53.67157745361328)\n",
      "(638, 62.40179443359375)\n",
      "(639, 84.80989074707031)\n",
      "(640, 102.82485961914062)\n",
      "(641, 92.97176361083984)\n",
      "(642, 44.78470993041992)\n",
      "(643, -28.846525192260742)\n",
      "(644, -97.36359405517578)\n",
      "(645, -130.3617706298828)\n",
      "(646, -115.02310943603516)\n",
      "(647, -61.391815185546875)\n",
      "(648, 6.867649555206299)\n",
      "(649, 68.05907440185547)\n",
      "(650, 112.67930603027344)\n",
      "(651, 142.18695068359375)\n",
      "(652, 160.0558319091797)\n",
      "(653, 164.4650421142578)\n",
      "(654, 149.45465087890625)\n",
      "(655, 112.93696594238281)\n",
      "(656, 63.263179779052734)\n",
      "(657, 16.95859718322754)\n",
      "(658, -12.041810035705566)\n",
      "(659, -23.300378799438477)\n",
      "(660, -31.374853134155273)\n",
      "(661, -55.31357192993164)\n",
      "(662, -103.35418701171875)\n",
      "(663, -164.5540771484375)\n",
      "(664, -214.3512725830078)\n",
      "(665, -230.5338897705078)\n",
      "(666, -207.9599151611328)\n",
      "(667, -161.1834716796875)\n",
      "(668, -113.34526062011719)\n",
      "(669, -80.10462188720703)\n",
      "(670, -60.87731170654297)\n",
      "(671, -43.5347900390625)\n",
      "(672, -17.93731689453125)\n",
      "(673, 13.20097827911377)\n",
      "(674, 35.19347381591797)\n",
      "(675, 33.39043045043945)\n",
      "(676, 6.556746006011963)\n",
      "(677, -29.442049026489258)\n",
      "(678, -51.198631286621094)\n",
      "(679, -43.64615249633789)\n",
      "(680, -10.285680770874023)\n",
      "(681, 29.97673988342285)\n",
      "(682, 56.88405227661133)\n",
      "(683, 63.086299896240234)\n",
      "(684, 58.032798767089844)\n",
      "(685, 59.090213775634766)\n",
      "(686, 77.17778015136719)\n",
      "(687, 108.07074737548828)\n",
      "(688, 135.69424438476562)\n",
      "(689, 144.3212890625)\n",
      "(690, 130.0003662109375)\n",
      "(691, 102.67089080810547)\n",
      "(692, 78.03809356689453)\n",
      "(693, 66.08128356933594)\n",
      "(694, 65.00847625732422)\n",
      "(695, 64.44334411621094)\n",
      "(696, 54.06257247924805)\n",
      "(697, 30.157596588134766)\n",
      "(698, -4.693440914154053)\n",
      "(699, -47.0891227722168)\n",
      "(700, -97.10305786132812)\n",
      "(701, -156.6248016357422)\n",
      "(702, -223.1032257080078)\n",
      "(703, -285.3121337890625)\n",
      "(704, -327.1001892089844)\n",
      "(705, -338.42034912109375)\n",
      "(706, -325.6338806152344)\n",
      "(707, -311.6487121582031)\n",
      "(708, -323.0061950683594)\n",
      "(709, -371.2483825683594)\n",
      "(710, -441.72735595703125)\n",
      "(711, -499.2744445800781)\n",
      "(712, -508.7569885253906)\n",
      "(713, -457.5259704589844)\n",
      "(714, -364.57244873046875)\n",
      "(715, -269.8204040527344)\n",
      "(716, -210.56192016601562)\n",
      "(717, -200.70448303222656)\n",
      "(718, -225.9974822998047)\n",
      "(719, -256.94610595703125)\n",
      "(720, -268.9765930175781)\n",
      "(721, -255.60476684570312)\n",
      "(722, -226.9582977294922)\n",
      "(723, -197.4132537841797)\n",
      "(724, -173.46092224121094)\n",
      "(725, -150.98631286621094)\n",
      "(726, -122.38627624511719)\n",
      "(727, -85.857421875)\n",
      "(728, -48.16907501220703)\n",
      "(729, -18.753904342651367)\n",
      "(730, -0.7555148601531982)\n",
      "(731, 12.622392654418945)\n",
      "(732, 32.84545135498047)\n",
      "(733, 66.13280487060547)\n",
      "(734, 107.37010955810547)\n",
      "(735, 143.24131774902344)\n",
      "(736, 162.26190185546875)\n",
      "(737, 163.54832458496094)\n",
      "(738, 157.2567138671875)\n",
      "(739, 156.42481994628906)\n",
      "(740, 166.87594604492188)\n",
      "(741, 183.11021423339844)\n",
      "(742, 192.81472778320312)\n",
      "(743, 185.5661163330078)\n",
      "(744, 158.46173095703125)\n",
      "(745, 114.96907043457031)\n",
      "(746, 59.66827392578125)\n",
      "(747, -5.082491397857666)\n",
      "(748, -77.1765365600586)\n",
      "(749, -150.10293579101562)\n",
      "(750, -211.71441650390625)\n",
      "(751, -249.82492065429688)\n",
      "(752, -261.2456359863281)\n",
      "(753, -256.2637939453125)\n",
      "(754, -252.9662628173828)\n",
      "(755, -264.0419006347656)\n",
      "(756, -285.970947265625)\n",
      "(757, -300.0589599609375)\n",
      "(758, -286.0484619140625)\n",
      "(759, -238.66690063476562)\n",
      "(760, -174.0825958251953)\n",
      "(761, -120.3546371459961)\n",
      "(762, -98.39803314208984)\n",
      "(763, -107.74125671386719)\n",
      "(764, -127.98226928710938)\n",
      "(765, -134.59994506835938)\n",
      "(766, -116.51009368896484)\n",
      "(767, -81.59344482421875)\n",
      "(768, -46.46272659301758)\n",
      "(769, -19.736242294311523)\n",
      "(770, 6.592723369598389)\n",
      "(771, 50.11737060546875)\n",
      "(772, 120.91444396972656)\n",
      "(773, 208.83651733398438)\n",
      "(774, 286.41912841796875)\n",
      "(775, 326.0074768066406)\n",
      "(776, 318.0885009765625)\n",
      "(777, 276.76275634765625)\n",
      "(778, 228.60574340820312)\n",
      "(779, 194.28533935546875)\n",
      "(780, 177.42124938964844)\n",
      "(781, 168.3594970703125)\n",
      "(782, 157.75613403320312)\n",
      "(783, 147.08876037597656)\n",
      "(784, 146.71961975097656)\n",
      "(785, 163.62796020507812)\n",
      "(786, 190.3451690673828)\n",
      "(787, 205.8151092529297)\n",
      "(788, 188.6640625)\n",
      "(789, 132.50917053222656)\n",
      "(790, 50.88914108276367)\n",
      "(791, -32.141639709472656)\n",
      "(792, -98.04293060302734)\n",
      "(793, -143.72198486328125)\n",
      "(794, -178.42620849609375)\n",
      "(795, -211.91529846191406)\n",
      "(796, -245.15953063964844)\n",
      "(797, -271.53729248046875)\n",
      "(798, -286.25030517578125)\n",
      "(799, -293.8804931640625)\n",
      "(800, -305.7540283203125)\n",
      "(801, -328.6115417480469)\n",
      "(802, -355.0511169433594)\n",
      "(803, -365.78631591796875)\n",
      "(804, -343.8377380371094)\n",
      "(805, -289.6936950683594)\n",
      "(806, -224.15765380859375)\n",
      "(807, -175.00502014160156)\n",
      "(808, -157.08236694335938)\n",
      "(809, -161.70668029785156)\n",
      "(810, -164.3080291748047)\n",
      "(811, -144.5242156982422)\n",
      "(812, -102.51155853271484)\n",
      "(813, -58.07131576538086)\n",
      "(814, -33.207069396972656)\n",
      "(815, -32.5759391784668)\n",
      "(816, -38.2261848449707)\n",
      "(817, -23.329599380493164)\n",
      "(818, 26.1478271484375)\n",
      "(819, 99.63888549804688)\n",
      "(820, 169.85177612304688)\n",
      "(821, 214.05487060546875)\n",
      "(822, 231.54701232910156)\n",
      "(823, 243.39874267578125)\n",
      "(824, 275.17364501953125)\n",
      "(825, 336.9929504394531)\n",
      "(826, 416.9326477050781)\n",
      "(827, 492.122802734375)\n",
      "(828, 547.1141967773438)\n",
      "(829, 583.5919799804688)\n",
      "(830, 613.6974487304688)\n",
      "(831, 643.80712890625)\n",
      "(832, 664.008056640625)\n",
      "(833, 653.5361938476562)\n",
      "(834, 598.4139404296875)\n",
      "(835, 506.4278259277344)\n",
      "(836, 406.0750732421875)\n",
      "(837, 329.0133361816406)\n",
      "(838, 289.1685791015625)\n",
      "(839, 274.7052307128906)\n",
      "(840, 258.8782653808594)\n",
      "(841, 220.89328002929688)\n",
      "(842, 160.35952758789062)\n",
      "(843, 94.71588897705078)\n",
      "(844, 42.96802520751953)\n",
      "(845, 9.740427017211914)\n",
      "(846, -17.416872024536133)\n",
      "(847, -56.01622772216797)\n",
      "(848, -112.30264282226562)\n",
      "(849, -173.99598693847656)\n",
      "(850, -217.62246704101562)\n",
      "(851, -224.30267333984375)\n",
      "(852, -191.92869567871094)\n",
      "(853, -135.5400848388672)\n",
      "(854, -77.3014144897461)\n",
      "(855, -34.60268020629883)\n",
      "(856, -14.279510498046875)\n",
      "(857, -14.49435043334961)\n",
      "(858, -29.81365203857422)\n",
      "(859, -54.288448333740234)\n",
      "(860, -81.35818481445312)\n",
      "(861, -103.44133758544922)\n",
      "(862, -113.98066711425781)\n",
      "(863, -111.04740142822266)\n",
      "(864, -98.62067413330078)\n",
      "(865, -83.00291442871094)\n",
      "(866, -66.48592376708984)\n",
      "(867, -43.9200439453125)\n",
      "(868, -6.027389049530029)\n",
      "(869, 52.731842041015625)\n",
      "(870, 128.7256622314453)\n",
      "(871, 211.75486755371094)\n",
      "(872, 294.1386413574219)\n",
      "(873, 377.9386291503906)\n",
      "(874, 472.23614501953125)\n",
      "(875, 580.6194458007812)\n",
      "(876, 688.7933959960938)\n",
      "(877, 764.6401977539062)\n",
      "(878, 774.6553955078125)\n",
      "(879, 707.1690063476562)\n",
      "(880, 585.0751953125)\n",
      "(881, 456.284423828125)\n",
      "(882, 365.8840637207031)\n",
      "(883, 328.34173583984375)\n",
      "(884, 319.5799865722656)\n",
      "(885, 295.27313232421875)\n",
      "(886, 222.98342895507812)\n",
      "(887, 105.56915283203125)\n",
      "(888, -20.379390716552734)\n",
      "(889, -109.24095916748047)\n",
      "(890, -136.36849975585938)\n",
      "(891, -112.57638549804688)\n",
      "(892, -74.51614379882812)\n",
      "(893, -59.542755126953125)\n",
      "(894, -83.34381103515625)\n",
      "(895, -134.4290771484375)\n",
      "(896, -186.20346069335938)\n",
      "(897, -215.47418212890625)\n",
      "(898, -214.123291015625)\n",
      "(899, -188.5181884765625)\n",
      "(900, -150.69131469726562)\n",
      "(901, -110.15200805664062)\n",
      "(902, -71.81595611572266)\n",
      "(903, -38.925540924072266)\n",
      "(904, -15.912515640258789)\n",
      "(905, -7.684425354003906)\n",
      "(906, -16.281137466430664)\n",
      "(907, -38.53089904785156)\n",
      "(908, -67.17469024658203)\n",
      "(909, -94.12006378173828)\n",
      "(910, -112.7618637084961)\n",
      "(911, -117.72840881347656)\n",
      "(912, -103.55885314941406)\n",
      "(913, -65.33206176757812)\n",
      "(914, -2.1788856983184814)\n",
      "(915, 78.9724349975586)\n",
      "(916, 163.56605529785156)\n",
      "(917, 235.07650756835938)\n",
      "(918, 283.1137390136719)\n",
      "(919, 308.3538818359375)\n",
      "(920, 320.7537536621094)\n",
      "(921, 332.6466979980469)\n",
      "(922, 352.1017761230469)\n",
      "(923, 381.0585021972656)\n",
      "(924, 418.07037353515625)\n",
      "(925, 461.42376708984375)\n",
      "(926, 508.7855529785156)\n",
      "(927, 554.0037841796875)\n",
      "(928, 585.7704467773438)\n",
      "(929, 592.1617431640625)\n",
      "(930, 569.4264526367188)\n",
      "(931, 527.8372802734375)\n",
      "(932, 487.74700927734375)\n",
      "(933, 466.07952880859375)\n",
      "(934, 462.2597961425781)\n",
      "(935, 455.23333740234375)\n",
      "(936, 416.22943115234375)\n",
      "(937, 329.7675476074219)\n",
      "(938, 207.67059326171875)\n",
      "(939, 84.50491333007812)\n",
      "(940, -3.7556774616241455)\n",
      "(941, -43.0023307800293)\n",
      "(942, -49.194313049316406)\n",
      "(943, -55.0025520324707)\n",
      "(944, -84.94061279296875)\n",
      "(945, -137.84634399414062)\n",
      "(946, -190.0148468017578)\n",
      "(947, -216.18406677246094)\n",
      "(948, -211.46348571777344)\n",
      "(949, -196.4091033935547)\n",
      "(950, -200.63453674316406)\n",
      "(951, -237.58375549316406)\n",
      "(952, -290.6170654296875)\n",
      "(953, -322.4057922363281)\n",
      "(954, -301.8802490234375)\n",
      "(955, -229.10946655273438)\n",
      "(956, -139.27862548828125)\n",
      "(957, -81.85936737060547)\n",
      "(958, -88.93913269042969)\n",
      "(959, -154.2823028564453)\n",
      "(960, -236.84381103515625)\n",
      "(961, -285.3932800292969)\n",
      "(962, -267.2440490722656)\n",
      "(963, -183.14480590820312)\n",
      "(964, -61.535667419433594)\n",
      "(965, 60.53206253051758)\n",
      "(966, 155.62413024902344)\n",
      "(967, 213.087646484375)\n",
      "(968, 234.98825073242188)\n",
      "(969, 228.28042602539062)\n",
      "(970, 200.6727752685547)\n",
      "(971, 161.61572265625)\n",
      "(972, 124.02127075195312)\n",
      "(973, 101.82943725585938)\n",
      "(974, 103.26065063476562)\n",
      "(975, 124.82855224609375)\n",
      "(976, 151.82058715820312)\n",
      "(977, 166.31541442871094)\n",
      "(978, 157.6990203857422)\n",
      "(979, 128.30149841308594)\n",
      "(980, 90.23442077636719)\n",
      "(981, 56.06586456298828)\n",
      "(982, 30.38629150390625)\n",
      "(983, 8.237707138061523)\n",
      "(984, -19.152942657470703)\n",
      "(985, -56.31801986694336)\n",
      "(986, -99.41055297851562)\n",
      "(987, -138.63876342773438)\n",
      "(988, -164.70584106445312)\n",
      "(989, -174.0800323486328)\n",
      "(990, -169.6002197265625)\n",
      "(991, -157.083984375)\n",
      "(992, -141.5841827392578)\n",
      "(993, -126.39592742919922)\n",
      "(994, -114.78604125976562)\n",
      "(995, -111.61615753173828)\n",
      "(996, -122.17742919921875)\n",
      "(997, -148.40696716308594)\n",
      "(998, -185.55300903320312)\n",
      "(999, -222.61245727539062)\n",
      "(1000, -247.047119140625)\n",
      "(1001, -250.75360107421875)\n",
      "(1002, -233.07083129882812)\n",
      "(1003, -198.911376953125)\n",
      "(1004, -154.0560302734375)\n",
      "(1005, -101.88264465332031)\n",
      "(1006, -44.34497833251953)\n",
      "(1007, 14.040637969970703)\n",
      "(1008, 63.644222259521484)\n",
      "(1009, 92.41145324707031)\n",
      "(1010, 93.34317016601562)\n",
      "(1011, 71.68514251708984)\n",
      "(1012, 45.703365325927734)\n",
      "(1013, 38.791290283203125)\n",
      "(1014, 66.84803009033203)\n",
      "(1015, 128.48291015625)\n",
      "(1016, 205.47613525390625)\n",
      "(1017, 270.4518737792969)\n",
      "(1018, 303.0234069824219)\n",
      "(1019, 293.9493713378906)\n",
      "(1020, 252.5462646484375)\n",
      "(1021, 190.9376220703125)\n",
      "(1022, 127.80016326904297)\n",
      "(1023, 69.68441772460938)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Get denoised EEG plotting points\n",
    "x_points = list(range(len(clean_segment)))      # X-axis: time/sample index\n",
    "y_points = clean_segment.tolist()               # Y-axis: denoised EEG values\n",
    "\n",
    "# ‚úÖ Print the plotting points\n",
    "print(\"Clean EEG Plotting Points:\")\n",
    "for x, y in zip(x_points, y_points):\n",
    "    print(f\"({x}, {y})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
